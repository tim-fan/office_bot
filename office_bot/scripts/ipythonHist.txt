 2/1: from findPeople.models import *
 2/2: User()
 2/3: User(userId = 1)
 2/4: u = User(userId = 1)
 2/5: u
 2/6: u.userId
 2/7: u.lastSeenLocation
 2/8: u.save
 2/9: u.save()
2/10: from uuid import uuid4 as uusid
2/11: from uuid import uuid4 as uuid
2/12: from uuid import UUID
2/13:
u = User(userId = UUID(str(uuid()))

)
2/14: u = User(userId = UUID(str(uuid())))
2/15: u.id
2/16: u.userId
2/17: u.save()
2/18: u = User(userId = UUID(str(uuid())))
2/19: User.objects.all()
2/20: u.save()
 3/1: from findPeople.models import *
 3/2: u = User(userId = UUID(str(uuid())))
 3/3: from uuid import UUID
 3/4: from uuid import uuid4 as uuid
 3/5: u = User(userId = UUID(str(uuid())))
 3/6: u.save()
 3/7: l = LocationObservation(lat = 0, lon = 0, time = datetime.now())
 3/8: from datetime import datetime
 3/9: l = LocationObservation(lat = 0, lon = 0, time = datetime.now())
3/10: l.save()
3/11: u = User(userId = UUID(str(uuid())), lastSeenLocation = l)
3/12: u.save()
3/13: id = UUID(str(uuid()))
3/14: id
3/15: u = User(userId = id, lastSeenLocation = l)
3/16: u.save()
3/17: l = LocationObservation(lat = 0, lon = 0, time = datetime.now())
3/18: l.save()
3/19: l = LocationObservation(lat = 0, lon = 0, time = datetime.now())
3/20: l.save()
3/21: u = User(userId = id, lastSeenLocation = l)
3/22: u.save()
3/23: User.objects.all()
3/24: help User.objects.get_or_create
3/25: help(User.objects.get_or_createi)
3/26: help(User.objects.get_or_create)
3/27: help(User.objects.get_or_create)
3/28: User.objects.all()
3/29: User.objects.get(userId = id)
3/30: u = User.objects.get(userId = id)
3/31: u.id
3/32: id
3/33: u.userId
3/34: u.lastSeenLocation
3/35: l = LocationObservation(lat = 0, lon = 0, time = datetime.now())
3/36: l
3/37: u.lastSeenLocation = l
3/38: u.save()
3/39: l.save()
3/40: u.lastSeenLocation = l
3/41: u.save()
3/42: LocationObservation.objects.all()
3/43: list(LocationObservation.objects.all())
3/44: usr = User.objects.get(userId = id)
3/45: usr = User.objects.all()
3/46: usr
3/47: usr = User.objects.all()
3/48: usr
3/49: usr[0]
3/50: usr = usr[0]
3/51: help(User.objects.only)
3/52: usr = usr[0]
3/53: usr.userId
3/54: id = usr.userId
3/55: User.objects.all()
3/56: User.objects.get(id)
3/57: User.objects.get(userId = id)
3/58: usr = User.objects.all()
3/59: ust
3/60: usr
3/61: usr = User.objects.all()
3/62: usr
3/63: usr
3/64: usr = usr[0]
3/65: id = usr.userId
3/66: User.objects.count(userId = id)
3/67: User.objects.get(userId = id)
3/68: id
3/69: User.objects.get(userId = uuid())
3/70: User.objects.all()
3/71: u1 = User.objects.all()[0]
3/72: u1
3/73: u1.lastSeenLocation
3/74: list(u1.lastSeenLocation)
3/75: u1.lastSeenLocation.validate_unique
3/76: u1.lastSeenLocation.values()
3/77: u1 = User.objects.all()[0]
3/78: u1
3/79: u1 = User.objects.values()
3/80: u1
3/81: u1
3/82: u1 = User.objects.all()[0]
3/83: User.objects.all()
3/84: User.objects.all.lastSeenLocation
3/85: User.objects.all()
3/86: type(User.objects.all())
3/87: users = User.objects.all()
3/88: u1 = users[0]
3/89: u0 = users[0]
3/90: u0.lastSeenLocation
3/91: l0 = u0.lastSeenLocation
3/92: dict(l0)
3/93: l0
3/94: from django.forms.models import model_to_dict
3/95: model_to_dict(l0)
3/96: [model_to_dict(user.lastSeenLocation) for user in users]
3/97: lis(User.objects.values)
3/98: list(User.objects.values)
3/99: list(User.objects.values())
3/100: [model_to_dict(user.lastSeenLocation) for user in users]
3/101: users = User.objects.all()
3/102: users = User.objects.all()
3/103: User.objects.all()
3/104: len(User.objects.all())
3/105: usr.lastSeenLocation.delete()
3/106: usr.lastSeenLocation.delete()
10/1: from findPeople.models import LocationObservation
10/2: ls
10/3: LocationObservation.objects.all()
11/1: from findPeople.models import *
11/2: LocationObservation.objects.all()
11/3: LocationObservation.objects.all()
11/4: LocationObservation.objects.all()
11/5: time_threshold = datetime.now() - timedelta(hours=5)
11/6: from datetime import datetime, timedelta
11/7: from django.utils import timezone
11/8: time_threshold = timezone.now() - timedelta(hours=5)
11/9: time_threshold
11/10: LocationObservation.objects.filter(time__lt=time_threshold)
11/11: timezone.now()
11/12: str(timezone.now())
11/13: LocationObservation.objects.filter(time__gt=time_threshold)
11/14: LocationObservation.objects.filter(time__gt=time_threshold)
11/15: LocationObservation.objects.filter(time__lt=time_threshold)
11/16: User.objects.all()
11/17: LocationObservation.objects.filter(time__lt=time_threshold)
11/18: oldPositions = LocationObservation.objects.filter(time__lt=time_threshold)
11/19: oldPositions.delete()
11/20: User.objects.all()
13/1:
class Loc:
    pass
l = Loc()
13/2: l
13/3: l.a = 2
13/4: l
13/5: l.a
13/6: :q
14/1:
class Loc:
    pass
l = Loc()
14/2: l
14/3: l.a
14/4: l.a = 2
14/5: l.a
14/6: l.a.b =2
12/1: name = ''
12/2: name is empty
12/3: name is ''
12/4: 1 if 1 else 2
12/5: 1 if 0 else 2
14/7: :q
12/6: from findPeople.models import *
12/7: LocationObservation.objects.all()
12/8: LocationObservation.objects.all()
12/9: User.objects.all()
12/10: User.objects.all()
12/11: User.objects.all()[0]
12/12: str(User.objects.all()[0])
12/13: u = User.objects.all()[0]
12/14: u.lastSeenLocation
12/15: u = User.objects.all()[0]
12/16: u
12/17: from findPeople.models import *
12/18: LocationObservation.objects.all()
12/19: l = LocationObservation.objects.all()[0]
12/20: l.user
12/21: u = ul.user
12/22: u = l.user
12/23: LocationObservation.objects
12/24: l
12/25: LocationObservation.objects.filter(User=u)
12/26: LocationObservation.objects.filter(user=u)
12/27: LocationObservation.objects.get_or_create(user=u)
12/28: LocationObservation.objects.get_or_create(user=u)
15/1: from findPeople.models import *
15/2: LocationObservation.objects.get_or_create(user=u)
15/3: u = l.user
15/4: l = LocationObservation.objects.all()[0]
15/5: u = l.user
15/6: u = l.user
15/7: LocationObservation.objects.all()[0]
15/8: l = LocationObservation.objects.all()[0]
15/9: l.time
15/10: l.user
15/11: l = LocationObservation.objects.all()[0]
15/12: l.time
15/13: l.user
15/14: l
15/15: l = LocationObservation.objects.all()[0]
15/16: l
16/1: from findPeople.models import *
16/2: l = LocationObservation.objects.all()[0]
16/3: l = LocationObservation.objects.all()[0]
16/4: l.user
16/5: l.user.name
17/1: from findPeople.models import *
17/2: User.objects.all()
17/3: User.objects.all()[0]
17/4: usr = User.objects.all()[0]
17/5: usr.name
17/6: usr.name = 'KoiKoi'
17/7: usr.save()
17/8: usr.name
17/9: usr.userId
17/10: usr.pk
17/11:
if '':
    print('yes')
18/1: from findPeople.models import *
18/2: User.objects.all()
20/1: from findPeople.models import *
20/2: User.objects.all()
24/1: a = [2,3,4]
24/2: b = [5,2,4,3,1]
24/3: abs(1)
24/4: sum(abs(i - j) for i in a for j in b[0:3])
24/5: b[0:3]
24/6: sum(abs(i - j) for i in a for j in b[0:len(a)])
24/7: sum(abs(i - j) for i in a for j in b[o:len(a)+o])
24/8: cost = lambda o: sum(abs(i - j) for i in a for j in b[o:len(a)+o])
24/9: cost(1)
24/10: cost(0)
24/11: [cost(o) for o in range(len(b) - len(a))]
24/12: a = [1, 2, 6] b = [0, 1, 3, 4, 5]
24/13: a = [1, 2, 6] # b = [0, 1, 3, 4, 5]
24/14:  b = [0, 1, 3, 4, 5]
24/15: [cost(o) for o in range(len(b) - len(a))]
24/16: cost = lambda o: sum(abs(i - j) for i in a for j in b[o:len(a)+o])
24/17: [cost(o) for o in range(len(b) - len(a))]
24/18: cost(0)
24/19: cost(1)
24/20: cost(2)
24/21: cost(3)
24/22: [cost(o) for o in range(len(b) - len(a))]
24/23: a
24/24: b
24/25: cost = lambda o: sum(abs(a[i] - b[i+o]) for i in range(len(a)))
24/26: cost(0)
24/27: cost(1)
24/28: cost(2)
24/29: cost(3)
24/30: cost = lambda o: sum(abs(a[i] - b[i+o]) for i in range(len(a)))
24/31: a
24/32: b
24/33: range(len(a))
24/34: [cost(o) for o in range(len(b) - len(a))]
24/35: [cost(o) for o in range(len(b) + 1 - len(a))]
24/36: a
24/37: b
24/38: indices = range(len(b))
24/39: indices
24/40: import itertools
24/41: help(itertools.combinations)
24/42: itertools.combinations(indices,3)
24/43: list(itertools.combinations(indices,3))
24/44: indices
24/45: num2drop = len(b) - len(a)
24/46: list(itertools.combinations(range(len(b)),num2drop))
24/47: d = list(itertools.combinations(range(len(b)),num2drop))[0]
24/48: d
24/49: b
24/50: b[-3]
24/51: exclude = lambda l, e : (i for i in l if i not in e)
24/52: exclude(b, d)
24/53: list(exclude(b, d))
24/54: d
24/55: b
24/56: d = list(itertools.combinations(range(len(b)),num2drop))[4]
24/57: d
24/58: list(exclude(b, d))
24/59: b
24/60: d
24/61: score = lambda a ,b : sum()
24/62: zip([1,2,3], ['a', 'b', 'c'])
24/63: score = lambda a ,b : sum(abs(i-j) for i, j in zip(a,b))
24/64: score(a,b)
24/65: zip([1,2,3], ['a', 'b', 'c', 'd'])
24/66: a
24/67: b
24/68: score(a,exclude(b,d))
24/69: d
24/70: d = (0,3)
24/71: score(a,exclude(b,d))
24/72: exclude(b,d)
24/73: list(exclude(b,d))
24/74: b
24/75: d
24/76: b[3]
24/77: list(exclude(b,d))
24/78: exclude = lambda l, e : (i for i in l if not i in e)
24/79: list(exclude(b,d))
24/80: 1 not in (2,3)
24/81: 1 not in (1,2,3)
24/82: exclude = lambda l, e : (l[i] for i in range(len(l)) if i not in e)
24/83: list(exclude(b,d))
24/84: score(a,exclude(b,d))
24/85: dropScore = lambda dropIndices : score(a, exclude(b, dropIndices))
24/86: dropScore((0,2))
24/87: d
24/88: dropScore((0,3))
24/89: itertools.combinations(indices,3)
24/90: list(itertools.combinations(range(len(b)),num2drop))
24/91: %paste
24/92:     num2drop = len(b) - len(a)
24/93:     possibleDrops = itertools.combinations(range(len(b)),num2drop)
24/94:     dropResults = [dropScore(dropIndices) for dropIndices in possibleDrops]
24/95: dropResults
24/96:
dropResults.index(min(dropResults)
)
24/97: dropResults.index(min(dropResults))
24/98: possiblDrops[dropResults.index(min(dropResults))]
24/99: possibleDrops[dropResults.index(min(dropResults))]
24/100: list(possibleDrops)
24/101: possibleDrops = list(itertools.combinations(range(len(b)),num2drop))
24/102: possibleDrops[dropResults.index(min(dropResults))]
24/103:
class Node:
    i = 0
24/104: Node()
24/105: n1 = Node()
24/106: n1.i
24/107: n1.i = 34
24/108: n1.i
24/109: n2 = n1
24/110: n2.i
24/111: n2.i = 0
24/112: n1.i
25/1: import sys; print('%s %s' % (sys.executable or sys.platform, sys.version))
25/2: Node()
25/3: example.Node()
25/4: whos
25/5: import example
25/6: pwd
26/1: import sys; print('%s %s' % (sys.executable or sys.platform, sys.version))
26/2: import root
26/3: root.nested
26/4: import root.nested
26/5: import root.nested
26/6: root.nested
26/7: root.nested.example
26/8: import root.nested.example
26/9: root.nest
26/10: root.nested.example.Node()
26/11: ([],0)
26/12: firstNode = ([], 0)
28/1: ls
28/2: mod()
28/3: from math import modf
28/4: 10 % 3
28/5: 14 % 10
28/6: 14 /10
28/7: nCols = 16, nRows = 11, col = 5, row = 3
28/8: nCols = 16 #, nRows = 11, col = 5, row = 3
28/9: nRows = 11, #col = 5, #row = 3
28/10: col = 5, #row = 3
28/11: row = 3
28/12: whos
28/13: nRows = 11
28/14: col = 5
28/15: whos
28/16: ans = 96
28/17: (nRows - row) * (nCols - col)
28/18: (nRows - row) * (nCols - col + 1)
28/19: 10 % 10
28/20: from itertools import combinations
28/21: combinations([1,2,3])
28/22: combinations([1,2,3], 'any')
28/23: combinations([1,2,3], 'any')
28/24: combinations([1,2], 2)
28/25: combinations([1,2], 2) + combinations([1,2], 1)
28/26: from itertools import chain
28/27: chain(combinations([1,2], 2) + combinations([1,2], 1))
28/28: chain(combinations([1,2], 2), combinations([1,2], 1))
28/29: (chain(combinations([1,2], 2), combinations([1,2], 1)))
28/30: list(chain(combinations([1,2], 2), combinations([1,2], 1)))
28/31: combinations([],3)
28/32: a = [(1,2), (3,4)]
28/33: a.sort()
28/34: a
28/35: help(a.sort)
28/36: a.sort(cmp = lambda x: x[0])
28/37: a.sort(key = lambda x: x[0])
28/38: a
28/39: a.sort(key = lambda x: x[0], reverse=Ture)
28/40: a.sort(key = lambda x: x[0], reverse=True)
28/41: a
28/42: a.sort(key = lambda x: x[0], reverse=True)
28/43: a
28/44: a,b = 0,0
28/45: a
28/46: b
28/47: a,b = 0
28/48: a = [1,4,4]
28/49: a.count(a[0])
28/50: a.count(a[1])
28/51:
def arithmeticExpression(A, B, C):
        return ( A + B == C or
                 A - B == C or 
                 A * B == C or 
                 A / B == C 
               )
28/52: max((1,2))
28/53: True and True and True
27/1: daysInMonth = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]
27/2: daysInMonth
28/54: daysInMonths = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]
28/55: daysInMonths.index(31)
28/56: daysInMonths.index(31, all)
28/57: help(daysInMonths.index)
28/58: [i for i in range(12) if daysInMonths(i) == 31]
28/59: [i for i in range(12) if daysInMonths[i] == 31]
28/60: int('101',2)
28/61: int(bin(6),2)
28/62: b = bin(34)
28/63: b
28/64: b[0]
28/65: b[1]
28/66: int(bin(432),2)
28/67: int(bin(432)[2:],2)
28/68:     dec2bin = lambda d : bin(d)[2:]
28/69:     bin2dec = lambda b : int(b,2)
28/70: a = 'hithere'
28/71: a[4] = 'x'
28/72: a
28/73: a.replace(4, 'x')
28/74: help(a.replace)
28/75: a = 'hithere'
28/76: a = 23
28/77: nbits = lambda x : log()
28/78:
log(0
)
28/79: from math import log
28/80: log(32,2)
28/81: bin(32)
28/82: bin(32-1)
28/83: log(32-1,2)
28/84: log(32,2)
28/85: log(35,2)
28/86: log(64,2)
28/87: int(log(64,2))
28/88: int(log(64,2)) + 1
28/89: nbits = int(log(x,2)) + 1
28/90: nbits = lambda : int(log(x,2)) + 1
28/91: nbits(32)
28/92: nbits = lambda x: int(log(x,2)) + 1
28/93: nbits(32)
28/94: bin(32)
28/95: bin(31)
28/96: nbits(31)
28/97: setbitlow = lambda b , k
28/98: a = dec2bin(42)
28/99: a
28/100: a[:3]
28/101: a[:3] + a[4:]
28/102: setbitlow = lambda b , k : b[:k] '0' b[k+1:]
28/103: setbitlow = lambda b , k : b[:k] + '0' + b[k+1:]
28/104: setbitlow(a,2)
28/105: a
28/106: setbitlow(a,0)
28/107:
def killKthBit(n, k):
        return int(bin(n)[2:][:k] + '0' + bin(n)[2:][k+1:],2)
28/108: dec2bin = lambda d : bin(d)[2:]
28/109: bin2dec = lambda b : int(b,2)
28/110: setbitlow = lambda b , k : b[:k] + '0' + b[k+1:]
28/111: n = 2147483647
28/112: k = 16
28/113: dec2bin(n)
28/114: setbitlow(dec2bin(n))
28/115: setbitlow(dec2bin(n),k)
28/116: k
28/117: bin2dec(setbitlow(dec2bin(n),k))
28/118: n - 2147450879
28/119: log(n - 2147450879,2)
28/120: bin2dec(setbitlow( dec2bin(n), k))
28/121: bin(2147450879)
28/122: bin(2147450879)[2:]
28/123: bin(2147450879)[2:].index('0')
29/1: a = [1, 2, 6] # b = [0, 1, 3, 4, 5]
29/2: b = [0,1,3,4,5]
29/3: state = []
29/4: sum(abs(a[i] - b[i])  for i in range(len(state)) if state[i])
29/5: state = [1]
29/6: sum(abs(a[i] - b[i])  for i in range(len(state)) if state[i])
29/7: state = [1,0]
29/8: sum(abs(a[i] - b[i])  for i in range(len(state)) if state[i])
29/9: stateScore = lambda state: sum(abs(a[i] - b[i])  for i in range(len(state)) if state[i])
29/10: stateScore([0,1,0])
29/11: stateScore([0,1,1,0,1])
29/12: state [0,1,1,0,1]
29/13: state = [0,1,1,0,1]
29/14: state
29/15: [b[i] for i in range(len(b)) if state[i]]
29/16: subsequence = lambda x, index : [x[i] for i in range(len(x)) if index[i]]
29/17: subsequence(b, state)
29/18: subsequence(b, [])
29/19: subsequence = lambda x, index : [x[i] for i in range(len(index)) if index[i]]
29/20: subsequence(b, [])
29/21: subsequence(b, [1])
29/22: b
29/23: subsequence(b, [1,1])
29/24: subsequence(b, [1,1,0])
29/25: subsequence(b, [1,1,0,1])
29/26: sequencediff = lambda x, y: sum(abs(i-j) for i,j in zip(x,y))
29/27: sequenceDiff = lambda x, y: sum(abs(i-j) for i,j in zip(x,y))
29/28: stateScore = lambda state: sequenceDiff(b, subsequence(a, state))
29/29: stateScore([0,1,1,0,1])
29/30: stateScore = lambda state: sequenceDiff(a, subsequence(b, state))
29/31: stateScore([0,1,1,0,1])
29/32: stateScore([0,1,1,1,1])
29/33: stateScore([0,1,1,1,0])
29/34: stateScore([0,0,1,1,0])
29/35: subSequence = lambda x, index : [x[i] for i in range(len(index)) if index[i]]
29/36: sequenceDiff = lambda x, y: sum(abs(i-j) for i,j in zip(x,y))
29/37: stateScore = lambda state: sequenceDiff(a, subSequence(b, state))
29/38: stateScore([0,0,1,1,0])
29/39: frontier = [([],0)]
29/40: isValidState = lambda state: state.count(1) <= len(a) and (len(b) - state.count(0)) >= len(a)
29/41: isValidState([])
29/42: isValidState([0,0,0])
29/43: isValidState([0,0])
29/44: isValidState([0,0,1])
29/45: isValidState([0,0,1,1,1])
29/46: isValidState([0,1,1,1,1])
29/47: nextState = lambda currentState, nextPick : currentState + nextPick
29/48: nextState(state,1)
29/49: nextState = lambda currentState, nextPick : currentState + [nextPick]
29/50: nextState(state,1)
29/51: state
29/52: import math
29/53: float('inf')
29/54: 1 if 2 else 3
29/55: 1 if 0 else 3
29/56:     subSequence = lambda x, index : [x[i] for i in range(len(index)) if index[i]]
29/57:     sequenceDiff = lambda x, y: sum(abs(i-j) for i,j in zip(x,y))
29/58:     #cant pick more elements than are in a, or throw away more than (len(b) - len(a))
29/59:     isValidState = lambda state: state.count(1) <= len(a) and (len(b) - state.count(0)) >= len(a)
29/60:     stateScore = lambda state: sequenceDiff(a, subSequence(b, state)) if isValidState(state) else float('inf')
29/61:     nextState = lambda currentState, nextPick : currentState + [nextPick]
29/62:     evaluateState = lambda state : (state, stateScore(state))
29/63: evaluateState([])
29/64: evaluateState([1])
29/65: evaluateState([1,1,1,1,1])
29/66:     subSequence = lambda x, index : [x[i] for i in range(len(index)) if index[i]]
29/67:     sequenceDiff = lambda x, y: sum(abs(i-j) for i,j in zip(x,y))
29/68:     #cant pick more elements than are in a, or throw away more than (len(b) - len(a))
29/69:     isValidState = lambda state: state.count(1) <= len(a) and (len(b) - state.count(0)) >= len(a)
29/70:     stateScore = lambda state: sequenceDiff(a, subSequence(b, state)) if isValidState(state) else float('inf')
29/71:     evaluateState = lambda state : (state, stateScore(state))
29/72:     nextState = lambda currentState, nextPick : currentState + [nextPick]
29/73:     evaluateNextState = lambda currentState, nextPick : evaluateState(nextState(currentState, nextPick))
29/74:     exploreState = lambda state : [evaluateNextState(state, 0), evaluateNextState(state, 1)]
29/75: exploreState([])
29/76: exploreState(exploreState([])[0])
29/77: exploreState(exploreState([])[0][0])
29/78: exploreState(exploreState([])[1][0])
29/79:
class Node:
    def __init__(self, state, score):
        self.state = state
        self.score = score
29/80: Node([],8)
29/81: n = Node([],8)
29/82: n.score
29/83: n.score = 4
29/84:     subSequence = lambda x, index : [x[i] for i in range(len(index)) if index[i]]
29/85:     sequenceDiff = lambda x, y: sum(abs(i-j) for i,j in zip(x,y))
29/86:     #cant pick more elements than are in a, or throw away more than (len(b) - len(a))
29/87:     isValidState = lambda state: state.count(1) <= len(a) and (len(b) - state.count(0)) >= len(a)
29/88:     stateScore = lambda state: sequenceDiff(a, subSequence(b, state)) if isValidState(state) else float('inf')
29/89:     evaluateState = lambda state : Node(state, stateScore(state))
29/90:     nextState = lambda currentState, nextPick : currentState + [nextPick]
29/91:     evaluateNextState = lambda currentState, nextPick : evaluateState(nextState(currentState, nextPick))
29/92:     exploreNode = lambda node : [evaluateNextState(node.state, 0), evaluateNextState(node.state, 1)]
29/93:     frontier = [Node([],0)]
29/94: exploreNode(frontier[0])
29/95:
class Node:
        def __init__(self, state, score):
                self.state = state
                self.score = score
            def __str__ print(self)
                return 'state: {st}, score: {sc}'.format(st = self.state, sc = self.score)
29/96:
class Node:
        def __init__(self, state, score):
                self.state = state
                self.score = score
            def __str__(self):
                    return 'state: {st}, score: {sc}'.format(st = self.state, sc = self.score)
29/97: %paste
29/98: %paste
29/99: Node([],8)
29/100: str(Node([],8))
29/101: %paste
29/102: Node([],8)
29/103: %paste
29/104: Node([],8)
29/105: exploreNode(frontier[0])
29/106: %paste
29/107: exploreNode(frontier[0])
29/108: exploreNode(frontier[0])
29/109: f  = exploreNode(frontier[0])
29/110: f
29/111: min(f, key = lambda n: n.score)
29/112: a = [1:5]
29/113: a = range(5)
29/114: a
29/115: a.remove(2)
29/116: a
29/117: %paste
29/118: frontier
29/119: leaves
29/120: a = [1,2,3]
29/121: a
29/122: a.append([4,5,6])
29/123: a
29/124: a = [1,2,3]
29/125: a.extend([4,5,6])
29/126: a
29/127: %paste
29/128: %paste
29/129: bestCurrentLeaf
29/130: leaves
29/131: frontier
29/132: %paste
29/133: %paste
29/134: %paste
29/135: a
29/136: b
29/137: a = [1,2,3]
29/138: a = [1, 2, 6] # b = [0, 1, 3, 4, 5]
29/139: %paste
29/140: c = range(4)
29/141: c
29/142: c + [5]
29/143: None = [5]
29/144: None + [5]
29/145: a
29/146: b
30/1: help(range)
30/2: help(range)
30/3: set(range(lower-1, upper+1, 1))
30/4: lower = 0
30/5: upper = 3
30/6: set(range(lower-1, upper+1, 1))
30/7: set(range(lower, upper+1, 1))
30/8: round(1.2)
30/9: help(round)
30/10: ciel(1.2)
30/11: ceil(1.2)
30/12: from math import ceik
30/13: from math import ceil
31/1:
def addInRange(lower, upper):
        return sum(range(int(math.ceil(lower)), int(math.floor(upper+1))))
31/2: addInRange(0, 2 * 10e8)
31/3: import math
31/4: addInRange(0, 2 * 10e8)
31/5:
range(int(math.ceil(lower)), int(math.floor(upper+1)
)
)
31/6: lower = 0
31/7: upper = 2*10e8
31/8:
range(int(math.ceil(lower)), int(math.floor(upper+1)
)
)
31/9: range(5)
31/10: help(range)
31/11:
range(int(math.ceil(lower)), int(math.floor(upper+1)
)
)
31/12: range(int(math.ceil(lower)), int(math.floor(upper+1)))
31/13: xrange(int(math.ceil(lower)), int(math.floor(upper+1)))
31/14: addInRange(0, 2 * 10e8)
31/15:
def addInRange(lower, upper):
        return sum(xrange(int(math.ceil(lower)), int(math.floor(upper+1))))
31/16: addInRange(0, 2 * 10e8)
31/17: n = 2*10e8
31/18: n
31/19: n(n+1)/2
31/20: n*(n+1)/2
32/1: 2^2
33/1: float('nan')
31/21: import itertools
34/1: sum([T,F,T])
34/2: sum([True,False,True])
35/1: intArray = []
35/2: intArray.append(3)
35/3: intArray.append(2)
35/4: intArray.append(1)
35/5: intArray
35/6: intArray.extend(3)
36/1: intAtPos = lambda num : num
36/2: num = 1734
36/3: num /10
36/4: (num /10) % 10
36/5: (num /100) % 100
36/6: (num /100) % 10
36/7: (num /1000) % 10
36/8: (num /1) % 10
36/9: (num /1**0) % 10
36/10: (num /1**1) % 10
36/11: (num /1**2) % 10
36/12: num
36/13: (num /10**2) % 10
36/14: (num /10**0) % 10
36/15: (num /10**1) % 10
36/16: (num /10**2) % 10
36/17: (num /10**3) % 10
36/18: (num /10**4) % 10
36/19: (num /10**5) % 10
36/20: intAtPos = lambda num, pos : (num /10**pos) % 10
36/21: intAtPos(1734, 0)
36/22:     toIntArray = lambda (num, length) : [intAtPos(num, pos) for pos in range(length)]
36/23: toIntArray(1734, 4)
36/24:     toIntArray = lambda num, length : [intAtPos(num, pos) for pos in range(length)]
36/25: toIntArray(1734, 4)
36/26:     toIntArray = lambda num, length : [intAtPos(num, pos) for pos in range(length,0)]
36/27: toIntArray(1734, 4)
36/28:     toIntArray = lambda num, length : [intAtPos(num, pos) for pos in range(length,0,-1)]
36/29: toIntArray(1734, 4)
36/30:     toIntArray = lambda num, length : [intAtPos(num, pos) for pos in range(length,-1,-1)]
36/31: toIntArray(1734, 4)
36/32: a = toIntArray(1734, 4)
36/33: a.reverse
36/34: a
36/35: a.reverse()
36/36: a
36/37: List.reverse(a)
36/38:     toIntArray = lambda num, length : [intAtPos(num, pos) for pos in range(length,-1,-1)]
36/39: toIntArray(1734, 4)
36/40: toIntArray(1734, 4)
36/41: a = toIntArray(1734, 4)
36/42: a
36/43: intArrayToInt = sum( array(i)*10**(len(array) - i) for i in range(len(array))  )
36/44: array = a
36/45: intArrayToInt = sum( array(i)*10**(len(array) - i) for i in range(len(array))  )
36/46: intArrayToInt = sum( array[i]*10**(len(array) - i) for i in range(len(array))  )
36/47: intArrayToInt
36/48: intArrayToInt = sum( array[i]*10**(len(array) - i -1) for i in range(len(array))  )
36/49: intArrayToInt
36/50: intArrayToInt = lambda array:  sum( array[i]*10**(len(array) - i -1) for i in range(len(array))  )
36/51: intArrayToInt(a)
37/1:
for i in range(10):
    print('Koi sucks!')
37/2: wtf
37/3:
for i in range(10):
    print('Koi sucks balls!')
37/4: error
37/5: ok bub
38/1: import h5py
39/1: import pandas
40/1: import pandas as np
40/2: import pandas as pd
40/3: import numpy as np
40/4: import pylab
42/1: import xml.etree.ElementTree as et
42/2: help(et)
44/1: import bz2
44/2: help(bz2.decompress)
44/3: help(bz2)
44/4: import zipfile
44/5: help zipfile
44/6: help(zipfile)
44/7: a = []
44/8: a == []
44/9: import shutil
44/10: help(shutil.move)
44/11: help(shutil.copy)
44/12: help(shutil.copy)
44/13: import xml.etree.ElementTree as et
44/14: import h5py
45/1: import extractLogInfo
45/2: import extractLogInfo
45/3: import extractLogInfo
45/4: import extractLogInfo
45/5: from imp import reload
45/6: reload(extractLogInfo)
45/7: extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
45/8: reload(extractLogInfo)
45/9: extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
45/10: type 'hi'
45/11: type('hi')
45/12: type(['hi'])
45/13: isinstance('hi', str)
45/14: isinstance(['hi'], str)
45/15: reload(extractLogInfo)
45/16: extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
45/17: import sys
45/18: import pipes
45/19: help(pipes)
45/20: import os
45/21: import shutil
45/22: help(shutil)
45/23: import h5py
45/24: f = h5py.File('/tmp/pathFittingWorkingFiles-20161219-1242-dTBgYA/TPE1454789.2016-11-03_045857-051-2227.h5')
45/25: f
45/26: f.items()
45/27: f['/EBL/InitData']
45/28: f['/EBL/InitData'].items
45/29: f['/EBL/InitData']
45/30: f['dfsdfsd']
45/31: f['/EBL/InitData']
45/32: f['/EBL/InitData/']
45/33: f['/EBL/InitDatad']
45/34: f['/EBL/InitData/']
45/35: id = f['/EBL/InitData/']
45/36: id
45/37: id.values
45/38: id.values()
45/39: id = f['/EBL/InitData/0000990074']
45/40: id
45/41: id.values
45/42: id.items()
45/43: id = f['/EBL/InitData/0000990074/ConfigXml']
45/44: id.value
45/45: id.value()
45/46: id.value.data
45/47: id.value.astype(char)
45/48: id.value.astype(chr)
45/49: id.value.astype(str)
45/50: id.value.tostring
45/51: id.value.tostring()
45/52: xmlStr = id.value.tostring()
45/53: et
45/54: import xml.etree.ElementTree as et
45/55: et.ElementPath(xmlStr)
45/56: et.ElementTree(xmlStr)
45/57: et.ElementTree(xmlStr)
45/58: import xml.etree.ElementTree
45/59: et = xml.etree.ElementTree.ElementTree(xmlStr)
45/60: print(xmlStr)
45/61: et['/']
45/62: et['/config']
45/63: et.find('/config/')
45/64: et.find('config/')
45/65: et.find('config')
45/66: cfg = et.find('config')
45/67: cfg.bit_length
45/68: cfg.bit_length()
45/69: cfg = et.find('config/wheelbase')
45/70: cfg
45/71: et.find('config')
45/72: et.find('config/wheelbase/')
45/73: et.find('config/wheelbase')
45/74: et.find('./config/wheelbase')
45/75: import BeautifulSoup as bf
45/76: soup = bf.BeautifulSoup(xmlStr)
45/77: print(xmlStr)
45/78: soup['config']
45/79: soup['/config']
45/80: soup.find('config')
45/81: soup.find('config/wheelbase')
45/82: help(soup)
45/83: help(et)
45/84: et.find('config')
45/85: help(xml.etree.ElementPath)
45/86: help(xml.etree.ElementTree)
45/87: help(xml.etree.ElementTree)
45/88: et.find('config')
45/89: et.find('config').find('wheelbase')
45/90: et.find('config/wheelbase')
45/91: et.getroot
45/92: et.getroot()
45/93: root = et.getroot()
45/94: type(root)
45/95: et.parse()
45/96: a = et.find('config')
45/97: a
45/98: xml.etree.ElementTree.parse(xmlStr)
45/99: parsed = xml.etree.ElementTree.parse(xmlStr)
45/100: parsed
45/101: parsed = xml.etree.ElementTree.parse(xmlStr)
45/102: parsed = xml.etree.ElementTree.parse(xmlStr)
45/103: parsed
45/104: f = h5py.File('/tmp/pathFittingWorkingFiles-20161219-1242-dTBgYA/TPE1454789.2016-11-03_045857-051-2227.h5')
45/105: f['/EBL/InitData/']
45/106: f['/EBL/InitData/'].items
45/107: f['/EBL/InitData/'].items()
45/108: i.items() for i in f['/EBL/InitData/'].items()
45/109: (i.items() for i in f['/EBL/InitData/'].items())
45/110: [i.items() for i in f['/EBL/InitData/'].items()]
45/111: [i.items() for i in f['/EBL/InitData/'].items()]
45/112: id = f['/EBL/InitData/']
45/113: id
45/114: id.values
45/115: [id.values]
45/116: [i.items() for i in f['/EBL/InitData/'].values()]
45/117: [i.values() for i in f['/EBL/InitData/'].values()]
45/118: [i.values() for i in f['/EBL/InitData/'].values()]
45/119: l = [i.values() for i in f['/EBL/InitData/'].values()]
45/120: s = ''
45/121: l = [[1,2], [3], [4,5,6]]
45/122: l
45/123: l.items
45/124: l.pop
45/125: l.pop()
45/126: l.pop()
45/127: l.pop()
45/128: l = [[1,2], [3], [4,5,6]]
45/129: %patse
45/130: %paste
45/131: flattenList(l)
45/132: l = [i.values() for i in f['/EBL/InitData/'].values()]
45/133: flattenList(l)
45/134: d = []
45/135: d = {}
45/136: c ={'a':2, 'b':3}
45/137: c
45/138: c.update(d)
45/139: d
45/140: c
45/141: d.update(c)
45/142: c
45/143: d
45/144: d.update(c)
45/145: d
45/146: flattenList(l)
45/147: configH5Groups = flattenList(l)
45/148: configH5Groups
45/149: configH5Groups[0]
45/150: configH5Groups[0]
45/151: cg0 = configH5Groups[0]
45/152: cg0.name
45/153: cg0.value
45/154: cg0.id
45/155: a = cg0.id
45/156: a.id
45/157: cg0.value
45/158: cg0.name
45/159: cg0.name.split('/')
45/160: cg0.name.split('/')[-1]
45/161: group = cg0
45/162: group
45/163: %paste
45/164: group
45/165: groupName(group)
45/166: %paste
45/167: groupName(group)
45/168: group.value.tostring
45/169: group.value.tostring()
45/170: {groupName(h5Group):h5Group.value.tostring}
45/171: h5Group = group
45/172: {groupName(h5Group):h5Group.value.tostring}
45/173: {groupName(h5Group):h5Group.value.tostring()}
45/174: h5Group = configH5Groups[1]
45/175: {groupName(h5Group):h5Group.value.tostring()}
45/176: h5Group.value
45/177: type(h5Group.value)
45/178: %paste
45/179: groupToDict(group)
45/180: groupToDict(group, asString = True)
45/181: %patse
45/182: %paste
45/183: groupToDict(group)
45/184: groupToDict(group, asString = True)
45/185: groupToDict(h5Group, asString = True)
45/186: groupToDict(h5Group, asString = False)
45/187: h5Group
45/188: {groupToDict(g) for g in }
45/189: flattenList(l)
45/190: {groupToDict(g) for g in flattenList(l)}
45/191: [groupToDict(g) for g in flattenList(l)}]
45/192: [groupToDict(g) for g in flattenList(l)]
45/193: h5Group = configH5Groups[3]
45/194: groupToDict(h5Group, asString = False)
45/195: groupToDict(h5Group, asString = True)
45/196: h5Group
45/197: groupToDict(h5Group, asString = True)
45/198: l = [i.values() for i in f['/EBL/InitData/'].values()]
45/199: d = {}
45/200: d = dict()
45/201: b
45/202: c
45/203: c.update(d)
45/204: c
45/205: d.update(c)
45/206: d
45/207: d.update(c)
45/208: c.update(d)
45/209: [groupToDict(g) for g in flattenList(l)}]
45/210: reload(extractLogInfo)
45/211: extractLogInfo.infoFromInitDatasets()
45/212: whos
45/213: wtf
45/214: extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
45/215: workingDir = '/tmp/pathFittingWorkingFiles-20161219-1457-SHdiKj'
45/216: extractLogInfo.infoFromInitDatasets(workingDir)
45/217: reload(extractLogInfo)
45/218: extractLogInfo.infoFromInitDatasets(workingDir)
45/219: extractLogInfo.infoFromInitDatasets(workingDir)
45/220: reload(extractLogInfo)
45/221: extractLogInfo.infoFromInitDatasets(workingDir)
45/222: logWithConfig = getLogWithLowestIndex(logDir)
45/223: logWithConfig = extractLogInfo.getLogWithLowestIndex(logDir)
45/224: logWithConfig = extractLogInfo.getLogWithLowestIndex(workingDir)
45/225: logWithConfig
45/226: %paste
45/227: %paste
45/228: h5py.File(logWithConfig)
45/229: h5File = h5py.File(logWithConfig)
45/230: initDataGroup = h5File['/EBL/InitData']
45/231: initDataGroup
45/232: [group.values() for group in initDataGroup.values()]
45/233: reload(extractLogInfo)
45/234: extractLogInfo.infoFromInitDatasets(workingDir)
45/235: extractLogInfo.infoFromInitDatasets(workingDir)
45/236: reload(extractLogInfo)
45/237: extractLogInfo.infoFromInitDatasets(workingDir)
45/238: l = [i.values() for i in f['/EBL/InitData/'].values()]
45/239: initDataGroup
45/240: initDataGroup.values
45/241: initDataGroup.values()
45/242: [i.values() for i in initDataGroup.values()]
45/243: flattenList([group.values() for group in initDataGroup.values()])
45/244: reload(extractLogInfo)
45/245: extractLogInfo.infoFromInitDatasets(workingDir)
45/246: reload(extractLogInfo)
45/247: extractLogInfo.infoFromInitDatasets(workingDir)
45/248: info = extractLogInfo.infoFromInitDatasets(workingDir)
45/249: info
45/250: info.keys
45/251: info.keys()
45/252: info['siteId]
45/253: info['siteId']
45/254: info['runtimeAGENT']
45/255: info['runtimeAGENT']
45/256: info['runtimeUSERNAME']
45/257: info['runtimeUsername']
45/258: import sha
45/259: help(sha)
45/260: f
45/261: f.items()
45/262: [groupName(i) for i in f.items()]
45/263: [groupName(i) for i in f.values()]
45/264: {groupName(i) for i in f.values()}
45/265: giveSet = lambda: {1,2}
45/266: {{1,2}, {2,3}}
45/267: a = {1,2}
45/268: type(a)
45/269: a.add({2,3})
45/270: a.update({2,3})
45/271: a
45/272: reload(extractLogInfo)
45/273: extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
45/274: reload(extractLogInfo)
45/275: extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
45/276: type({})
45/277: type(set)
45/278: type(set())
45/279: reload(extractLogInfo)
45/280: extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/1: import extractLogInfo
46/2: extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/3: logInfo = extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/4: logInfo.keys()
46/5: logInfo['configXml']
46/6: logInfo['ConfigXml']
46/7: logInfo['ConfigXml']
46/8: import xml.etree.ElementTree as ET
46/9: root = ET.fromstring()
46/10: configXmlStr = logInfo['ConfigXml']
46/11: root = ET.fromstring(configXmlStr)
46/12: root.findall('/config')
46/13: root.findall('./config')
46/14: root.findall('.')
46/15: print(configXmlStr)
46/16: root.findall('./wheelbase')
46/17: root.findall('./wheelbase').value
46/18: root.find('./wheelbase')
46/19: root.find('./wheelbase').value
46/20: root.find('./wheelbase')
46/21: wbe = root.find('./wheelbase')
46/22: wbe.items
46/23: wbe.text
46/24: float(wbe.text)
46/25: root.getchildren
46/26: root.getchildren()
46/27: wbe.getchildren()
46/28: isLeaf = lambda el : length(l.getchildren) == 0
46/29: isLeaf(wbe)
46/30: a = []
46/31: isLeaf = lambda el : len(l.getchildren) == 0
46/32: isLeaf(wbe)
46/33: isLeaf = lambda el : len(el.getchildren) == 0
46/34: isLeaf(wbe)
46/35: isLeaf = lambda el : len(el.getchildren()) == 0
46/36: isLeaf(wbe)
46/37: root.getchildren()
46/38: filter(root.getchildren(), isLeaf)
46/39: filter(isLeaf, root.getchildren())
46/40: filter(isLeaf, root.getchildren())
46/41: filter(isLeaf, root.getchildren())
46/42:
apply(lambda x : x.text, filter(isLeaf, root.getchildren())
)
46/43: map(lambda x : x.text, filter(isLeaf, root.getchildren()))
46/44: map(lambda x : x:x.text, filter(isLeaf, root.getchildren()))
46/45: map(lambda x : {x:x.text}, filter(isLeaf, root.getchildren()))
46/46: map(lambda x : x.text, filter(isLeaf, root.getchildren()))[0]
46/47: map(lambda x : x.text, filter(isLeaf, root.getchildren()))[0]
46/48: filter(isLeaf, root.getchildren())
46/49: filter(isLeaf, root.getchildren())[0]
46/50: e = filter(isLeaf, root.getchildren())[0]
46/51: e.tag
46/52: map(lambda x : x.tag:x.text, filter(isLeaf, root.getchildren()))
46/53: map(lambda x : {x.tag:x.text}, filter(isLeaf, root.getchildren()))
46/54: print(configXmlStr)
46/55: {'a':{'b':2}}}
46/56: {'a':{'b':2}}
46/57: {'a':n for n in range(5)}
46/58: {n:n for n in range(5)}
46/59: {{n:n} for n in range(5)}
46/60: {{n:n} for n in range(5)}
46/61: {n:n for n in range(5)}
46/62: {n:n for n in range(5)}
46/63: i2kv = lambda i : i,i
46/64: i2kv = lambda i : (i,i)
46/65: map(i2kv, range(5))
46/66: {i:j for i,j in map(i2kv, range(5))}
46/67: i2kv(2)
46/68: {i2kv(2)}
46/69: {i:j for i,j in i2kv(2)}
46/70: root.tag
46/71: import xml.etree.ElementTree as ET
46/72: reload(extractLogInfo)
46/73: reload(extractLogInfo)
46/74: extractLogInfo.configXmlToDict(configXmlStr)
46/75: reload(extractLogInfo)
46/76: extractLogInfo.configXmlToDict(configXmlStr)
46/77: xmlDict = extractLogInfo.configXmlToDict(configXmlStr)
46/78: xmlDict.keys
46/79: xmlDict.keys()
46/80: xmlDict['config'].keys()
46/81: xmlDict['config']['odometry'].keys()
46/82: xmlDict['config']['odometry']
46/83: reload(extractLogInfo)
46/84: extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/85: xmlDict['config'].keys()
46/86: a = {'a':1, 'b':2}
46/87: a
46/88: a.popitem('a')
46/89: a.pop('a')
46/90: a
46/91: xmlDict['config'].keys()
46/92: xmlDict['config']['sp']
46/93: xmlDict['config']['rc']
46/94: xmlDict['config']['sp']
46/95: xmlDict['config']['sp'].keys()
46/96: xmlDict['config']['rc'].keys()
46/97: xmlDict['config'].keys()
46/98: xmlDict['config']['rc'].keys()
46/99: configXmlStr
46/100: print(configXmlStr)
46/101: root.tag
46/102: root.keys()
46/103: root.getchildren()
46/104: root.getchildren()[-3]
46/105: e = root.getchildren()[-3]
46/106: e.attrib
46/107: e.attrib['calibrationField'] == ''Truck Type Code''
46/108: e.attrib['calibrationField'] == 'Truck Type Code'
46/109: root.remove(e)
46/110: root.getchildren()
46/111: e.attrib['calibrationField'] == 'Truck Type Code'
46/112: reload(extractLogInfo)
46/113: extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/114: reload(extractLogInfo)
46/115: extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/116: reload(extractLogInfo)
46/117: extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/118: reload(extractLogInfo)
46/119: extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/120: extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/121: e = extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/122: reload(extractLogInfo)
46/123: e = extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/124: reload(extractLogInfo)
46/125: e = extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/126: root.text
46/127: str(root)
46/128: reload(extractLogInfo)
46/129: e = extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/130: root = ET.fromstring(configXmlStr)
46/131: root.remove(e)
46/132: e = root.getchildren()[-3]
46/133: e
46/134: e.attrib['calibrationField'] == 'Truck Type Code'
46/135: root.remove(e)
46/136: root.remove(e)
46/137: reload(extractLogInfo)
46/138: e.attrib['calibrationField'] == 'Truck Type Code'
46/139: e = extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/140: e.keys()
46/141: e['config'].keys()
46/142: e['config']['tc_agv']
46/143: root.getchildren()
46/144: e = root.getchildren()[-5]
46/145: e
46/146: e = root.getchildren()[-6]
46/147: e
46/148: e = root.getchildren()[-8]
46/149: e
46/150: e.attrib
46/151: e.attrib['calibrationField'] == 'Truck Type Code'
46/152: reload(extractLogInfo)
46/153: e = extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/154: e = extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/155: reload(extractLogInfo)
46/156: e = extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/157: help(e.remove)
46/158: reload(extractLogInfo)
46/159: e = extractLogInfo.extractLogInfo('../logs/penroseLoop.zip')
46/160: e['config'].keys()
49/1: [(i,j,k) for i in range(9) for j in range(9) for k in range(9)]
49/2: allOptions = [(i,j,k) for i in range(9) for j in range(9) for k in range(9)]
49/3: [(i,j,k) for (i,j,k) in allOptions if i == 6 | j == 8 | k == 2]
49/4: [(i,j,k) for (i,j,k) in allOptions if i == 6 or j == 8 or k == 2]
49/5: allOptions = [(i,j,k) for (i,j,k) in allOptions if i == 6 or j == 8 or k == 2]
49/6: allOptions = [(i,j,k) for (i,j,k) in allOptions if i == 6 or j == 8 or k == 2]
49/7:
2 in [1,2,3[
2 in [1,2,3]
]

)
49/8: 2 in [1,2,3]
49/9: 2 in [1,5,3]
49/10: allOptions = [(i,j,k) for (i,j,k) in allOptions if not (i in [7,3,8]  or j in [7,3,8] or k in [7,3,8])]
49/11: allOptions
49/12: len(allOptions)
49/13: allOptions = [(i,j,k) for (i,j,k) in allOptions if (i in [7,8,0]  or j in [7,8,0] or k in [7,8,0])]
49/14: allOptions
49/15: allOptions = [(i,j,k) for (i,j,k) in allOptions if not (i == 7 or j == 8 or k == 0)]
49/16: allOptions
49/17: allOptions = [(i,j,k) for (i,j,k) in allOptions if (i in [6,1,4]  or j in [6,1,4] or k in [6,1,4])]
49/18: allOptions
49/19: allOptions = [(i,j,k) for (i,j,k) in allOptions if not (i == 6 or j == 1 or k == 4)]
49/20: allOptions
49/21: allOptions = [(i,j,k) for (i,j,k) in allOptions if not (i == 2 or j == 0 or k == 6)]
49/22: allOptions
49/23: allOptions = [(i,j,k) for (i,j,k) in allOptions if sum([i == 6, j == 8, k == 2]) == 2]
49/24: allOptions
49/25: allOptions = [(i,j,k) for i in range(9) for j in range(9) for k in range(9)]
49/26: allOptions = [(i,j,k) for (i,j,k) in allOptions if sum([i == 6, j == 8, k == 2]) == 1]
49/27: allOP
49/28: allOptions
49/29: allOptions = [(i,j,k) for (i,j,k) in allOptions if not (i in [7,3,8]  or j in [7,3,8] or k in [7,3,8])]
49/30: allOptions = [(i,j,k) for (i,j,k) in allOptions if (i in [7,8,0]  or j in [7,8,0] or k in [7,8,0])]
49/31: allOptions = [(i,j,k) for (i,j,k) in allOptions if not (i == 7 or j == 8 or k == 0)]
49/32: allOptions = [(i,j,k) for (i,j,k) in allOptions if (i in [6,1,4]  or j in [6,1,4] or k in [6,1,4])]
49/33: allOptions = [(i,j,k) for (i,j,k) in allOptions if not (i == 6 or j == 1 or k == 4)]
49/34: allOptions
50/1: allOptions = [(i,j,k) for i in range(9) for j in range(9) for k in range(9)]
50/2: digits = (6,8,2)
50/3: options = all
50/4: options = allOptions
50/5: [option for option in options if len(set(option) + set(digits)) == 0]
50/6: a = set(digits)
51/1: a = (1,2,3)
51/2: b = (2,3,4)
51/3: a - b
51/4: option = (1,2,3)
51/5: digits = (5,4,3)
51/6: [i==j for i,j in zip(option, digits)]
51/7: sum(i==j for i,j in zip(option, digits))
51/8: a = {1,2,3}
52/1: import stravalib
52/2: stravalib.Client
52/3: help(stravalib.Client)
52/4: client = stravalib.Client()
52/5: client.authorization_url(clientid=11558948, redirect_uri='http://localhost:8282/authorized')
52/6: client.authorization_url(client_id=11558948, redirect_uri='http://localhost:8282/authorized')
52/7: client.authorization_url(client_id=16470, redirect_uri='http://localhost:8282/authorized')
52/8: code = b2f7e66424a49b71db8395318a8d001f1f062698
52/9: code = 'b2f7e66424a49b71db8395318a8d001f1f062698'
52/10: access_token = client.exchange_code_for_token(client_id=1234, client_secret='asdf1234', code=code)
52/11: access_token = client.exchange_code_for_token(client_id=16470, client_secret='a4f496f106aed88671be0de6d296f0834cb46fb3', code=code)
52/12: client.access_token = access_token
52/13: client.get_activities()
52/14: activities = client.get_activities()
52/15: activities(0)
52/16: activities[0]
52/17: a = [activities]
52/18: activities.entity
52/19: activities.entity()
52/20: e  = activities.entity()
52/21: e.distance
52/22: e.distance()
52/23: e  = activities.next
52/24: e  = activities.next()
52/25: activities = client.get_activities()
52/26: len(activities)
52/27: athlete = client.get_athlete()
52/28: athlete
52/29: athlete.weight
52/30: athlete.sex
52/31: activities = client.get_activities()
52/32: activities
52/33: activities()
52/34: a = [a for a in activities]
52/35: a
52/36: activities = [activity for activity in client.get_activities()]
52/37: activities
52/38: activities[0]
52/39: a0 = activities[0]
52/40: a0.distance
52/41: a0.distance.num
52/42: import pandas
52/43: fiveK = [a for a in activities if abs(a-5000) < 200]
52/44: fiveK = [a for a in activities if abs(a.distance.num-5000) < 200]
52/45: len(fiveK)
52/46: len(activities)
52/47: fiveKTime = [a.moving_time for a in fiveK]
52/48: timeFrame = pandas.DataFrame(fiveKTime)
52/49: timeFrame
52/50: timeFrame.plot()
52/51: ls fiveKTime
52/52: fiveKTime[0]
52/53: t0 = fiveKTime[0]
52/54: t0.min
52/55: t0.seconds
52/56: t0.seconds / 600
52/57: t0.seconds / 60
52/58: t0.seconds / 60.
52/59: fiveKTime = [a.moving_time.seconds / 60. for a in fiveK]
52/60: timeFrame = pandas.DataFrame(fiveKTime)
52/61: timeFrame.plot()
52/62: import pylab
52/63: pylab.show()
52/64: fiveKDate = [a.start_date for a in fiveK]
52/65: fiveKDate
52/66: timeFrame = pandas.DataFrame(fiveKDate, fiveKTime)
52/67: timeFrame
52/68: help(pandas.DataFrame)
52/69:
timeFrame = pandas.DataFrame({'date':fiveKDate, 'duration':fiveKTime)
}
52/70: timeFrame = pandas.DataFrame({'date':fiveKDate, 'duration':fiveKTime})
52/71: timeFrame
52/72: help(pylab.plot)
52/73: pylab.plot(timeFrame.date, timeFrame.duration)
52/74: pylab.show()
52/75: help(pylab.plot)
52/76: pylab.plot(timeFrame.date, timeFrame.duration, 'bo')
52/77: pylab.show()
52/78: ls
52/79: %history
52/80: client = stravalib.Client()
53/1: import matplotlib
53/2: surf
53/3: matplotlib.__version__
53/4: import matplotlib.pyplot as plt
53/5: plt.plt
53/6: plt.plot()
53/7: plt.plot([1,2,3,4])
53/8: plt.show()
53/9: fig = plt.figure()
53/10: ax = fig.add_subplot(111, projection='3d')
53/11: ax = fig.add_subplot(111, projection='3D')
54/1: import matplotlib
55/1: import matplotlib
55/2: import matplotlib.pyplot as plt
55/3: fig = plt.figure()
55/4: ax = fig.add_subplot(111, projection='3d')
55/5: from mpl_toolkits.mplot3d import axes3d, Axes3D
55/6: ax = Axes3D(fig) #<-- Note the difference from your original code...
55/7: X, Y, Z = axes3d.get_test_data(0.05)
55/8: cset = ax.contour(X, Y, Z, 16, extend3d=True)
55/9: ax.clabel(cset, fontsize=9, inline=1)
55/10: plt.show()
55/11: X
55/12: Y
55/13: Z
55/14: type(X)
55/15: X.shape
55/16: Z.shape
55/17: X
55/18: %history
56/1: from mpl_toolkits.mplot3d import axes3d, Axes3D
56/2: ax = Axes3D(fig) #<-- Note the difference from your original code...
57/1: import pyplotSurfExample
57/2: X
57/3: from pyplotSurfExample import *
57/4: X
57/5: Z
57/6: Z.shape()
57/7: Z.shape
57/8: Z
57/9: import matplotlib.pyplot as plt
57/10: plt.ion()
57/11: fig = plt.figure()
57/12: from mpl_toolkits.mplot3d import axes3d, Axes3D
57/13: ax = Axes3D(fig) #<-- Note the difference from your original code...
57/14: X, Y, Z = axes3d.get_test_data(0.05)
57/15: cset = ax.contour(X, Y, Z, 16, extend3d=True)
57/16: ax.clabel(cset, fontsize=9, inline=1)
57/17: plt.show()
57/18: plt.show()
57/19: fig = plt.figure()
57/20: ax = Axes3D(fig) #<-- Note the difference from your original code...
57/21: help(ax)
57/22: cset = ax.contour(X, Y, Z)
57/23: cset = ax.contour3D(X, Y, Z)
57/24: cset = ax.contour(X, Y, Z, 16, extend3d=True)
57/25: import pyplotSurfExample2
57/26: from imp import reload
57/27: reload(pyplotSurfExample2)
57/28: import numpy as np
57/29: np.histogram
57/30: help(np.histogram)
57/31: help(np.histogram2d)
57/32: help(np.array)
57/33: np.array([1,2,3])
57/34: np.array([{1},{2,3},{}])
57/35: help(np.array)
57/36: [{} for i in range(5)]
57/37: [[{} for i in range(5)] for i in range(5)]
57/38: m = [[{} for i in range(5)] for i in range(5)]
57/39:
m[0,1
]
57/40: m = np.array([[{} for i in range(5)] for i in range(5)])
57/41: m[0,1]
57/42: s = {}
57/43: s.update(4)
57/44: s.update([1])
57/45: s
57/46: class(s)
57/47: type(s)
57/48: m = np.array([[set() for i in range(5)] for i in range(5)])
57/49: m
57/50: s = set()
57/51: s.update(5)
57/52: s.add(5)
57/53: s
57/54: s.add(5)
57/55: s
57/56: m = np.array([[[] for i in range(5)] for i in range(5)])
57/57: m
57/58: help(np.array)
57/59: type(m)
57/60: m = np.array([[[] for i in range(5)] for i in range(5)], dtype=numpy.ndarray)
57/61: m = np.array([[[] for i in range(5)] for i in range(5)], dtype=np.ndarray)
57/62: m
57/63: m = np.array([[set() for i in range(5)] for i in range(5)])
57/64: m
57/65: help(np.array)
57/66: np.array(ndmin=2)
57/67: m = np.array([[[] for i in range(5)] for i in range(5)], dtype=np.ndarray, ndim=2)
57/68: help(np.array)
57/69: help(np.array)
57/70: import pandas as pd
59/1: 1e1
59/2: e
59/3: import math
59/4: math.e
59/5: 1 * math.e ^ 1
59/6: 1 * math.e ^ 1.
60/1: from visualization_msgs.msg import Marker
60/2: m = Marker
60/3: m
60/4: m.points
60/5: type(m.points)
60/6: type(m.points())
60/7: m = Marker()
60/8: type(m.points)
60/9: from geometry_msgs.msg import Point
60/10: from sensor_msgs.msg import LaserScan
60/11: LaserScan
60/12: s = LaserScan()
60/13: s
60/14: s.ranges = [2,2,3,2]
60/15: len(s.ranges)
60/16: range(-50:12.:50)
60/17: range(-50,12.5,50)
60/18: Point
60/19: help(Point)
60/20: m
60/21: s.header
60/22: Marker.LINE_STRIP
60/23: Marker.ADD
61/1: import urllib2
61/2: response = urllib2.urlopen('http://python.org/')
61/3: html = response.read()
61/4: html
61/5: response = urllib2.urlopen('http://rickandmorty.wikia.com/wiki/Lawnmower_Dog/Transcript')
61/6: html = response.read()
61/7: html
61/8: from bs4 import BeautifulSoup
61/9: soup = BeautifulSoup(html, 'html.parser')
61/10: selector = "#mw-content-text > div.poem"
61/11: soup.select(selector)
61/12: transcript = soup.select(selector)
61/13: transcript
61/14: type(transcript)
61/15: len(transcript)
61/16: transcript = soup.select(selector)[0]
61/17: transcript.prettify
61/18: transcript.prettify()
61/19: print(transcript.prettify())
61/20: transcript.get_text
61/21: print(transcript.get_text)
61/22: %hist
62/1:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/Lawnmower_Dog/Transcript'
selector = "#mw-content-text > div.poem"

#response = urllib2.urlopen(url)
#html = response.read()
#fh = open("response.html","w")
#fh.write(html)
#fh.close()

fh = open("response.html","r")
html = fh.read()
fh.close()

soup = BeautifulSoup(html, 'html.parser')
transcript = soup.select(selector)[0]
text = transcript.get_text()
#print(text)
print(text)
62/2:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/Lawnmower_Dog/Transcript'
selector = "#mw-content-text > div.poem"

#response = urllib2.urlopen(url)
#html = response.read()
#fh = open("response.html","w")
#fh.write(html)
#fh.close()

fh = open("response.html","r")
html = fh.read()
fh.close()

soup = BeautifulSoup(html, 'html.parser')
transcript = soup.select(selector)[0]
text = transcript.get_text()
#print(text)
print(text)
62/3: text.find('(')
62/4: text[text.find('(')]
62/5: text.find('(')
62/6:
text.find('(')
text[0]
62/7: text.find(')')
62/8: help(text.find)
62/9: text[text.find('('):text.find(')')]
62/10: text[text.find('('):text.find(')')+1]
62/11:
text[text.find('('):text.find(')')+1]
text[:[text.find('(')]
62/12:
text[text.find('('):text.find(')')+1]
text[:text.find('(')]
62/13:
text[text.find('('):text.find(')')+1]
text[:text.find('(')] + text[:text.find(')')+1]
62/14:
text[text.find('('):text.find(')')+1]
text[:text.find('(')] + text[text.find(')')+1:]
62/15:
while text.find('(') != -1:
    text = text[:text.find('(')] + text[text.find(')')+1:]
text
62/16:
while text.find('(') != -1:
    text = text[:text.find('(')] + text[text.find(')')+1:]
print(text)
62/17: lines = text.split('\n')
62/18:
lines = text.split('\n')
lines
62/19:
lines = text.split('\n')
lines = [line for line in lines if line is not ""]
lines
62/20:
lines = text.split('\n')
lines = [line for line in lines if line != ""]
lines
62/21:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
text = text.split('\n')

lines = []
prevCharacter = ""
# for line in text:
    
line[2]
62/22:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
text = text.split('\n')

lines = []
prevCharacter = ""
# for line in text:
    
lines[2]
62/23:
soup = BeautifulSoup(html, 'html.parser')
transcript = soup.select(selector)[0]
text = transcript.get_text()
#print(text)
print(text)
62/24:
# remove everything in parentheses 
while text.find('(') != -1:
    text = text[:text.find('(')] + text[text.find(')')+1:]
print(text)
62/25:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

lines = []
prevCharacter = ""
# for line in text:
    
splitText[2]
62/26:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

lines = []
prevCharacter = ""
# for line in text:
    
line = splitText[2]
62/27:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

lines = []
prevCharacter = ""
# for line in text:
    
line = splitText[2]
line.split(":")
62/28:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

lines = []
prevCharacter = ""
# for line in text:
    
line = splitText[2]
"hi there".split(":")
62/29:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

lines = []
prevCharacter = ""
# for line in text:
    
line = splitText[2]
a,b = "hi there".split(":")
62/30:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

lines = []
prevCharacter = ""
# for line in text:
    
line = splitText[2]
"hi there".find(":")
62/31:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

lines = []
prevCharacter = ""
# for line in text:
    
line = splitText[2]
"hi there".find(":")
"hi there"[-1:]
62/32:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

lines = []
prevCharacter = ""
# for line in text:
    
line = splitText[2]
"hi there".find(":")
"hi there"[0:]
62/33:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

lines = []
prevCharacter = ""
# for line in text:
    
line = splitText[2]
"hi there".find(":")
colonIndex = min(line.find(':'),0)

"hi there"[0:]
62/34:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

# for line in text:
    
line = splitText[2]
colonIndex = min(line.find(':'),0)
character = line[0:colonIndex]
speech = line[colonIndex:]
62/35:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

# for line in text:
    
line = splitText[2]
colonIndex = min(line.find(':'),0)
character = line[0:colonIndex]
speech = line[colonIndex:]
(character, speech)
62/36:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

# for line in text:
    
line = splitText[2]
colonIndex = max(line.find(':'),0)
character = line[0:colonIndex]
speech = line[colonIndex:]
(character, speech)
62/37:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

def parseLine(text):
    """
    Split up a line from the script into a dict containing
    the name of the character and the text of what they said
    """

    colonIndex = max(line.find(':'),0)
    line['character'] = line[0:colonIndex]
    line['text'] = line[colonIndex:]
    
lines = [parseLine(line) for line in lines]
# for line in text:

    
line = splitText[2]
colonIndex = max(line.find(':'),0)
character = line[0:colonIndex]
speech = line[colonIndex:]
(character, speech)
62/38:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

def parseLine(text):
    """
    Split up a line from the script into a dict containing
    the name of the character and the text of what they said
    """

    colonIndex = max(line.find(':'),0)
    line['character'] = line[0:colonIndex]
    line['text'] = line[colonIndex:]
    
lines = [parseLine(line) for line in lines]
# for line in text:

    
line = splitText[2]
colonIndex = max(line.find(':'),0)
character = line[0:colonIndex]
speech = line[colonIndex:]
(character, speech)
lines
62/39:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

def parseLine(text):
    """
    Split up a line from the script into a dict containing
    the name of the character and the text of what they said
    """

    colonIndex = max(line.find(':'),0)
    line['character'] = line[0:colonIndex]
    line['text'] = line[colonIndex:]
    
lines = [parseLine(line) for line in splitText]
# for line in text:

    
line = splitText[2]
colonIndex = max(line.find(':'),0)
character = line[0:colonIndex]
speech = line[colonIndex:]
(character, speech)
lines
62/40:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

def parseLine(text):
    """
    Split up a line from the script into a dict containing
    the name of the character and the text of what they said
    """

    colonIndex = max(line.find(':'),0)
    line = dict()
    line['character'] = line[0:colonIndex]
    line['text'] = line[colonIndex:]
    
lines = [parseLine(line) for line in splitText]
# for line in text:

    
line = splitText[2]
colonIndex = max(line.find(':'),0)
character = line[0:colonIndex]
speech = line[colonIndex:]
(character, speech)
lines
62/41:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

def parseLine(text):
    """
    Split up a line from the script into a dict containing
    the name of the character and the text of what they said
    """

    colonIndex = max(text.find(':'),0)
    line = dict()
    line['character'] = text[0:colonIndex]
    line['text'] = text[colonIndex:]
    
lines = [parseLine(line) for line in splitText]
# for line in text:

    
line = splitText[2]
colonIndex = max(line.find(':'),0)
character = line[0:colonIndex]
speech = line[colonIndex:]
(character, speech)
lines
62/42:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

def parseLine(text):
    """
    Split up a line from the script into a dict containing
    the name of the character and the text of what they said
    """

    colonIndex = max(text.find(':'),0)
    line = dict()
    line['character'] = text[0:colonIndex]
    line['text'] = text[colonIndex:]
    return line
    
lines = [parseLine(line) for line in splitText]
# for line in text:

    
line = splitText[2]
colonIndex = max(line.find(':'),0)
character = line[0:colonIndex]
speech = line[colonIndex:]
(character, speech)
lines
62/43:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

def parseLine(text):
    """
    Split up a line from the script into a dict containing
    the name of the character and the text of what they said
    """

    colonIndex = max(text.find(':'),0)
    line = dict()
    line['character'] = text[0:colonIndex]
    line['text'] = text[colonIndex:]
    return line
    
lines = [parseLine(line) for line in splitText]

lines
62/44:
#cleanup - lines with no character name are continuations of the line above.
#Combine these into a single 'line' dict
62/45:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentCharacter = lines[0]['character']
currentText = lines[0]['text']
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
62/46:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    if iChar != currentLine['character'] and iChar != '':
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
    else:
        currentLine['text'].append("\n" + iText)
62/47: t = lines[0]['text']
62/48:
t = lines[0]['text']
t
62/49:
t = lines[0]['text']
t.append
62/50:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    if iChar != currentLine['character'] and iChar != '':
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
    else:
        currentLine['text'] = currentLine['text'] + "\n" + iText
62/51:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    if iChar != currentLine['character'] and iChar != '':
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
    else:
        currentLine['text'] = currentLine['text'] + "\n" + iText
62/52:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    if iChar != currentLine['character'] and iChar != '':
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
    else:
        currentLine['text'] = currentLine['text'] + "\n" + iText

cleanedLines
62/53:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    if iChar != currentLine['character'] and iChar != '':
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
    else:
        currentLine['text'] = currentLine['text'] + iText

cleanedLines
62/54:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    if iChar != currentLine['character'] and iChar != '':
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
    else:
        currentLine['text'] = currentLine['text'] + iText

cleanedLines
62/55: l = 'hi \n htere'
62/56:
l = 'hi \n htere'
l.strip('\n')
62/57:
l = 'hi \n htere'
l.replace('\n', '')
62/58:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []
t.s

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    iText.replace('\n','')
    if iChar != currentLine['character'] and iChar != '':
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
    else:
        currentLine['text'] = currentLine['text'] + iText

cleanedLines
62/59:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    iText.replace('\n','')
    if iChar != currentLine['character'] and iChar != '':
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
    else:
        currentLine['text'] = currentLine['text'] + iText

cleanedLines
62/60:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    iText = iText.replace('\n','')
    if iChar != currentLine['character'] and iChar != '':
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
    else:
        currentLine['text'] = currentLine['text'] + iText

cleanedLines
62/61:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    iText = iText.replace('\n','')
    print(iText)
    if iChar != currentLine['character'] and iChar != '':
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
    else:
        currentLine['text'] = currentLine['text'] + iText

cleanedLines
62/62:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    iText = iText.replace('\n','')
    if iChar != currentLine['character'] and iChar != '':
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
    else:
        currentLine['text'] = currentLine['text'] + iText

cleanedLines
62/63:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
#     iText = iText.replace('\n','')
    if iChar != currentLine['character'] and iChar != '':
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
    else:
        currentLine['text'] = currentLine['text'] + iText

cleanedLines
62/64:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
#     iText = iText.replace('\n','')
    if iChar != currentLine['character'] and iChar != '':
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
    else:
        currentLine['text'] = currentLine['text'] + iText

cleanedLines
62/65:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    if iChar == currentLine['character'] or iChar == '':
        #continuation
        currentLine['text'] = currentLine['text'] + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
    else:
        

cleanedLines
62/66:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    if iChar == currentLine['character'] or iChar == '':
        #continuation
        currentLine['text'] = currentLine['text'] + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
        

cleanedLines
62/67:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    if iChar == currentLine['character'] or iChar == '':
        #continuation
        currentLine['text'] = currentLine['text'] + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
        
if cleanedLines[0]['character'] == '':
    cleanedLines = cleanedLines[1:]

cleanedLines
62/68:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    if iChar == currentLine['character'] or iChar == '':
        #continuation
        currentLine['text'] = currentLine['text'] + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0]['character'] == '':
    cleanedLines = cleanedLines[1:]

cleanedLines
62/69:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    if iChar == currentLine['character'] or iChar == '':
        #continuation
        currentLine['text'] = currentLine['text'] + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0]['character'] == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
62/70:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    if iChar == currentLine['character'] or iChar == '':
        #continuation
        currentLine['text'] = currentLine['text'] + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0]['character'] == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
lines
62/71:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    if iChar == currentLine['character'] or iChar == '':
        #continuation
        currentLine['text'] = currentLine['text'] + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0]['character'] == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print("{c}:{t}".format(c=line['character'], t=line['text']))
62/72:
#format conversion: list of (character,line) pairs. One for each uninterupted block of speech from a single character
splitText = text.split('\n')

def parseLine(text):
    """
    Split up a line from the script into a dict containing
    the name of the character and the text of what they said
    """

    colonIndex = max(text.find(':'),0)
    line = dict()
    line['character'] = text[0:colonIndex]
    line['text'] = text[colonIndex+1:]
    return line
    
lines = [parseLine(line) for line in splitText]

lines
62/73:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i]['character']
    iText = lines[i]['text']
    if iChar == currentLine['character'] or iChar == '':
        #continuation
        currentLine['text'] = currentLine['text'] + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine['character'] = iChar
        currentLine['text'] = iText
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0]['character'] == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print("{c}:{t}".format(c=line['character'], t=line['text']))
62/74:
#format conversion - one long string into a list of 'Line' types
splitText = text.split('\n')

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = max(text.find(':'),0)
    line = Line(
        character = text[0:colonIndex],
        text = text[colonIndex+1:]
    )
    return line
    
lines = [parseLine(line) for line in splitText]

lines
62/75:
#format conversion - one long string into a list of 'Line' types
splitText = text.split('\n')

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return "{c}:{t}".format(c=self.character, t=self.text)

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = max(text.find(':'),0)
    line = Line(
        character = text[0:colonIndex],
        text = text[colonIndex+1:]
    )
    return line
    
lines = [parseLine(line) for line in splitText]

lines
62/76:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine.character = iChar
        currentLine.text = iText
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
62/77:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = Line("", "")
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = dict()
        currentLine.character = iChar
        currentLine.text = iText
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
62/78:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = Line("", "")
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = lines[i]
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
62/79:
# remove everything in parentheses 
while text.find('(') != -1:
    text = text[:text.find('(')] + text[text.find(')')+1:]
print(text)
62/80:
#format conversion - one long string into a list of 'Line' types
splitText = text.split('\n')

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return "{c}:{t}".format(c=self.character, t=self.text)

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    line = Line(
        character = text[0:colonIndex],
        text = text[colonIndex+1:]
    )
    return line
    
lines = [parseLine(line) for line in splitText]

lines
62/81:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = Line("", "")
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = lines[i]
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
62/82:
#format conversion - one long string into a list of 'Line' types
splitText = text.split('\n')

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return "{c}:{t}".format(c=self.character, t=self.text)

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = max(text.find(':'),0)
    line = Line(
        character = text[0:colonIndex],
        text = text[colonIndex+1:]
    )
    return line
    
lines = [parseLine(line) for line in splitText]

lines
62/83:
#format conversion - one long string into a list of 'Line' types
splitText = text.split('\n')

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return "{c}:{t}".format(c=self.character, t=self.text)

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = max(text.find(':'),0)
    line = Line(
        character = text[0:colonIndex],
        text = text[colonIndex:]
    )
    return line
    
lines = [parseLine(line) for line in splitText]

lines
62/84:
#format conversion - one long string into a list of 'Line' types
splitText = text.split('\n')

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return "{c}:{t}".format(c=self.character, t=self.text)

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex],
            text = text[colonIndex:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line
    
lines = [parseLine(line) for line in splitText]

lines
62/85:
#format conversion - one long string into a list of 'Line' types
splitText = text.split('\n')

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return "{c}:{t}".format(c=self.character, t=self.text)

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex],
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line
    
lines = [parseLine(line) for line in splitText]

lines
62/86:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = Line("", "")
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = lines[i]
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
62/87:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = Line("", "")
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + " " + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = lines[i]
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
62/88:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = Line("", "")
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + " " + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = lines[i]
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
62/89:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = Line("", "")
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + " " + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = lines[i]
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
62/90:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = Line[0]
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + " " + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = lines[i]
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
62/91:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = Lines[0]
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + " " + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = lines[i]
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
62/92:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + " " + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = lines[i]
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
62/93:
#format conversion - one long string into a list of 'Line' types
splitText = text.split('\n')

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return "{c}:{t}".format(c=self.character, t=self.text)

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex],
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line
    
lines = [parseLine(line) for line in splitText]

lines
62/94:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + " " + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = lines[i]
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
62/95:
#find out some things
#how many words per line?
#how many charachters?
#how many words by character?
62/96:
#find out some things
#how many words per line?
#how many charachters?
#how many words by character?

wordsPerLine = [len(line.text.split() for line in Lines]
62/97:
#find out some things
#how many words per line?
#how many charachters?
#how many words by character?

wordsPerLine = [len(line.text.split()) for line in Lines]
62/98:
#find out some things
#how many words per line?
#how many charachters?
#how many words by character?

wordsPerLine = [len(line.text.split()) for line in lines]
62/99:
#find out some things
#how many words per line?
#how many charachters?
#how many words by character?

wordsPerLine = [len(line.text.split()) for line in lines]
wordsPerLine
62/100:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordsPerLine = [len(line.text.split()) for line in lines]
characters = set(line.character for line in lines)
wordsPerLine
62/101:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordsPerLine = [len(line.text.split()) for line in lines]
characters = set(line.character for line in lines)
characters
62/102:
#format conversion - one long string into a list of 'Line' types
splitText = text.split('\n')

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return "{c}:{t}".format(c=self.character, t=self.text)

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line
    
lines = [parseLine(line) for line in splitText]

lines
62/103:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + " " + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = lines[i]
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
62/104:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordsPerLine = [len(line.text.split()) for line in lines]
characters = set(line.character for line in lines)
characters
62/105:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
    print(Char + str(wordsByChar))
62/106:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
    print(char + str(wordsByChar))
62/107:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
#     print(char + str(wordsByChar))
rickLines = [line for line in lines if line.character == "Rick"]
rickLines
62/108:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
    print(char + '\t' + str(wordsByChar))
rickLines = [line for line in lines if line.character == "Rick"]
rickLines
62/109:

soup.find("div", {"id": "articlebody"})
62/110:

soup.find("div", {"id": "articlebody"})
62/111:

print(soup.find("div", {"id": "articlebody"}))
62/112:

print(soup.find("div", {"id": "WikiaArticle"}))
62/113:

print(soup.find("div", {"id": "WikiaArticle"}).prettify())
62/114:

print(soup.find("div", {"id": "mw-content-text"}).prettify())
62/115:

divContentText = soup.find("div", {"id": "mw-content-text"})
62/116:

divContentText = soup.find("div", {"id": "mw-content-text"})
divContentText.find('table')
62/117:

divContentText = soup.find("div", {"id": "mw-content-text"})
len(divContentText.find('table'))
62/118:

divContentText = soup.find("div", {"id": "mw-content-text"})
divContentText.find('table')
62/119:

divContentText = soup.find("div", {"id": "mw-content-text"})
divContentText.find('table')
soup.select('#mw-content-text > table:nth-child(2) > tbody > tr > td:nth-child(1) > a')
62/120:

divContentText = soup.find("div", {"id": "mw-content-text"})
divContentText.find('table')
62/121:

divContentText = soup.find("div", {"id": "mw-content-text"})
print(divContentText.find('table').prettify())
62/122:

divContentText = soup.find("div", {"id": "mw-content-text"})
print(divContentText.find('table')[0].prettify())
62/123:

divContentText = soup.find("div", {"id": "mw-content-text"})
print(divContentText.find('table').prettify())
62/124:

divContentText = soup.find("div", {"id": "mw-content-text"})
print(divContentText.find('table').find('td')
62/125:

divContentText = soup.find("div", {"id": "mw-content-text"})
print(divContentText.find('table').find('td'))
62/126:

divContentText = soup.find("div", {"id": "mw-content-text"})
print(divContentText.find('table').find('td').prettify)
62/127:

divContentText = soup.find("div", {"id": "mw-content-text"})
print(divContentText.find('table').find('td').prettify())
62/128:

divContentText = soup.find("div", {"id": "mw-content-text"})
print(divContentText.find('table').find('td')[1].prettify())
62/129:

divContentText = soup.find("div", {"id": "mw-content-text"})
print(len(divContentText.find('table'))
print(divContentText.find('table').find('td')[1].prettify())
62/130:

divContentText = soup.find("div", {"id": "mw-content-text"})
print(len(divContentText.find('table'))
# print(divContentText.find('table').find('td')[1].prettify())
62/131:

divContentText = soup.find("div", {"id": "mw-content-text"})
print(len(divContentText.find('table'))
# print(divContentText.find('table').find('td')[1].prettify())
62/132:

divContentText = soup.find("div", {"id": "mw-content-text"})
print(len(divContentText.find('table'))
      
# print(divContentText.find('table').find('td')[1].prettify())
62/133:

divContentText = soup.find("div", {"id": "mw-content-text"})
print(len(divContentText.find('table')))
      
# print(divContentText.find('table').find('td')[1].prettify())
62/134:

divContentText = soup.find("div", {"id": "mw-content-text"})
linksTable = soup.find("div", {"id": "mw-content-text"}).find('table')
linksTable
62/135:

divContentText = soup.find("div", {"id": "mw-content-text"})
linksTable = soup.find("div", {"id": "mw-content-text"}).find('table')
type(linksTable)
62/136:

divContentText = soup.find("div", {"id": "mw-content-text"})
linksTable = soup.find("div", {"id": "mw-content-text"}).find('table')
pp = lambda x : print(x.prettify())
62/137:

divContentText = soup.find("div", {"id": "mw-content-text"})
linksTable = soup.find("div", {"id": "mw-content-text"}).find('table')
def pp(x) :
    print(x.prettify())
62/138:

divContentText = soup.find("div", {"id": "mw-content-text"})
linksTable = soup.find("div", {"id": "mw-content-text"}).find('table')
def pp(x) :
    print(x.prettify())
pp(linksTable)
62/139:

divContentText = soup.find("div", {"id": "mw-content-text"})
linksTable = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1]
def pp(x) :
    print(x.prettify())
pp(linksTable)
62/140:

divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(linksTable)
62/141:

divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
62/142:

divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
62/143:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path


divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
62/144:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
print firstEpPath.split('/')

divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
62/145:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
print firstEpPath.split('/')[2]

divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
62/146:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
62/147:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2
                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    pass
                                               
                                               
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
62/148:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]
                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    pass
                                               
                                               
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
62/149:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath
                                               

print(getNextEpisodePath(firstEpPath))    
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
62/150:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/The_Real_Animated_Adventures_of_Doc_and_Mharti/Transcript'




selector = "#mw-content-text > div.poem"

#response = urllib2.urlopen(url)
#html = response.read()
#fh = open("response.html","w")
#fh.write(html)
#fh.close()

fh = open("response.html","r")
html = fh.read()
fh.close()
62/151:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/The_Real_Animated_Adventures_of_Doc_and_Mharti/Transcript'




selector = "#mw-content-text > div.poem"

response = urllib2.urlopen(url)
html = response.read()
fh = open("response.html","w")
62/152:
soup = BeautifulSoup(html, 'html.parser')
transcript = soup.select(selector)[0]
text = transcript.get_text()
#print(text)
print(text)
62/153:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/Pilot/Transcript'




selector = "#mw-content-text > div.poem"

response = urllib2.urlopen(url)
html = response.read()
fh = open("response.html","w")
62/154:
soup = BeautifulSoup(html, 'html.parser')
transcript = soup.select(selector)[0]
text = transcript.get_text()
#print(text)
print(text)
62/155:
# remove everything in parentheses
removeBetween = lambda string, startChar, endChar: string[:string.find(startChar] + string[string.find(endChar)+1:]
                                                                       
while text.find('(') != -1:
    text = removeBetween(text, '(', ')')
                                                                       
                                                                    
print(text)
62/156:
# remove everything in parentheses
removeBetween = lambda string, startChar, endChar: string[:string.find(startChar)] + string[string.find(endChar)+1:]
                                                                       
while text.find('(') != -1:
    text = removeBetween(text, '(', ')')
                                                                       
                                                                    
print(text)
62/157:
# remove everything in parentheses
removeBetween = lambda string, startChar, endChar: string[:string.find(startChar)] + string[string.find(endChar)+1:]
                                                                       
while text.find('(') != -1:
    text = removeBetween(text, '(', ')')                                                               

while text.find('[') != -1:
    text = removeBetween(text, '[', ']')
print(text)
62/158:
# remove everything in parentheses
removeBetween = lambda string, startChar, endChar: string[:string.find(startChar)] + string[string[string.find(startChar):].find(endChar)+1:]
                                                                       
while text.find('(') != -1:
    text = removeBetween(text, '(', ')')                                                               

while text.find('[') != -1:
    text = removeBetween(text, '[', ']')

while text.find('*') != -1:
    text = removeBetween(text, '*', '*')
print(text)
62/159:
# remove everything in parentheses
removeBetween = lambda string, startChar, endChar: string[:string.find(startChar)] + string[string[string.find(startChar)+1:].find(endChar)+1:]
                                                                       
while text.find('(') != -1:
    text = removeBetween(text, '(', ')')                                                               

while text.find('[') != -1:
    text = removeBetween(text, '[', ']')

while text.find('*') != -1:
    text = removeBetween(text, '*', '*')
63/1:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/Pilot/Transcript'




selector = "#mw-content-text > div.poem"

response = urllib2.urlopen(url)
html = response.read()
fh = open("response.html","w")
63/2:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything between the first instance of the start character and 
    the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1]
    fromEndChar = fromStartChar[fromStartChar.find(endChar):]
    return toStartChar + fromEndChar
                                                                       
while text.find('(') != -1:
    text = removeBetween(text, '(', ')')                                                               

while text.find('[') != -1:
    text = removeBetween(text, '[', ']')

while text.find('*') != -1:
    text = removeBetween(text, '*', '*')
63/3:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/Pilot/Transcript'




selector = "#mw-content-text > div.poem"

response = urllib2.urlopen(url)
html = response.read()
fh = open("response.html","w")
63/4:
soup = BeautifulSoup(html, 'html.parser')
transcript = soup.select(selector)[0]
text = transcript.get_text()
#print(text)
print(text)
63/5:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything between the first instance of the start character and 
    the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1]
    fromEndChar = fromStartChar[fromStartChar.find(endChar):]
    return toStartChar + fromEndChar
                                                                       
while text.find('(') != -1:
    text = removeBetween(text, '(', ')')                                                               

while text.find('[') != -1:
    text = removeBetween(text, '[', ']')

while text.find('*') != -1:
    text = removeBetween(text, '*', '*')
63/6:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything between the first instance of the start character and 
    the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1]
    fromEndChar = fromStartChar[fromStartChar.find(endChar):]
    return toStartChar + fromEndChar
                                                                       
while text.find('(') != -1:
    text = removeBetween(text, '(', ')')                                                               

while text.find('[') != -1:
    text = removeBetween(text, '[', ']')

while text.find('*') != -1:
    text = removeBetween(text, '*', '*')

print(text)
63/7:
soup = BeautifulSoup(html, 'html.parser')
transcript = soup.select(selector)[0]
text = transcript.get_text()
#print(text)
print(text)
63/8:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything between the first instance of the start character and 
    the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1]
    fromEndChar = fromStartChar[fromStartChar.find(endChar):]
    return toStartChar + fromEndChar
                                                                       
while text.find('(') != -1:
    text = removeBetween(text, '(', ')')                                                               

while text.find('[') != -1:
    text = removeBetween(text, '[', ']')

# while text.find('*') != -1:
#     text = removeBetween(text, '*', '*')

print(text)
63/9:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything between the first instance of the start character and 
    the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar):]
    return toStartChar + fromEndChar
                                                                       
while text.find('(') != -1:
    text = removeBetween(text, '(', ')')                                                               

while text.find('[') != -1:
    text = removeBetween(text, '[', ']')

# while text.find('*') != -1:
#     text = removeBetween(text, '*', '*')

print(text)
63/10:
soup = BeautifulSoup(html, 'html.parser')
transcript = soup.select(selector)[0]
text = transcript.get_text()
#print(text)
print(text)
63/11:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything between the first instance of the start character and 
    the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar):]
    return toStartChar + fromEndChar
                                                                       
while text.find('(') != -1:
    text = removeBetween(text, '(', ')')                                                               

while text.find('[') != -1:
    text = removeBetween(text, '[', ']')

# while text.find('*') != -1:
#     text = removeBetween(text, '*', '*')

print(text)
63/12:
soup = BeautifulSoup(html, 'html.parser')
transcript = soup.select(selector)[0]
text = transcript.get_text()
#print(text)
print(text)
63/13:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything between the first instance of the start character and 
    the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar
                                                                       
while text.find('(') != -1:
    text = removeBetween(text, '(', ')')                                                               

while text.find('[') != -1:
    text = removeBetween(text, '[', ']')

# while text.find('*') != -1:
#     text = removeBetween(text, '*', '*')

print(text)
63/14:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything between the first instance of the start character and 
    the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar
                                                                       
while text.find('(') != -1:
    text = removeBetween(text, '(', ')')                                                               

while text.find('[') != -1:
    text = removeBetween(text, '[', ']')

while text.find('*') != -1:
    text = removeBetween(text, '*', '*')

print(text)
63/15:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while text.find(startChar != -1):
        text = removeBetween(text, startChar, endChar)
    
    return text

text = removeAllBetween(text, '(', ')')
text = removeAllBetween(text, '[', ']')
text = removeAllBetween(text, '*', '*')
    
print(text)
63/16:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar != -1):
        string = removeBetween(string, startChar, endChar)
    
    return text

text = removeAllBetween(text, '(', ')')
text = removeAllBetween(text, '[', ']')
text = removeAllBetween(text, '*', '*')
    
print(text)
63/17:
soup = BeautifulSoup(html, 'html.parser')
transcript = soup.select(selector)[0]
text = transcript.get_text()
#print(text)
print(text)
63/18:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar != -1):
        string = removeBetween(string, startChar, endChar)
    
    return text

text = removeAllBetween(text, '(', ')')
text = removeAllBetween(text, '[', ']')
text = removeAllBetween(text, '*', '*')
    
print(text)
63/19:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)
    
    return text

text = removeAllBetween(text, '(', ')')
text = removeAllBetween(text, '[', ']')
text = removeAllBetween(text, '*', '*')
    
print(text)
63/20:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)
    
    return text

text = removeAllBetween(text, '(', ')')
text = removeAllBetween(text, '[', ']')
text = removeAllBetween(text, '*', '*')
    
print(text)
63/21:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)
    
    return string

text = removeAllBetween(text, '(', ')')
text = removeAllBetween(text, '[', ']')
text = removeAllBetween(text, '*', '*')
    
print(text)
63/22:
#format conversion - one long string into a list of 'Line' types
splitText = text.split('\n')

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return "{c}:{t}".format(c=self.character, t=self.text)

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line
    
lines = [parseLine(line) for line in splitText]

lines
63/23:
#format conversion - one long string into a list of 'Line' types
splitText = text.split('\n')

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}:{t}".format(c=self.character, t=self.text)

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line
    
lines = [parseLine(line) for line in splitText]

lines
63/24:
#format conversion - one long string into a list of 'Line' types
splitText = text.split('\n')

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}:{t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line
    
lines = [parseLine(line) for line in splitText]

lines
63/25:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + " " + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = lines[i]
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
63/26:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



print(getNextEpisodePath(firstEpPath))    
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
63/27:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



print(getNextEpisodePath(firstEpPath))    
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
soup.find(text='Next:')
63/28:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



print(getNextEpisodePath(firstEpPath))    
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
type(soup.find(text='Next:')
63/29:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



print(getNextEpisodePath(firstEpPath))    
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
type(soup.find(text='Next:'))
63/30:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



print(getNextEpisodePath(firstEpPath))    
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
n = soup.find(text='Next:')
63/31:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



print(getNextEpisodePath(firstEpPath))    
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
n = soup.find(text='Next:')
n.parent
63/32:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



print(getNextEpisodePath(firstEpPath))    
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
63/33:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



print(getNextEpisodePath(firstEpPath))    
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.next_sibling
63/34:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



print(getNextEpisodePath(firstEpPath))    
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.next_element
63/35:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



print(getNextEpisodePath(firstEpPath))    
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
n.next_element
63/36:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



print(getNextEpisodePath(firstEpPath))    
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.next_element
63/37:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



print(getNextEpisodePath(firstEpPath))    
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.find_next('a')
63/38:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/The_Rickchurian_Mortydate/Transcript'




selector = "#mw-content-text > div.poem"

response = urllib2.urlopen(url)
html = response.read()
fh = open("response.html","w")
63/39:
soup = BeautifulSoup(html, 'html.parser')
transcript = soup.select(selector)[0]
text = transcript.get_text()
#print(text)
print(text)
63/40:
soup = BeautifulSoup(html, 'html.parser')
transcriptDiv = soup.select(selector)

transcript = soup.select(selector)[0]
text = transcript.get_text()
#print(text)
print(text)
63/41:
soup = BeautifulSoup(html, 'html.parser')
transcriptDiv = soup.select(selector)
print(transcriptDiv)
transcript = soup.select(selector)[0]
text = transcript.get_text()
#print(text)
print(text)
63/42:
soup = BeautifulSoup(html, 'html.parser')
transcriptDiv = soup.select(selector)
if len(transcriptDiv) == 0:
    text = ''
else
    text = transcriptDiv[0].get_text()
    
#print(text)
print(text)
63/43:
soup = BeautifulSoup(html, 'html.parser')
transcriptDiv = soup.select(selector)
if len(transcriptDiv) == 0:
    text = ''
else:
    text = transcriptDiv[0].get_text()
    
#print(text)
print(text)
63/44:
# remove everything in parentheses

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)    
    return string

text = removeAllBetween(text, '(', ')')
text = removeAllBetween(text, '[', ']')
text = removeAllBetween(text, '*', '*')
    
print(text)
63/45:
#format conversion - one long string into a list of 'Line' types
splitText = text.split('\n')

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}:{t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line
    
lines = [parseLine(line) for line in splitText]

lines
63/46:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

cleanedLines = []

currentLine = lines[0]
for i in range(1,len(lines)):
    iChar = lines[i].character
    iText = lines[i].text
    if iChar == currentLine.character or iChar == '':
        #continuation
        currentLine.text = currentLine.text + " " + iText
    else:
        #new character started speaking
        #start a new line
        cleanedLines.append(currentLine)
        currentLine = lines[i]
        
#may end up with an empty character name/text for the first line
#remove this
if cleanedLines[0].character == '':
    cleanedLines = cleanedLines[1:]

lines = cleanedLines
for line in lines:
    print(line)
63/47:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



print(getNextEpisodePath(firstEpPath))    
divContentText = soup.find("div", {"id": "mw-content-text"})
nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
def pp(x) :
    print(x.prettify())
pp(nextLink)
nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.find_next('a')
63/48:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



# print(getNextEpisodePath(firstEpPath))    
# divContentText = soup.find("div", {"id": "mw-content-text"})
# nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
# def pp(x) :
#     print(x.prettify())
# pp(nextLink)
# nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.find_next('a')
63/49:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



# print(getNextEpisodePath(firstEpPath))    
# divContentText = soup.find("div", {"id": "mw-content-text"})
# nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
# def pp(x) :
#     print(x.prettify())
# pp(nextLink)
# nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.find_next_sibling('a')
63/50:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



# print(getNextEpisodePath(firstEpPath))    
# divContentText = soup.find("div", {"id": "mw-content-text"})
# nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
# def pp(x) :
#     print(x.prettify())
# pp(nextLink)
# nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.find_next_sibling('a')
63/51:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



# print(getNextEpisodePath(firstEpPath))    
# divContentText = soup.find("div", {"id": "mw-content-text"})
# nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
# def pp(x) :
#     print(x.prettify())
# pp(nextLink)
# nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.find_next_sibling('a')

nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
63/52:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



# print(getNextEpisodePath(firstEpPath))    
# divContentText = soup.find("div", {"id": "mw-content-text"})
# nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
# def pp(x) :
#     print(x.prettify())
# pp(nextLink)
# nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.find_next_sibling('a')

nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
print(nextLink)
63/53:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/Pilot/Transcript'




selector = "#mw-content-text > div.poem"

response = urllib2.urlopen(url)
html = response.read()
fh = open("response.html","w")
63/54:
soup = BeautifulSoup(html, 'html.parser')
transcriptDiv = soup.select(selector)
if len(transcriptDiv) == 0:
    text = ''
else:
    text = transcriptDiv[0].get_text()
    
#print(text)
print(text)
63/55:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



# print(getNextEpisodePath(firstEpPath))    
# divContentText = soup.find("div", {"id": "mw-content-text"})
# nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
# def pp(x) :
#     print(x.prettify())
# pp(nextLink)
# nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.find_next_sibling('a')

nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
print(nextLink)
if nextLink is None:
    nextPath = None
else:
    nextPath = nextLink
63/56:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



# print(getNextEpisodePath(firstEpPath))    
# divContentText = soup.find("div", {"id": "mw-content-text"})
# nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
# def pp(x) :
#     print(x.prettify())
# pp(nextLink)
# nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.find_next_sibling('a')

nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
print(nextLink)
if nextLink is None:
    nextPath = None
else:
    nextPath = nextLink
print(nextPath)
63/57:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



# print(getNextEpisodePath(firstEpPath))    
# divContentText = soup.find("div", {"id": "mw-content-text"})
# nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
# def pp(x) :
#     print(x.prettify())
# pp(nextLink)
# nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.find_next_sibling('a')

nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
print(nextLink)
if nextLink is None:
    nextPath = None
else:
    nextPath = nextLink[0]
print(nextPath)
63/58:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



# print(getNextEpisodePath(firstEpPath))    
# divContentText = soup.find("div", {"id": "mw-content-text"})
# nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
# def pp(x) :
#     print(x.prettify())
# pp(nextLink)
# nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.find_next_sibling('a')

nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
print(nextLink)
if nextLink is None:
    nextPath = None
else:
    nextPath = nextLink[0]
print(nextLink.text)
63/59:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



# print(getNextEpisodePath(firstEpPath))    
# divContentText = soup.find("div", {"id": "mw-content-text"})
# nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
# def pp(x) :
#     print(x.prettify())
# pp(nextLink)
# nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.find_next_sibling('a')

nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
print(nextLink)
if nextLink is None:
    nextPath = None
else:
    nextPath = nextLink
print(nextLink.text)
63/60:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextEpPath = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
    
    return nextEpPath



# print(getNextEpisodePath(firstEpPath))    
# divContentText = soup.find("div", {"id": "mw-content-text"})
# nextLink = soup.find("div", {"id": "mw-content-text"}).find_all('table')[1].find_all('a')[1]
# def pp(x) :
#     print(x.prettify())
# pp(nextLink)
# nextLink.attrs['href']
n = soup.find(text='Next:')
p = n.parent
p.find_next_sibling('a')

nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
print(nextLink)
if nextLink is None:
    nextPath = None
else:
    nextPath = nextLink.attrs['href']
print(nextPath)
63/61:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
    if nextLink is None:
        nextPath = None
    else:
        nextPath = nextLink.attrs['href']
    
    return nextPath



# print(getNextEpisodePath(firstEpPath))
63/62:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
    if nextLink is None:
        nextPath = None
    else:
        nextPath = nextLink.attrs['href']
    
    return nextPath



print(getNextEpisodePath(firstEpPath))
63/63:
#change of tack - get links for all episodes:
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
makeUrl = lambda path : baseUrl + path
getEpisodeName = lambda path : path.split('/')[2]

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
    if nextLink is None:
        nextPath = None
    else:
        nextPath = nextLink.attrs['href']
    
    return nextPath


nextPath = getNextEpisodePath(firstEpPath)
while nextPath is not None:
    print(nextPath)
    nextPath = getNextEpisodePath(nextPath)
63/64:
soup = BeautifulSoup(html, 'html.parser')

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """
    transcriptDiv = soup.select(selector)
    if len(transcriptDiv) == 0:
        text = ''
    else:
        text = transcriptDiv[0].get_text()
    
    return text
    
#print(text)
print(text)
63/65:
soup = BeautifulSoup(html, 'html.parser')

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """
    transcriptDiv = soup.select(selector)
    if len(transcriptDiv) == 0:
        text = ''
    else:
        text = transcriptDiv[0].get_text()
    
    return text
    
text = getTranscriptText(soup)
print(text)
63/66:
# remove actions - everything the transcript which is not speech
# actions seem to be indicated by parentheses or asterixis

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)    
    return string

def removeActions(text):
    """
    remove actions - everything the transcript which is not speech.
    Actions seem to be indicated by parentheses or asterixis
    """
    text = removeAllBetween(text, '(', ')')
    text = removeAllBetween(text, '[', ']')
    text = removeAllBetween(text, '*', '*')
    
text = removeActions(text)
print(text)
63/67:
#format conversion - one long string into a list of 'Line' types


class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}:{t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line

def textToLines(text):
    """
    
    """
    splitText = text.split('\n')    
    lines = [parseLine(line) for line in splitText]
    return lines

lines = textToLines(text)
lines
63/68:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/Pilot/Transcript'




selector = "#mw-content-text > div.poem"

response = urllib2.urlopen(url)
html = response.read()
fh = open("response.html","w")
63/69:
soup = BeautifulSoup(html, 'html.parser')

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """
    transcriptDiv = soup.select(selector)
    if len(transcriptDiv) == 0:
        text = ''
    else:
        text = transcriptDiv[0].get_text()
    
    return text
    
text = getTranscriptText(soup)
print(text)
63/70:
# remove actions - everything the transcript which is not speech
# actions seem to be indicated by parentheses or asterixis

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)    
    return string

def removeActions(text):
    """
    remove actions - everything the transcript which is not speech.
    Actions seem to be indicated by parentheses or asterixis
    """
    text = removeAllBetween(text, '(', ')')
    text = removeAllBetween(text, '[', ']')
    text = removeAllBetween(text, '*', '*')
    
text = removeActions(text)
print(text)
63/71:
# remove actions - everything the transcript which is not speech
# actions seem to be indicated by parentheses or asterixis

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)    
    return string

def removeActions(text):
    """
    remove actions - everything the transcript which is not speech.
    Actions seem to be indicated by parentheses or asterixis
    """
    text = removeAllBetween(text, '(', ')')
    text = removeAllBetween(text, '[', ']')
    text = removeAllBetween(text, '*', '*')
    return text
    
text = removeActions(text)
print(text)
63/72:
soup = BeautifulSoup(html, 'html.parser')

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """
    transcriptDiv = soup.select(selector)
    if len(transcriptDiv) == 0:
        text = ''
    else:
        text = transcriptDiv[0].get_text()
    
    return text
    
text = getTranscriptText(soup)
print(text)
63/73:
# remove actions - everything the transcript which is not speech
# actions seem to be indicated by parentheses or asterixis

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)    
    return string

def removeActions(text):
    """
    remove actions - everything the transcript which is not speech.
    Actions seem to be indicated by parentheses or asterixis
    """
    text = removeAllBetween(text, '(', ')')
    text = removeAllBetween(text, '[', ']')
    text = removeAllBetween(text, '*', '*')
    return text
    
text = removeActions(text)
print(text)
63/74:
#format conversion - one long string into a list of 'Line' types


class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}:{t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line

def textToLines(text):
    """
    
    """
    splitText = text.split('\n')    
    lines = [parseLine(line) for line in splitText]
    return lines

lines = textToLines(text)
lines
63/75:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

def mergeLineContinuations(lines):
    """
    cleanup - combine continuations (new lines where the same character is speaking)
    into single lines
    """
    cleanedLines = []

    currentLine = lines[0]
    for i in range(1,len(lines)):
        iChar = lines[i].character
        iText = lines[i].text
        if iChar == currentLine.character or iChar == '':
            #continuation
            currentLine.text = currentLine.text + " " + iText
        else:
            #new character started speaking
            #start a new line
            cleanedLines.append(currentLine)
            currentLine = lines[i]
        
    #may end up with an empty character name/text for the first line
    #remove this
    if cleanedLines[0].character == '':
        cleanedLines = cleanedLines[1:]
    
    return cleanedLines

lines = mergeLineContinuations(lines)
for line in lines:
    print(line)
63/76:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/Pilot/Transcript'

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

soup = getSoup(url)
print(soup)
63/77:


def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """
    selector = "#mw-content-text > div.poem"
    transcriptDiv = soup.select(selector)
    if len(transcriptDiv) == 0:
        text = ''
    else:
        text = transcriptDiv[0].get_text()
    
    return text
    
text = getTranscriptText(soup)
print(text)
63/78:
# combine the above steps into a single function

makeUrl = lambda path : baseUrl + path

def extractTranscript(path):
    """
    Given an epdisode path (e.g. '/wiki/Pilot/Transcript')
    return the parsed transcript (a list of lines)
    """
    url = makeUrl(path)
    text = getTranscriptText(soup)
    text = removeActions(text)
    lines = textToLines(text)
    lines = mergeLineContinuations(lines)

#test on pilot
print(extractTranscript'/wiki/Pilot/Transcript')
63/79:
# combine the above steps into a single function

makeUrl = lambda path : baseUrl + path

def extractTranscript(path):
    """
    Given an epdisode path (e.g. '/wiki/Pilot/Transcript')
    return the parsed transcript (a list of lines)
    """
    url = makeUrl(path)
    text = getTranscriptText(soup)
    text = removeActions(text)
    lines = textToLines(text)
    lines = mergeLineContinuations(lines)

#test on pilot
print(extractTranscript('/wiki/Pilot/Transcript'))
63/80:
# combine the above steps into a single function

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

def extractTranscript(path):
    """
    Given an epdisode path (e.g. '/wiki/Pilot/Transcript')
    return the parsed transcript (a list of lines)
    """
    url = makeUrl(path)
    text = getTranscriptText(soup)
    text = removeActions(text)
    lines = textToLines(text)
    lines = mergeLineContinuations(lines)

#test on pilot
print(extractTranscript('/wiki/Pilot/Transcript'))
63/81:
# combine the above steps into a single function

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

def extractTranscript(path):
    """
    Given an epdisode path (e.g. '/wiki/Pilot/Transcript')
    return the parsed transcript (a list of lines)
    """
    url = makeUrl(path)
    soup = getSoup(url)
    text = getTranscriptText(soup)
    text = removeActions(text)
    lines = textToLines(text)
    lines = mergeLineContinuations(lines)

#test on pilot
print(extractTranscript('/wiki/Pilot/Transcript'))
63/82:
# combine the above steps into a single function

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

def extractTranscript(path):
    """
    Given an epdisode path (e.g. '/wiki/Pilot/Transcript')
    return the parsed transcript (a list of lines)
    """
    url = makeUrl(path)
    soup = getSoup(url)
    print(sout)
    text = getTranscriptText(soup)
    text = removeActions(text)
    lines = textToLines(text)
    lines = mergeLineContinuations(lines)

#test on pilot
print(extractTranscript('/wiki/Pilot/Transcript'))
63/83:
# combine the above steps into a single function

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

def extractTranscript(path):
    """
    Given an epdisode path (e.g. '/wiki/Pilot/Transcript')
    return the parsed transcript (a list of lines)
    """
    url = makeUrl(path)
    soup = getSoup(url)
    print(soup)
    text = getTranscriptText(soup)
    text = removeActions(text)
    lines = textToLines(text)
    lines = mergeLineContinuations(lines)

#test on pilot
print(extractTranscript('/wiki/Pilot/Transcript'))
63/84:
# combine the above steps into a single function

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

def extractTranscript(path):
    """
    Given an epdisode path (e.g. '/wiki/Pilot/Transcript')
    return the parsed transcript (a list of lines)
    """
    url = makeUrl(path)
    soup = getSoup(url)
    text = getTranscriptText(soup)
    print(text)
    text = removeActions(text)
    lines = textToLines(text)
    lines = mergeLineContinuations(lines)

#test on pilot
print(extractTranscript('/wiki/Pilot/Transcript'))
63/85:
# combine the above steps into a single function

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

def extractTranscript(path):
    """
    Given an epdisode path (e.g. '/wiki/Pilot/Transcript')
    return the parsed transcript (a list of lines)
    """
    url = makeUrl(path)
    soup = getSoup(url)
    text = getTranscriptText(soup)
    text = removeActions(text)
    lines = textToLines(text)
    lines = mergeLineContinuations(lines)
    return lines

#test on pilot
print(extractTranscript('/wiki/Pilot/Transcript'))
63/86:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
    print(char + '\t' + str(wordsByChar))
rickLines = [line for line in lines if line.character == "Rick"]
rickLines

titleSelector = '#PageHeader > div.page-header__main > h1'
title = soup.select(titleSelector)
title
63/87:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
#     print(char + '\t' + str(wordsByChar))
rickLines = [line for line in lines if line.character == "Rick"]
rickLines

titleSelector = '#PageHeader > div.page-header__main > h1'
title = soup.select(titleSelector)
title
63/88:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
#     print(char + '\t' + str(wordsByChar))
rickLines = [line for line in lines if line.character == "Rick"]
rickLines

titleSelector = '#PageHeader > div.page-header__main > h1'
title = soup.select(titleSelector)
title.text
63/89:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
#     print(char + '\t' + str(wordsByChar))
rickLines = [line for line in lines if line.character == "Rick"]
rickLines

titleSelector = '#PageHeader > div.page-header__main > h1'
title = soup.select(titleSelector)[0]
title.text
63/90:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
#     print(char + '\t' + str(wordsByChar))
rickLines = [line for line in lines if line.character == "Rick"]
rickLines

def extractTitle(soup):
    """
    Retrieves episode title from soup
    """
    titleSelector = '#PageHeader > div.page-header__main > h1'
    title = soup.select(titleSelector)[0]
    return title.text
63/91:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
#     print(char + '\t' + str(wordsByChar))
rickLines = [line for line in lines if line.character == "Rick"]
rickLines

def extractTitle(soup):
    """
    Retrieves episode title from soup
    """
    titleSelector = '#PageHeader > div.page-header__main > h1'
    title = soup.select(titleSelector)[0]
    return title.text

extractTitle(soup)
63/92:
# combine the above steps into a single function

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

class EpisodeInfo:
    """
    Container for episode data/metadata, including
    full transcript.
    Information on the episode is retrieved from the
    web on construction
    """
    
    def __init__(self, index path):
        """
        Construct with an index (sequence number in the
        series - pilot = index o) and a path from which
        to retrieve info about the episode
        """
        url = makeUrl(path)
        soup = getSoup(url)
        text = getTranscriptText(soup)
        text = removeActions(text)
        lines = textToLines(text)
        lines = mergeLineContinuations(lines)
        
        title = extractTitle(soup)
        
        self.transcriptUrl = url
        self.transcript = lines
        self.title = title

#test on pilot
print(EpisodeInfo(0,'/wiki/Pilot/Transcript'))
63/93:
# combine the above steps into a single function

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

class EpisodeInfo:
    """
    Container for episode data/metadata, including
    full transcript.
    Information on the episode is retrieved from the
    web on construction
    """
    
    def __init__(self, index, path):
        """
        Construct with an index (sequence number in the
        series - pilot = index o) and a path from which
        to retrieve info about the episode
        """
        url = makeUrl(path)
        soup = getSoup(url)
        text = getTranscriptText(soup)
        text = removeActions(text)
        lines = textToLines(text)
        lines = mergeLineContinuations(lines)
        
        title = extractTitle(soup)
        
        self.transcriptUrl = url
        self.transcript = lines
        self.title = title

#test on pilot
print(EpisodeInfo(0,'/wiki/Pilot/Transcript'))
63/94:
# combine the above steps into a single function

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

class EpisodeInfo:
    """
    Container for episode data/metadata, including
    full transcript.
    Information on the episode is retrieved from the
    web on construction
    """
    
    def __init__(self, index, path):
        """
        Construct with an index (sequence number in the
        series - pilot = index o) and a path from which
        to retrieve info about the episode
        """
        url = makeUrl(path)
        soup = getSoup(url)
        text = getTranscriptText(soup)
        text = removeActions(text)
        lines = textToLines(text)
        lines = mergeLineContinuations(lines)
        
        title = extractTitle(soup)
        
        self.transcriptUrl = url
        self.transcript = lines
        self.title = title
    
    def __repr__(self):
        return self.title

#test on pilot
print(EpisodeInfo(0,'/wiki/Pilot/Transcript'))
63/95:
# combine the above steps into a single function

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

class EpisodeInfo:
    """
    Container for episode data/metadata, including
    full transcript.
    Information on the episode is retrieved from the
    web on construction
    """
    
    def __init__(self, index, path):
        """
        Construct with an index (sequence number in the
        series - pilot = index o) and a path from which
        to retrieve info about the episode
        """
        url = makeUrl(path)
        soup = getSoup(url)
        text = getTranscriptText(soup)
        text = removeActions(text)
        lines = textToLines(text)
        lines = mergeLineContinuations(lines)
        
        title = extractTitle(soup)
        
        self.transcriptUrl = url
        self.transcript = lines
        self.title = title
    
    def __repr__(self):
        return "Episode {n}: {t}".format(n=self.index, t=self.title)

#test on pilot
print(EpisodeInfo(0,'/wiki/Pilot/Transcript'))
63/96:
# combine the above steps into a single function

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

class EpisodeInfo:
    """
    Container for episode data/metadata, including
    full transcript.
    Information on the episode is retrieved from the
    web on construction
    """
    
    def __init__(self, index, path):
        """
        Construct with an index (sequence number in the
        series - pilot = index o) and a path from which
        to retrieve info about the episode
        """
        url = makeUrl(path)
        soup = getSoup(url)
        text = getTranscriptText(soup)
        text = removeActions(text)
        lines = textToLines(text)
        lines = mergeLineContinuations(lines)
        
        title = extractTitle(soup)
        
        self.index = index
        self.transcriptUrl = url
        self.transcript = lines
        self.title = title
    
    def __repr__(self):
        return "Episode {n}: {t}".format(n=self.index, t=self.title)

#test on pilot
print(EpisodeInfo(0,'/wiki/Pilot/Transcript'))
63/97:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
#     print(char + '\t' + str(wordsByChar))
rickLines = [line for line in lines if line.character == "Rick"]
rickLines

def extractTitle(soup):
    """
    Retrieves episode title from soup
    """
    titleSelector = '#PageHeader > div.page-header__main > h1'
    header = soup.select(titleSelector)[0]
    #Headers are of the form '{title}/Transcript' as we are viewing
    #the transcript page. Extract just the title
    title = header.text.split('/')[0]
    return title

extractTitle(soup)
63/98:
# combine the above steps into a single function

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

class EpisodeInfo:
    """
    Container for episode data/metadata, including
    full transcript.
    Information on the episode is retrieved from the
    web on construction
    """
    
    def __init__(self, index, path):
        """
        Construct with an index (sequence number in the
        series - pilot = index o) and a path from which
        to retrieve info about the episode
        """
        url = makeUrl(path)
        soup = getSoup(url)
        text = getTranscriptText(soup)
        text = removeActions(text)
        lines = textToLines(text)
        lines = mergeLineContinuations(lines)
        
        title = extractTitle(soup)
        
        self.index = index
        self.transcriptUrl = url
        self.transcript = lines
        self.title = title
    
    def __repr__(self):
        return "Episode {n}: {t}".format(n=self.index, t=self.title)

#test on pilot
print(EpisodeInfo(0,'/wiki/Pilot/Transcript'))
63/99:
#get info for all Episodes
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
    if nextLink is None:
        nextPath = None
    else:
        nextPath = nextLink.attrs['href']
    
    return nextPath

episodes = []
index = 0
nextPath = getNextEpisodePath(firstEpPath)
while nextPath is not None:
    print(nextPath)
    episodes.append(EpisodeInfo(index, nextPath))
    nextPath = getNextEpisodePath(nextPath)
    index = index + 1
63/100:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/Anatomy_Park_(episode)/Transcript'

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

soup = getSoup(url)
print(soup)
63/101:
# remove actions - everything the transcript which is not speech
# actions seem to be indicated by parentheses or asterixis

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)    
    return string

def removeActions(text):
    """
    remove actions - everything the transcript which is not speech.
    Actions seem to be indicated by parentheses or asterixis
    """
    text = removeAllBetween(text, '(', ')')
    text = removeAllBetween(text, '[', ']')
    text = removeAllBetween(text, '*', '*')
    return text
    
text = removeActions(text)
print(text)
63/102:
#format conversion - one long string into a list of 'Line' types


class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}:{t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line

def textToLines(text):
    """
    
    """
    splitText = text.split('\n')    
    lines = [parseLine(line) for line in splitText]
    return lines

lines = textToLines(text)
lines
63/103:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

def mergeLineContinuations(lines):
    """
    cleanup - combine continuations (new lines where the same character is speaking)
    into single lines
    """
    cleanedLines = []

    currentLine = lines[0]
    for i in range(1,len(lines)):
        iChar = lines[i].character
        iText = lines[i].text
        if iChar == currentLine.character or iChar == '':
            #continuation
            currentLine.text = currentLine.text + " " + iText
        else:
            #new character started speaking
            #start a new line
            cleanedLines.append(currentLine)
            currentLine = lines[i]
        
    #may end up with an empty character name/text for the first line
    #remove this
    if cleanedLines[0].character == '':
        cleanedLines = cleanedLines[1:]
    
    return cleanedLines

lines = mergeLineContinuations(lines)
for line in lines:
    print(line)
64/1:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/Anatomy_Park_(episode)/Transcript'

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

soup = getSoup(url)
print(soup)
64/2:


def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """
    selector = "#mw-content-text > div.poem"
    transcriptDiv = soup.select(selector)
    if len(transcriptDiv) == 0:
        text = ''
    else:
        text = transcriptDiv[0].get_text()
    
    return text
    
text = getTranscriptText(soup)
print(text)
64/3:
# remove actions - everything the transcript which is not speech
# actions seem to be indicated by parentheses or asterixis

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)    
    return string

def removeActions(text):
    """
    remove actions - everything the transcript which is not speech.
    Actions seem to be indicated by parentheses or asterixis
    """
    text = removeAllBetween(text, '(', ')')
    text = removeAllBetween(text, '[', ']')
    text = removeAllBetween(text, '*', '*')
    return text
    
text = removeActions(text)
print(text)
64/4:
#format conversion - one long string into a list of 'Line' types


class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}:{t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line

def textToLines(text):
    """
    
    """
    splitText = text.split('\n')    
    lines = [parseLine(line) for line in splitText]
    return lines

lines = textToLines(text)
lines
64/5:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

def mergeLineContinuations(lines):
    """
    cleanup - combine continuations (new lines where the same character is speaking)
    into single lines
    """
    cleanedLines = []

    currentLine = lines[0]
    for i in range(1,len(lines)):
        iChar = lines[i].character
        iText = lines[i].text
        if iChar == currentLine.character or iChar == '':
            #continuation
            currentLine.text = currentLine.text + " " + iText
        else:
            #new character started speaking
            #start a new line
            cleanedLines.append(currentLine)
            currentLine = lines[i]
        
    #may end up with an empty character name/text for the first line
    #remove this
    if cleanedLines[0].character == '':
        cleanedLines = cleanedLines[1:]
    
    return cleanedLines

lines = mergeLineContinuations(lines)
for line in lines:
    print(line)
64/6:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    
text = getTranscriptText(soup)
print(text)
64/7:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)
    
text = getTranscriptText(soup)
print(text)
64/8:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)
    print(transcriptHeader)
    
text = getTranscriptText(soup)
print(text)
64/9:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)
    print(transcriptHeader)
    
text = getTranscriptText(soup)
    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)
    print(transcriptHeader)
print(text)
64/10:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)
    print(transcriptHeader)
    
text = getTranscriptText(soup)
headSelector = '#Transcript'
transcriptHeader = soup.select(headSelector)
print(transcriptHeader)
print(text)
64/11:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)
    print(transcriptHeader)
    
text = getTranscriptText(soup)
headSelector = '#Transcript'
transcriptHeader = soup.select(headSelector)[0]
print(transcriptHeader.)
print(text)
64/12:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)
    print(transcriptHeader)
    
text = getTranscriptText(soup)
headSelector = '#Transcript'
transcriptHeader = soup.select(headSelector)[0]
print(transcriptHeader)
print(text)
64/13:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
headSelector = '#Transcript'
transcriptHeader = soup.select(headSelector)[0]
print(transcriptHeader.)
print(text)
64/14:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
headSelector = '#Transcript'
transcriptHeader = soup.select(headSelector)[0]
print(transcriptHeader.fetchNextSiblings())
print(text)
64/15:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
headSelector = '#Transcript'
transcriptHeader = soup.select(headSelector)[0]
print(transcriptHeader.fetchNextSiblings
print(text)
64/16:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
headSelector = '#Transcript'
transcriptHeader = soup.select(headSelector)[0]
print(transcriptHeader.fetchNextSiblings)
print(text)
64/17:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
headSelector = '#Transcript'
transcriptHeader = soup.select(headSelector)[0]
print(transcriptHeader.fetchNextSiblings())
print(text)
64/18:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
headSelector = '#Transcript'
transcriptHeader = soup.select(headSelector)[0]
print(transcriptHeader.parent.fetchNextSiblings())
print(text)
64/19:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
headSelector = '#Transcript'
transcriptHeader = soup.select(headSelector)[0]
print(transcriptHeader.parent.fetchNextSiblings().prettify())
print(text)
64/20:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
headSelector = '#Transcript'
transcriptHeader = soup.select(headSelector)[0]
print(transcriptHeader.parent.fetchNextSiblings()[-1].prettify())
print(text)
64/21:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
headSelector = '#Transcript'
transcriptHeader = soup.select(headSelector)[0]
print(transcriptHeader.parent.fetchNextSiblings())
print(text)
64/22:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
headSelector = '#Transcript'
transcriptHeader = soup.select(headSelector)[0]
print(transcriptHeader.parent.find_all('p')
print(text)
64/23:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
headSelector = '#Transcript'
transcriptHeader = soup.select(headSelector)[0]
print(transcriptHeader.parent.find_all('p'))
print(text)
64/24:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
content = '#mw-content-text'
transcriptContent = soup.select(content)[0]
print(transcriptContent.find_all('p'))
print(text)
64/25:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
content = '#mw-content-text'
transcriptContent = soup.select(content)[0]
paragraphs = transcriptContent.find_all('p')
print(transcriptContent.find_all('p'))
print(text)
64/26:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
content = '#mw-content-text'
transcriptContent = soup.select(content)[0]
paragraphs = transcriptContent.find_all('p')
text = '\n'.join([p.text for p in paragraphs])
print(transcriptContent.find_all('p'))
print(text)
64/27:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
content = '#mw-content-text'
transcriptContent = soup.select(content)[0]
paragraphs = transcriptContent.find_all('p')
text = '\n'.join([p.text for p in paragraphs])
# print(transcriptContent.find_all('p'))
print(text)
64/28:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    
    approach: find the transcript div, and
    assume all paragraph tags inside comprise
    the transcript text
    """

    headSelector = '#Transcript'
    transcriptHeader = soup.select(headSelector)[0]
    print(transcriptHeader)
    
text = getTranscriptText(soup)
content = '#mw-content-text'
transcriptContent = soup.select(content)[0]
paragraphs = transcriptContent.find_all('p')
text = '\n'.join([p.text for p in paragraphs])
# print(transcriptContent.find_all('p'))
print(text)
64/29:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    
    approach: find the transcript div, and
    assume all paragraph tags inside comprise
    the transcript text
    """

    contentSelector = '#mw-content-text'
    transcriptContent = soup.select(contentSelector)[0]
    paragraphs = transcriptContent.find_all('p')
    text = '\n'.join([p.text for p in paragraphs])
    return text
    
text = getTranscriptText(soup)
content = '#mw-content-text'
transcriptContent = soup.select(content)[0]
paragraphs = transcriptContent.find_all('p')
text = '\n'.join([p.text for p in paragraphs])
# print(transcriptContent.find_all('p'))
print(text)
64/30:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    
    approach: find the transcript div, and
    assume all paragraph tags inside comprise
    the transcript text
    """

    contentSelector = '#mw-content-text'
    transcriptContent = soup.select(contentSelector)[0]
    paragraphs = transcriptContent.find_all('p')
    text = '\n'.join([p.text for p in paragraphs])
    return text
    
text = getTranscriptText(soup)
print(text)
64/31:
# remove actions - everything the transcript which is not speech
# actions seem to be indicated by parentheses or asterixis

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)    
    return string

def removeActions(text):
    """
    remove actions - everything the transcript which is not speech.
    Actions seem to be indicated by parentheses or asterixis
    """
    text = removeAllBetween(text, '(', ')')
    text = removeAllBetween(text, '[', ']')
    text = removeAllBetween(text, '*', '*')
    return text
    
text = removeActions(text)
print(text)
64/32:
#format conversion - one long string into a list of 'Line' types


class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}:{t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line

def textToLines(text):
    """
    
    """
    splitText = text.split('\n')    
    lines = [parseLine(line) for line in splitText]
    return lines

lines = textToLines(text)
lines
64/33:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    
    approach: find the transcript div, and
    assume all paragraph tags inside comprise
    the transcript text
    """

    contentSelector = '#mw-content-text'
    transcriptContent = soup.select(contentSelector)[0]
    paragraphs = transcriptContent.find_all('p')
    text = ''.join([p.text for p in paragraphs])
    return text
    
text = getTranscriptText(soup)
print(text)
64/34:
# remove actions - everything the transcript which is not speech
# actions seem to be indicated by parentheses or asterixis

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)    
    return string

def removeActions(text):
    """
    remove actions - everything the transcript which is not speech.
    Actions seem to be indicated by parentheses or asterixis
    """
    text = removeAllBetween(text, '(', ')')
    text = removeAllBetween(text, '[', ']')
    text = removeAllBetween(text, '*', '*')
    return text
    
text = removeActions(text)
print(text)
64/35:
#format conversion - one long string into a list of 'Line' types


class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}:{t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line

def textToLines(text):
    """
    
    """
    splitText = text.split('\n')    
    lines = [parseLine(line) for line in splitText]
    return lines

lines = textToLines(text)
lines
64/36:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

def mergeLineContinuations(lines):
    """
    cleanup - combine continuations (new lines where the same character is speaking)
    into single lines
    """
    cleanedLines = []

    currentLine = lines[0]
    for i in range(1,len(lines)):
        iChar = lines[i].character
        iText = lines[i].text
        if iChar == currentLine.character or iChar == '':
            #continuation
            currentLine.text = currentLine.text + " " + iText
        else:
            #new character started speaking
            #start a new line
            cleanedLines.append(currentLine)
            currentLine = lines[i]
        
    #may end up with an empty character name/text for the first line
    #remove this
    if cleanedLines[0].character == '':
        cleanedLines = cleanedLines[1:]
    
    return cleanedLines

lines = mergeLineContinuations(lines)
for line in lines:
    print(line)
64/37:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

def mergeLineContinuations(lines):
    """
    cleanup - combine continuations (new lines where the same character is speaking)
    into single lines
    """
    cleanedLines = []

    currentLine = lines[0]
    for i in range(1,len(lines)):
        iChar = lines[i].character
        iText = lines[i].text
        if iChar == currentLine.character or iChar == '':
            #continuation
            currentLine.text = currentLine.text + " " + iText
        else:
            #new character started speaking
            #start a new line
            cleanedLines.append(currentLine)
            currentLine = lines[i]
        
    #may end up with an empty character name/text for the first line
    #remove this
    if cleanedLines[0].character == '':
        cleanedLines = cleanedLines[1:]
    
    return cleanedLines

lines = mergeLineContinuations(lines)

def removeExtraWhitespace(lines):
    """
    Replaces duplicated spaces or tabs with single spaces
    Just to tidy things up a little
    """
    for line in lines
        line.text = " ".join(line.text.split())

for line in lines:
    print(line)
64/38:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

def mergeLineContinuations(lines):
    """
    cleanup - combine continuations (new lines where the same character is speaking)
    into single lines
    """
    cleanedLines = []

    currentLine = lines[0]
    for i in range(1,len(lines)):
        iChar = lines[i].character
        iText = lines[i].text
        if iChar == currentLine.character or iChar == '':
            #continuation
            currentLine.text = currentLine.text + " " + iText
        else:
            #new character started speaking
            #start a new line
            cleanedLines.append(currentLine)
            currentLine = lines[i]
        
    #may end up with an empty character name/text for the first line
    #remove this
    if cleanedLines[0].character == '':
        cleanedLines = cleanedLines[1:]
    
    return cleanedLines

lines = mergeLineContinuations(lines)

def removeExtraWhitespace(lines):
    """
    Replaces duplicated spaces or tabs with single spaces
    Just to tidy things up a little
    """
    for line in lines:
        line.text = " ".join(line.text.split()).strip()
    return lines
    
lines = removeExtraWhitespace(lines)

for line in lines:
    print(line)
64/39:
#format conversion - one long string into a list of 'Line' types


class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}: {t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line

def textToLines(text):
    """
    
    """
    splitText = text.split('\n')    
    lines = [parseLine(line) for line in splitText]
    return lines

lines = textToLines(text)
lines
64/40:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

def mergeLineContinuations(lines):
    """
    cleanup - combine continuations (new lines where the same character is speaking)
    into single lines
    """
    cleanedLines = []

    currentLine = lines[0]
    for i in range(1,len(lines)):
        iChar = lines[i].character
        iText = lines[i].text
        if iChar == currentLine.character or iChar == '':
            #continuation
            currentLine.text = currentLine.text + " " + iText
        else:
            #new character started speaking
            #start a new line
            cleanedLines.append(currentLine)
            currentLine = lines[i]
        
    #may end up with an empty character name/text for the first line
    #remove this
    if cleanedLines[0].character == '':
        cleanedLines = cleanedLines[1:]
    
    return cleanedLines

lines = mergeLineContinuations(lines)

def removeExtraWhitespace(lines):
    """
    Replaces duplicated spaces or tabs with single spaces
    Just to tidy things up a little
    """
    for line in lines:
        line.text = " ".join(line.text.split()).strip()
    return lines
    
lines = removeExtraWhitespace(lines)

for line in lines:
    print(line)
64/41:
# combine the above steps into a single class, to extract
# info and hold the resutls

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

class EpisodeInfo:
    """
    Container for episode data/metadata, including
    full transcript.
    Information on the episode is retrieved from the
    web on construction
    """
    
    def __init__(self, index, path):
        """
        Construct with an index (sequence number in the
        series - pilot = index o) and a path from which
        to retrieve info about the episode
        """
        url = makeUrl(path)
        soup = getSoup(url)
        text = getTranscriptText(soup)
        text = removeActions(text)
        lines = textToLines(text)
        lines = mergeLineContinuations(lines)
        lines = removeExtraWhitespace(lines)
        
        title = extractTitle(soup)
        
        self.index = index
        self.transcriptUrl = url
        self.transcript = lines
        self.title = title
    
    def __repr__(self):
        return "Episode {n}: {t}".format(n=self.index, t=self.title)

#test on pilot
print(EpisodeInfo(0,'/wiki/Pilot/Transcript'))
64/42:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
#     print(char + '\t' + str(wordsByChar))
rickLines = [line for line in lines if line.character == "Rick"]
rickLines

def extractTitle(soup):
    """
    Retrieves episode title from soup
    """
    titleSelector = '#PageHeader > div.page-header__main > h1'
    header = soup.select(titleSelector)[0]
    #Headers are of the form '{title}/Transcript' as we are viewing
    #the transcript page. Extract just the title
    title = header.text.split('/')[0]
    return title

extractTitle(soup)
64/43:
# combine the above steps into a single class, to extract
# info and hold the resutls

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

class EpisodeInfo:
    """
    Container for episode data/metadata, including
    full transcript.
    Information on the episode is retrieved from the
    web on construction
    """
    
    def __init__(self, index, path):
        """
        Construct with an index (sequence number in the
        series - pilot = index o) and a path from which
        to retrieve info about the episode
        """
        url = makeUrl(path)
        soup = getSoup(url)
        text = getTranscriptText(soup)
        text = removeActions(text)
        lines = textToLines(text)
        lines = mergeLineContinuations(lines)
        lines = removeExtraWhitespace(lines)
        
        title = extractTitle(soup)
        
        self.index = index
        self.transcriptUrl = url
        self.transcript = lines
        self.title = title
    
    def __repr__(self):
        return "Episode {n}: {t}".format(n=self.index, t=self.title)

#test on pilot
print(EpisodeInfo(0,'/wiki/Pilot/Transcript'))
64/44:
# combine the above steps into a single class, to extract
# info and hold the resutls

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

class EpisodeInfo:
    """
    Container for episode data/metadata, including
    full transcript.
    Information on the episode is retrieved from the
    web on construction
    """
    
    def __init__(self, index, path):
        """
        Construct with an index (sequence number in the
        series - pilot = index o) and a path from which
        to retrieve info about the episode
        """
        url = makeUrl(path)
        soup = getSoup(url)
        text = getTranscriptText(soup)
        text = removeActions(text)
        lines = textToLines(text)
        lines = mergeLineContinuations(lines)
        lines = removeExtraWhitespace(lines)
        
        title = extractTitle(soup)
        
        self.index = index
        self.transcriptUrl = url
        self.transcript = lines
        self.title = title
    
    def __repr__(self):
        return "Episode {n}: {t}".format(n=self.index, t=self.title)

#test on pilot
pilotInfo = EpisodeInfo(0,'/wiki/Pilot/Transcript')
print(pilotInfo)
print(len(pilotInfo.transcript))
64/45:
#get info for all Episodes
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
    if nextLink is None:
        nextPath = None
    else:
        nextPath = nextLink.attrs['href']
    
    return nextPath

episodes = []
index = 0
nextPath = getNextEpisodePath(firstEpPath)
while nextPath is not None:
    print(nextPath)
    episodes.append(EpisodeInfo(index, nextPath))
    nextPath = getNextEpisodePath(nextPath)
    index = index + 1
64/46:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/Meeseeks_and_Destroy/Transcript'

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

soup = getSoup(url)
print(soup)
64/47:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    
    approach: find the transcript div, and
    assume all paragraph tags inside comprise
    the transcript text
    """

    contentSelector = '#mw-content-text'
    transcriptContent = soup.select(contentSelector)[0]
    paragraphs = transcriptContent.find_all('p')
    text = ''.join([p.text for p in paragraphs])
    return text
    
text = getTranscriptText(soup)
print(text)
64/48:
# remove actions - everything the transcript which is not speech
# actions seem to be indicated by parentheses or asterixis

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)    
    return string

def removeActions(text):
    """
    remove actions - everything the transcript which is not speech.
    Actions seem to be indicated by parentheses or asterixis
    """
    text = removeAllBetween(text, '(', ')')
    text = removeAllBetween(text, '[', ']')
    text = removeAllBetween(text, '*', '*')
    return text
    
text = removeActions(text)
print(text)
64/49:
#format conversion - one long string into a list of 'Line' types


class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}: {t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line

def textToLines(text):
    """
    
    """
    splitText = text.split('\n')    
    lines = [parseLine(line) for line in splitText]
    return lines

lines = textToLines(text)
lines
64/50:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

def mergeLineContinuations(lines):
    """
    cleanup - combine continuations (new lines where the same character is speaking)
    into single lines
    """
    cleanedLines = []

    currentLine = lines[0]
    for i in range(1,len(lines)):
        iChar = lines[i].character
        iText = lines[i].text
        if iChar == currentLine.character or iChar == '':
            #continuation
            currentLine.text = currentLine.text + " " + iText
        else:
            #new character started speaking
            #start a new line
            cleanedLines.append(currentLine)
            currentLine = lines[i]
        
    #may end up with an empty character name/text for the first line
    #remove this
    if cleanedLines[0].character == '':
        cleanedLines = cleanedLines[1:]
    
    return cleanedLines

lines = mergeLineContinuations(lines)

def removeExtraWhitespace(lines):
    """
    Replaces duplicated spaces or tabs with single spaces
    Just to tidy things up a little
    """
    for line in lines:
        line.text = " ".join(line.text.split()).strip()
    return lines
    
lines = removeExtraWhitespace(lines)

for line in lines:
    print(line)
64/51:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/Raising_Gazorpazorp/Transcript'

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

soup = getSoup(url)
print(soup)
64/52:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    
    approach: find the transcript div, and
    assume all paragraph tags inside comprise
    the transcript text
    """

    contentSelector = '#mw-content-text'
    transcriptContent = soup.select(contentSelector)[0]
    paragraphs = transcriptContent.find_all('p')
    text = ''.join([p.text for p in paragraphs])
    return text
    
text = getTranscriptText(soup)
print(text)
64/53:
# remove actions - everything the transcript which is not speech
# actions seem to be indicated by parentheses or asterixis

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)    
    return string

def removeActions(text):
    """
    remove actions - everything the transcript which is not speech.
    Actions seem to be indicated by parentheses or asterixis
    """
    text = removeAllBetween(text, '(', ')')
    text = removeAllBetween(text, '[', ']')
    text = removeAllBetween(text, '*', '*')
    return text
    
text = removeActions(text)
print(text)
64/54:
#format conversion - one long string into a list of 'Line' types


class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}: {t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line

def textToLines(text):
    """
    
    """
    splitText = text.split('\n')    
    lines = [parseLine(line) for line in splitText]
    return lines

lines = textToLines(text)
lines
64/55:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

def mergeLineContinuations(lines):
    """
    cleanup - combine continuations (new lines where the same character is speaking)
    into single lines
    """
    cleanedLines = []

    currentLine = lines[0]
    for i in range(1,len(lines)):
        iChar = lines[i].character
        iText = lines[i].text
        if iChar == currentLine.character or iChar == '':
            #continuation
            currentLine.text = currentLine.text + " " + iText
        else:
            #new character started speaking
            #start a new line
            cleanedLines.append(currentLine)
            currentLine = lines[i]
        
    #may end up with an empty character name/text for the first line
    #remove this
    if cleanedLines[0].character == '':
        cleanedLines = cleanedLines[1:]
    
    return cleanedLines

lines = mergeLineContinuations(lines)

def removeExtraWhitespace(lines):
    """
    Replaces duplicated spaces or tabs with single spaces
    Just to tidy things up a little
    """
    for line in lines:
        line.text = " ".join(line.text.split()).strip()
    return lines
    
lines = removeExtraWhitespace(lines)

for line in lines:
    print(line)
64/56:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

def mergeLineContinuations(lines):
    """
    cleanup - combine continuations (new lines where the same character is speaking)
    into single lines
    """
    cleanedLines = []

    currentLine = lines[0]
    for i in range(1,len(lines)):
        iChar = lines[i].character
        iText = lines[i].text
        if iChar == currentLine.character or iChar == '':
            #continuation
            currentLine.text = currentLine.text + " " + iText
        else:
            #new character started speaking
            #start a new line
            cleanedLines.append(currentLine)
            currentLine = lines[i]
        
    #may end up with an empty character name/text for the first line
    #remove this
    if len(cleanedLines) > 0 and cleanedLines[0].character == '':
        cleanedLines = cleanedLines[1:]
    
    return cleanedLines

lines = mergeLineContinuations(lines)

def removeExtraWhitespace(lines):
    """
    Replaces duplicated spaces or tabs with single spaces
    Just to tidy things up a little
    """
    for line in lines:
        line.text = " ".join(line.text.split()).strip()
    return lines
    
lines = removeExtraWhitespace(lines)

for line in lines:
    print(line)
64/57:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
#     print(char + '\t' + str(wordsByChar))
rickLines = [line for line in lines if line.character == "Rick"]
rickLines

def extractTitle(soup):
    """
    Retrieves episode title from soup
    """
    titleSelector = '#PageHeader > div.page-header__main > h1'
    header = soup.select(titleSelector)[0]
    #Headers are of the form '{title}/Transcript' as we are viewing
    #the transcript page. Extract just the title
    title = header.text.split('/')[0]
    return title

extractTitle(soup)
64/58:
#get info for all Episodes
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
    if nextLink is None:
        nextPath = None
    else:
        nextPath = nextLink.attrs['href']
    
    return nextPath

episodes = []
index = 0
nextPath = getNextEpisodePath(firstEpPath)
while nextPath is not None:
    print(nextPath)
    episodes.append(EpisodeInfo(index, nextPath))
    nextPath = getNextEpisodePath(nextPath)
    index = index + 1
64/59: e = episodes[0]
64/60:
e = episodes[0]
for e in episodes:
    print e.title
64/61:
# combine the above steps into a single class, to extract
# info and hold the resutls

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

class EpisodeInfo:
    """
    Container for episode data/metadata, including
    full transcript.
    Information on the episode is retrieved from the
    web on construction
    """
    
    def __init__(self, index, path):
        """
        Construct with an index (sequence number in the
        series - pilot = index o) and a path from which
        to retrieve info about the episode
        """
        url = makeUrl(path)
        soup = getSoup(url)
        text = getTranscriptText(soup)
        text = removeActions(text)
        lines = textToLines(text)
        lines = mergeLineContinuations(lines)
        lines = removeExtraWhitespace(lines)
        
        name = extractName(soup)
        
        self.index = index
        self.transcriptUrl = url
        self.transcript = lines
        self.name = name
    
    def __repr__(self):
        return "Episode {n}: {t}".format(n=self.index, t=self.name)

#test on pilot
pilotInfo = EpisodeInfo(0,'/wiki/Pilot/Transcript')
print(pilotInfo)
print(len(pilotInfo.transcript))
64/62:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
#     print(char + '\t' + str(wordsByChar))
rickLines = [line for line in lines if line.character == "Rick"]
rickLines

def extractName(soup):
    """
    Retrieves episode title from soup
    """
    titleSelector = '#PageHeader > div.page-header__main > h1'
    header = soup.select(titleSelector)[0]
    #Headers are of the form '{title}/Transcript' as we are viewing
    #the transcript page. Extract just the title
    title = header.text.split('/')[0]
    return title

extractName(soup)
64/63:
# combine the above steps into a single class, to extract
# info and hold the resutls

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

class EpisodeInfo:
    """
    Container for episode data/metadata, including
    full transcript.
    Information on the episode is retrieved from the
    web on construction
    """
    
    def __init__(self, index, path):
        """
        Construct with an index (sequence number in the
        series - pilot = index o) and a path from which
        to retrieve info about the episode
        """
        url = makeUrl(path)
        soup = getSoup(url)
        text = getTranscriptText(soup)
        text = removeActions(text)
        lines = textToLines(text)
        lines = mergeLineContinuations(lines)
        lines = removeExtraWhitespace(lines)
        
        name = extractName(soup)
        
        self.index = index
        self.transcriptUrl = url
        self.transcript = lines
        self.name = name
    
    def __repr__(self):
        return "Episode {n}: {t}".format(n=self.index, t=self.name)

#test on pilot
pilotInfo = EpisodeInfo(0,'/wiki/Pilot/Transcript')
print(pilotInfo)
print(len(pilotInfo.transcript))
64/64:
#get info for all Episodes
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
    if nextLink is None:
        nextPath = None
    else:
        nextPath = nextLink.attrs['href']
    
    return nextPath

episodes = []
index = 0
nextPath = getNextEpisodePath(firstEpPath)
while nextPath is not None:
    print(nextPath)
    episodes.append(EpisodeInfo(index, nextPath))
    nextPath = getNextEpisodePath(nextPath)
    index = index + 1
64/65:
e = episodes[0]
for e in episodes:
    print e.name
64/66:
e = episodes[0]
for e in episodes:
    print '{n}\t{l}'.format(e.name, len(e.transcript))
64/67:
e = episodes[0]
for e in episodes:
    print '{}\t{}'.format(e.name, len(e.transcript))
64/68:
e = episodes[0]
for e in episodes:
    print '{}\t{}'.format(e.name, len(e.transcript))

import pickle
64/69:
e = episodes[0]
for e in episodes:
    print '{}\t{}'.format(e.name, len(e.transcript))

import pickle
#save transcripts for later
saveFilename = 'rickAndMortyTranscripts_retrieved_{date}.'
# pickle.dump(file=)
help(pickle.dumps)
64/70:
e = episodes[0]
for e in episodes:
    print '{}\t{}'.format(e.name, len(e.transcript))

import pickle
#save transcripts for later
saveFilename = 'rickAndMortyTranscripts_retrieved_{date}.'
# pickle.dump(file=)
help(pickle.dump)
64/71:
e = episodes[0]
for e in episodes:
    print '{}\t{}'.format(e.name, len(e.transcript))

import pickle
import datetime
#save transcripts for later
date = datetime.datetime.today().strftime('%Y-%m-%d')
saveFilename = 'rickAndMortyTranscripts_retrieved_{date}.'
# pickle.dump(file=)
help(pickle.dump)
64/72:
e = episodes[0]
for e in episodes:
    print '{}\t{}'.format(e.name, len(e.transcript))

import pickle
import datetime
#save transcripts for later
date = datetime.datetime.today().strftime('%Y-%m-%d')
saveFilename = 'rickAndMortyTranscripts_retrieved_{date}.pkl'.format(date = date)
# pickle.dump(file=)
help(pickle.dump)
64/73:
e = episodes[0]
for e in episodes:
    print '{}\t{}'.format(e.name, len(e.transcript))

import pickle
import datetime
#save transcripts for later
date = datetime.datetime.today().strftime('%Y-%m-%d')
saveFilename = 'rickAndMortyTranscripts_retrieved_{date}.pkl'.format(date = date)
print(saveFilename)
# pickle.dump(file=)
help(pickle.dump)
64/74:
e = episodes[0]
for e in episodes:
    print '{}\t{}'.format(e.name, len(e.transcript))

import pickle
import datetime
#save transcripts for later
date = datetime.datetime.today().strftime('%Y-%m-%d')
saveFilename = 'rickAndMortyTranscripts_retrieved_{date}.pkl'.format(date = date)
with open(saveFilename, 'wb') as saveFile:
    pickle.dump(saveFile, episodes)
    
print(saveFilename)
64/75:
e = episodes[0]
for e in episodes:
    print '{}\t{}'.format(e.name, len(e.transcript))

import pickle
import datetime
#save transcripts for later
date = datetime.datetime.today().strftime('%Y-%m-%d')
saveFilename = 'rickAndMortyTranscripts_retrieved_{date}.pkl'.format(date = date)
with open(saveFilename, 'wb') as saveFile:
    pickle.dump(episodes, saveFile)
    
print(saveFilename)
65/1:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/Pilot/Transcript'

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

soup = getSoup(url)
print(soup)
65/2:


# def getTranscriptText(soup):
#     """
#     Extract transcript text from
#     parsed web page (soup)
#     """
#     selector = "#mw-content-text > div.poem"
#     transcriptDiv = soup.select(selector)
#     if len(transcriptDiv) == 0:
#         text = ''
#     else:
#         text = transcriptDiv[0].get_text()
    
#     return text

def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    
    approach: find the transcript div, and
    assume all paragraph tags inside comprise
    the transcript text
    """

    contentSelector = '#mw-content-text'
    transcriptContent = soup.select(contentSelector)[0]
    paragraphs = transcriptContent.find_all('p')
    text = ''.join([p.text for p in paragraphs])
    return text
    
text = getTranscriptText(soup)
print(text)
65/3:
# remove actions - everything the transcript which is not speech
# actions seem to be indicated by parentheses or asterixis

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)    
    return string

def removeActions(text):
    """
    remove actions - everything the transcript which is not speech.
    Actions seem to be indicated by parentheses or asterixis
    """
    text = removeAllBetween(text, '(', ')')
    text = removeAllBetween(text, '[', ']')
    text = removeAllBetween(text, '*', '*')
    return text
    
text = removeActions(text)
print(text)
65/4:
#format conversion - one long string into a list of 'Line' types


class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}: {t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line

def textToLines(text):
    """
    
    """
    splitText = text.split('\n')    
    lines = [parseLine(line) for line in splitText]
    return lines

lines = textToLines(text)
lines
65/5:
#cleanup - combine continuations (new lines where the same character is speaking)
#into single lines

def mergeLineContinuations(lines):
    """
    cleanup - combine continuations (new lines where the same character is speaking)
    into single lines
    """
    cleanedLines = []

    currentLine = lines[0]
    for i in range(1,len(lines)):
        iChar = lines[i].character
        iText = lines[i].text
        if iChar == currentLine.character or iChar == '':
            #continuation
            currentLine.text = currentLine.text + " " + iText
        else:
            #new character started speaking
            #start a new line
            cleanedLines.append(currentLine)
            currentLine = lines[i]
        
    #may end up with an empty character name/text for the first line
    #remove this
    if len(cleanedLines) > 0 and cleanedLines[0].character == '':
        cleanedLines = cleanedLines[1:]
    
    return cleanedLines

lines = mergeLineContinuations(lines)

def removeExtraWhitespace(lines):
    """
    Replaces duplicated spaces or tabs with single spaces
    Just to tidy things up a little
    """
    for line in lines:
        line.text = " ".join(line.text.split()).strip()
    return lines
    
lines = removeExtraWhitespace(lines)

for line in lines:
    print(line)
65/6:
#find out some things
#how many lines?
#how many words per line?
#who were the characters?
#how many charachters?
#how many words by character?

numLines = len(lines)
wordCount = lambda line : len(line.text.split())
wordsPerLine = [wordCount(line) for line in lines]
characters = set(line.character for line in lines)
characters
for char in characters:
    wordsByChar = sum(wordCount(line) for line in lines if line.character == char)
#     print(char + '\t' + str(wordsByChar))
rickLines = [line for line in lines if line.character == "Rick"]
rickLines

def extractName(soup):
    """
    Retrieves episode title from soup
    """
    titleSelector = '#PageHeader > div.page-header__main > h1'
    header = soup.select(titleSelector)[0]
    #Headers are of the form '{title}/Transcript' as we are viewing
    #the transcript page. Extract just the title
    title = header.text.split('/')[0]
    return title

extractName(soup)
65/7:
# combine the above steps into a single class, to extract
# info and hold the resutls

baseUrl = 'http://rickandmorty.wikia.com'
makeUrl = lambda path : baseUrl + path

class EpisodeInfo:
    """
    Container for episode data/metadata, including
    full transcript.
    Information on the episode is retrieved from the
    web on construction
    """
    
    def __init__(self, index, path):
        """
        Construct with an index (sequence number in the
        series - pilot = index o) and a path from which
        to retrieve info about the episode
        """
        url = makeUrl(path)
        soup = getSoup(url)
        text = getTranscriptText(soup)
        text = removeActions(text)
        lines = textToLines(text)
        lines = mergeLineContinuations(lines)
        lines = removeExtraWhitespace(lines)
        
        name = extractName(soup)
        
        self.index = index
        self.transcriptUrl = url
        self.transcript = lines
        self.name = name
    
    def __repr__(self):
        return "Episode {n}: {t}".format(n=self.index, t=self.name)

#test on pilot
pilotInfo = EpisodeInfo(0,'/wiki/Pilot/Transcript')
print(pilotInfo)
print(len(pilotInfo.transcript))
65/8:
#get info for all Episodes
baseUrl = 'http://rickandmorty.wikia.com'
firstEpPath = '/wiki/Pilot/Transcript'
                                               
def getNextEpisodePath(currentEpisodePath):
    """
    Returns the path for the next episode.
    Each episode transcript contains a link to 
    the following episode. Get this link.
    """
    episodeUrl = makeUrl(currentEpisodePath)
    soup = getSoup(episodeUrl)
    
    nextLink = soup.find(text='Next:').parent.find_next_sibling('a')
    if nextLink is None:
        nextPath = None
    else:
        nextPath = nextLink.attrs['href']
    
    return nextPath

episodes = []
index = 0
nextPath = getNextEpisodePath(firstEpPath)
while nextPath is not None:
    print(nextPath)
    episodes.append(EpisodeInfo(index, nextPath))
    nextPath = getNextEpisodePath(nextPath)
    index = index + 1
65/9:
e = episodes[0]
for e in episodes:
    print '{}\t{}'.format(e.name, len(e.transcript))

import pickle
import datetime
#save transcripts for later
date = datetime.datetime.today().strftime('%Y-%m-%d')
saveFilename = 'rickAndMortyTranscripts_retrieved_{date}.pkl'.format(date = date)
with open(saveFilename, 'wb') as saveFile:
    pickle.dump(episodes, saveFile)
    
print(saveFilename)
65/10:
import urllib2

from bs4 import BeautifulSoup

url = 'http://rickandmorty.wikia.com/wiki/Pilot/Transcript'

def getSoup(url):
    """
    Request the given url, return html as parsed 'soup'
    """
    response = urllib2.urlopen(url)
    html = response.read()
    soup = BeautifulSoup(html, 'html.parser')
    return soup

soup = getSoup(url)
print(soup.prettify())
65/11:
def getTranscriptText(soup):
    """
    Extract transcript text from
    parsed web page (soup)
    
    approach: find the transcript div, and
    assume all paragraph tags inside comprise
    the transcript text
    """

    contentSelector = '#mw-content-text'
    transcriptContent = soup.select(contentSelector)[0]
    paragraphs = transcriptContent.find_all('p')
    text = ''.join([p.text for p in paragraphs])
    return text
    
text = getTranscriptText(soup)
print(text)
65/12:
#format conversion - one long string into a list of 'Line' types

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}: {t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line

def textToLines(text):
    """
    convert entire text to a list of Line instances
    """
    splitText = text.split('\n')    
    lines = [parseLine(line) for line in splitText]
    return lines

lines = textToLines(text)
lines
65/13:
#format conversion - one long string into a list of 'Line' types

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}: {t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line

def textToLines(text):
    """
    convert entire text to a list of Line instances
    """
    splitText = text.split('\n')    
    lines = [parseLine(line) for line in splitText]
    return lines

lines = textToLines(text)

for line in lines:
    print(line)
65/14:
# remove actions - everything the transcript which is not speech
# actions seem to be indicated by parentheses or asterixis

def removeBetween(string, startChar, endChar):
    """
    Remove everything in the string from the first instance
    of the start character to the next instance of the end char 
    """
    toStartChar = string[:string.find(startChar)] 
    fromStartChar = string[string.find(startChar)+1:]
    fromEndChar = fromStartChar[fromStartChar.find(endChar)+1:]
    return toStartChar + fromEndChar

def removeAllBetween(string, startChar, endChar):
    """
    Keep calling 'removeBetween' until no
    instances of startChar remain in the
    given string
    """
    while string.find(startChar) != -1:
        string = removeBetween(string, startChar, endChar)    
    return string

def removeActions(text):
    """
    remove actions - everything the transcript which is not speech.
    Actions seem to be indicated by parentheses or asterixis
    """
    text = removeAllBetween(text, '(', ')')
    text = removeAllBetween(text, '[', ']')
    text = removeAllBetween(text, '*', '*')
    return text
    
text = removeActions(text)
print(text)
65/15:
#format conversion - one long string into a list of 'Line' types

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}: {t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line

def textToLines(text):
    """
    convert entire text to a list of Line instances
    """
    splitText = text.split('\n')    
    lines = [parseLine(line) for line in splitText]
    return lines

lines = textToLines(text)

for line in lines:
    print(line)
65/16:
#format conversion - one long string into a list of 'Line' types

class Line:
    def __init__(self, character, text):
        self.character = character
        self.text = text
    def __repr__(self):
        return u"{c}: {t}".format(c=self.character, t=self.text).encode('utf-8')

def parseLine(text):
    """
    Split up a line from the script into a Line type containing
    the name of the character and the text of what they said
    """

    colonIndex = text.find(':')
    if colonIndex != -1:
        #line contains a colon
        line = Line(
            character = text[0:colonIndex].strip(),
            text = text[colonIndex+1:] 
        )
    else:
        line = Line(
            character = "",
            text = text
        )
    return line

def textToLines(text):
    """
    convert entire text to a list of Line instances
    """
    splitText = text.split('\n')    
    lines = [parseLine(line) for line in splitText]
    return lines

lines = textToLines(text)

for line in lines:
    print(line)
66/1: pwd
66/2: sum = 0
66/3: incomes = [1000, "bob", 2000, 2.4]
66/4:
incomes = [1000, "bob", 2000, 2.4]

sum = 0

for thing in incomes:
66/5:
incomes = [1000, "bob", 2000, 2.4]

sum = 0

for thing in incomes:
66/6:
incomes = [1000, "bob", 2000, 2.4]

sum = 0

for thing in incomes:
66/7:
incomes = [1000, "bob", 2000, 2.4]

sum = 0

for thing in incomes:
66/8:
incomes = [1000, "bob", 2000, 2.4]

sum = 0

for thing in incomes:
    if thing is int:
        sum = sum + thing
print(sum)
66/9:
incomes = [1000, "bob", 2000, 2.4]

sum = 0

for thing in incomes:
    if type(thing) is int:
        sum = sum + thing
print(sum)
66/10:
incomes = [1000, "bob", 2000, 2.4]

sum = 0

for thing in incomes:
    print(type(thing))
    if type(thing) is int:
        sum = sum + thing
print(sum)
68/1: pwd
68/2:
incomes = [1000, "bob", 2000, 2.4]

sum = 0

for thing in incomes:
    print(type(thing))
    if type(thing) is int:
        sum = sum + thing
print(sum)
68/3:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print(bookGenres.popitem())
68/4:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print(bookGenres.popitem())
68/5:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print(bookGenres.popitem())
68/6:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print(bookGenres.popitem())
68/7:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print(bookGenres.popitem())
68/8:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print(bookGenres.popitem())
68/9:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print(bookGenres.popitem())
print(bookGenres)
68/10:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print(bookGenres.popitem())
print(bookGenres)
69/1: pwd
69/2:
incomes = [1000, "bob", 2000, 2.4]

sum = 0

for thing in incomes:
    print(type(thing))
    if type(thing) is int:
        sum = sum + thing
print(sum)
69/3:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print (bookGenres)

print(bookGenres.popitem())
print(bookGenres)
69/4:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print (bookGenres)

bookTitles = list(bookGenres.keys())
69/5:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print (bookGenres)

bookList = list(bookGenres.keys())
bookGenres.pop('got')

print{bookGenres}
69/6:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print (bookGenres)

bookList = list(bookGenres.keys())
bookGenres.pop('fantasy')

print{bookGenres}
69/7:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print (bookGenres)

bookList = list(bookGenres.keys())
bookGenres.pop('drama')

print{bookGenres}
70/1: pwd
70/2:
incomes = [1000, "bob", 2000, 2.4]

sum = 0

for thing in incomes:
    print(type(thing))
    if type(thing) is int:
        sum = sum + thing
print(sum)
70/3:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print (bookGenres)

bookList = list(bookGenres.keys())
bookGenres.pop('drama')

print{bookGenres}
70/4:
bookGenres = {'got':'fantasy','haunted life':'drama','1984':'drama'}

print (bookGenres)

bookList = list(bookGenres.keys())
bookGenres.pop('drama')

print(bookGenres)
71/1: import gmplot
71/2: gmap = gmplot.GoogleMapPlotter.from_geocode("San Francisco")
71/3: gmap.draw("mymap.html")
71/4: gmap = gmplot.GoogleMapPlotter.from_geocode("Auckland")
71/5: gmap.draw("mymap.html")
72/1:
import gmplot
gmap = gmplot.GoogleMapPlotter.from_geocode("Auckland")
gmap.draw("mymap.html")
72/2:
import gmplot
gmap = gmplot.GoogleMapPlotter.from_geocode("Auckland")
gmap.draw("mymap.html")
72/3: import json
72/4:
import json
with open('onzo_20180225195226.json') as json_file:
    json_data=json_file.read()

data = json.loads(json_data)
pprint(data)
72/5:
import json
import pprint
with open('onzo_20180225195226.json') as json_file:
    json_data=json_file.read()

data = json.loads(json_data)
pprint(data)
72/6:
import json
from pprint import pprint
with open('onzo_20180225195226.json') as json_file:
    json_data=json_file.read()

data = json.loads(json_data)
pprint(data)
72/7:
import json
from pprint import pprint
with open('onzo_20180225195226.json') as json_file:
    json_data=json_file.read()

data = json.loads(json_data)
pprint(data)
72/8:
import json
from pprint import pprint
with open('onzo_20180225195226.json') as json_file:
    json_data=json_file.read()

data = json.loads(json_data)['data']
pprint(data)
72/9:
import json
import pandas as pd
from pprint import pprint
with open('onzo_20180225195226.json') as json_file:
    json_data=json_file.read()

data = json.loads(json_data)['data']
pprint(data)
72/10:
import json
import pandas as pd
from pprint import pprint
with open('onzo_20180225195226.json') as json_file:
    json_data=json_file.read()

data = json.loads(json_data)['data']
pprint(data)
72/11:
import json
import pandas as pd
from pprint import pprint
with open('onzo_20180225195226.json') as json_file:
    json_data=json_file.read()

data = pd.DataFrame(json.loads(json_data)['data'])
pprint(data)
72/12:
import json
import pandas as pd
from pprint import pprint
with open('onzo_20180225195226.json') as json_file:
    json_data=json_file.read()

data = pd.DataFrame(json.loads(json_data)['data'])
pprint(data)
data.to_csv('onzos.csv')
72/13:
import json
import pandas as pd
import gmplot
with open('onzo_20180225195226.json') as json_file:
    json_data=json_file.read()

data = pd.DataFrame(json.loads(json_data)['data'])
gmap = gmplot.GoogleMapPlotter.from_geocode("Auckland")
gmap.draw("mymap.html")
gmap.scatter(data.latitude, data.longitude, 'k', marker=True)
72/14:
import json
import pandas as pd
import gmplot
with open('onzo_20180225195226.json') as json_file:
    json_data=json_file.read()

data = pd.DataFrame(json.loads(json_data)['data'])
gmap = gmplot.GoogleMapPlotter.from_geocode("Auckland")
gmap.scatter(data.latitude, data.longitude, 'k', marker=True)
gmap.draw("mymap.html")
72/15:
import json
import pandas as pd
import gmplot
with open('onzo_20180225195226.json') as json_file:
    json_data=json_file.read()

data = pd.DataFrame(json.loads(json_data)['data'])
gmap = gmplot.GoogleMapPlotter.from_geocode("Auckland")
gmap.scatter(data.latitude, data.longitude, 'k', marker=True)
gmap.draw("mymap.html")
72/16:
import json
import pandas as pd
import gmplot
with open('onzo_20180225195226.json') as json_file:
    json_data=json_file.read()

data = pd.DataFrame(json.loads(json_data)['data'])
gmap = gmplot.GoogleMapPlotter.from_geocode("Auckland")
gmap.scatter(data.latitude, data.longitude, marker=True)
gmap.draw("mymap.html")
72/17:
import json
import pandas as pd
import gmplot
with open('onzo_20180225195226.json') as json_file:
    json_data=json_file.read()

data = pd.DataFrame(json.loads(json_data)['data'])
gmap = gmplot.GoogleMapPlotter.from_geocode("Auckland")
gmap.scatter(data.latitude, data.longitude, 'r', marker=True)
gmap.draw("mymap.html")
72/18: import requests
72/19:
import requests
apiUrl = 'https://app.onzo.co.nz/nearby/-36.848123/174.765588/50.0'
requests.get(apiUrl)
72/20:
import requests
apiUrl = 'https://app.onzo.co.nz/nearby/-36.848123/174.765588/50.0'
response = requests.get(apiUrl)
72/21:
import requests
apiUrl = 'https://app.onzo.co.nz/nearby/-36.848123/174.765588/50.0'
response = requests.get(apiUrl)
response.content
72/22:
import requests
apiUrl = 'https://app.onzo.co.nz/nearby/-36.848123/174.765588/50.0'
response = requests.get(apiUrl)
response.json
72/23:
import requests
apiUrl = 'https://app.onzo.co.nz/nearby/-36.848123/174.765588/50.0'
response = requests.get(apiUrl)
response.json()
72/24:
import requests
apiUrl = 'https://app.onzo.co.nz/nearby/-36.848123/174.765588/50.0'
response = requests.get(apiUrl)
type(response.json())
72/25:
import requests
apiUrl = 'https://app.onzo.co.nz/nearby/-36.848123/174.765588/50.0'
response = requests.get(apiUrl)
response.json()['data']
72/26:
import requests
apiUrl = 'https://app.onzo.co.nz/nearby/-36.848123/174.765588/50.0'
response = requests.get(apiUrl)
data = pd.DataFrame(response.json()['data'])
72/27:
import requests
apiUrl = 'https://app.onzo.co.nz/nearby/-36.848123/174.765588/50.0'
response = requests.get(apiUrl)
data = pd.DataFrame(response.json()['data'])
data
72/28:
import json
import pandas as pd
import gmplot
import requests

#with open('onzo_20180225195226.json') as json_file:
#    json_data=json_file.read()
#    data = pd.DataFrame(json.loads(json_data)['data'])

apiUrl = 'https://app.onzo.co.nz/nearby/-36.848123/174.765588/50.0'
response = requests.get(apiUrl)
data = pd.DataFrame(response.json()['data'])

gmap = gmplot.GoogleMapPlotter.from_geocode("Auckland")
gmap.scatter(data.latitude, data.longitude, 'r', marker=True)
gmap.draw("mymap.html")
72/29:
import json
import pandas as pd
import gmplot
import requests

#with open('onzo_20180225195226.json') as json_file:
#    json_data=json_file.read()
#    data = pd.DataFrame(json.loads(json_data)['data'])

apiUrl = 'https://app.onzo.co.nz/nearby/-36.848123/174.765588/50.0'
response = requests.get(apiUrl)
data = pd.DataFrame(response.json()['data'])

gmap = gmplot.GoogleMapPlotter.from_geocode("Auckland")
gmap.scatter(data.latitude, data.longitude, 'r', marker=True)
gmap.draw("onzoMap.html")
72/30:
import json
import pandas as pd
import gmplot
import requests

#with open('onzo_20180225195226.json') as json_file:
#    json_data=json_file.read()
#    data = pd.DataFrame(json.loads(json_data)['data'])

apiUrl = 'https://app.onzo.co.nz/nearby/-36.848123/174.765588/50.0'
response = requests.get(apiUrl)
data = pd.DataFrame(response.json()['data'])

gmap = gmplot.GoogleMapPlotter.from_geocode("Auckland")
gmap.scatter(data.latitude, data.longitude, 'r', marker=True)
gmap.draw("onzoMap.html")
72/31:
import pandas as pd
import gmplot
import requests

#import json
#with open('onzo_20180225195226.json') as json_file:
#    json_data=json_file.read()
#    data = pd.DataFrame(json.loads(json_data)['data'])

apiUrl = 'https://app.onzo.co.nz/nearby/-36.848123/174.765588/50.0'
response = requests.get(apiUrl)
data = pd.DataFrame(response.json()['data'])

gmap = gmplot.GoogleMapPlotter.from_geocode("Auckland")
gmap.scatter(data.latitude, data.longitude, 'r', marker=True)
gmap.draw("mymap.html")
72/32:
import pandas as pd
import gmplot
import requests

#import json
#with open('onzo_20180225195226.json') as json_file:
#    json_data=json_file.read()
#    data = pd.DataFrame(json.loads(json_data)['data'])

apiUrl = 'https://app.onzo.co.nz/nearby/-36.848123/174.765588/50.0'
response = requests.get(apiUrl)
data = pd.DataFrame(response.json()['data'])

gmap = gmplot.GoogleMapPlotter.from_geocode("Auckland")
gmap.scatter(data.latitude, data.longitude, 'r', marker=True)
gmap.draw("mymap.html")
73/1:
words = """
LALALA,
XOXOXO,
GCGCGC,
HHHCCC,
BBBMMM,
EGONUH,
HHRGOE
""".split(',')
73/2:
words = """
LALALA,
XOXOXO,
GCGCGC,
HHHCCC,
BBBMMM,
EGONUH,
HHRGOE
""".split(',')
73/3:
words = """
LALALA,
XOXOXO,
GCGCGC,
HHHCCC,
BBBMMM,
EGONUH,
HHRGOE
""".split(',')

words
73/4:
words = """
LALALA
XOXOXO
GCGCGC
HHHCCC
BBBMMM
EGONUH
HHRGOE
""".split('\n')

words
73/5:
words = """
LALALA
XOXOXO
GCGCGC
HHHCCC
BBBMMM
EGONUH
HHRGOE
""".strip().split('\n')

words
73/6:
words = """
LALALA
XOXOXO
GCGCGC
HHHCCC
BBBMMM
EGONUH
HHRGOE
""".strip().split('\n')

words
73/7:
def wordToNum(word):
    pass
73/8: word = words[1]
73/9:
word = words[1]
word
73/10:
word = words[0]
word
73/11:
word = words[0]
word
''.join(OrderedDict.fromkeys( word).keys())
'abcd'
73/12:
from collections import OrderedDict

word = words[0]
word
''.join(OrderedDict.fromkeys( word).keys())
'abcd'
73/13:
from collections import OrderedDict

word = words[0]
word
''.join(OrderedDict.fromkeys( word).keys())
73/14:
from collections import OrderedDict

word = words[0]
word
OrderedDict.fromkeys( word).keys()
73/15:
from collections import OrderedDict

word = words[0]
word
OrderedDict.fromkeys( word).keys()[0]
73/16:
from collections import OrderedDict

word = words[0]
word
OrderedDict.fromkeys( word)
73/17:
from collections import OrderedDict

word = words[0]
word
charToIndex = OrderedDict.fromkeys( word)
OrderedDict(key:i for key,i in enumerate(charToIndex.keys()))
73/18:
from collections import OrderedDict

word = words[0]
word
charToIndex = OrderedDict.fromkeys( word)
for char, i in enumerate(charToIndex.keys()):
    charToIndex[char] = i
73/19:
from collections import OrderedDict

word = words[0]
word
charToIndex = OrderedDict.fromkeys( word)
for char, i in enumerate(charToIndex.keys()):
    print(charToIndex[char])
73/20:
from collections import OrderedDict

word = words[0]
word
charToIndex = OrderedDict.fromkeys( word)
for i, char in enumerate(charToIndex.keys()):
    charToIndex[char] = i
73/21:
from collections import OrderedDict

word = words[0]
word
charToIndex = OrderedDict.fromkeys( word)
for i, char in enumerate(charToIndex.keys()):
    charToIndex[char] = i
charToIndex
73/22:
from collections import OrderedDict

word = words[0]
word
charToIndex = OrderedDict.fromkeys( word)
for i, char in enumerate(charToIndex.keys()):
    charToIndex[char] = i
print(charToIndex)
73/23:
from collections import OrderedDict

word = words[0]
word
charToIndex = OrderedDict.fromkeys( word)
for i, char in enumerate(charToIndex.keys()):
    charToIndex[char] = i
print(charToIndex)

num = [charToIndex(char) for char in word]
73/24:
from collections import OrderedDict

word = words[0]
word
charToIndex = OrderedDict.fromkeys( word)
for i, char in enumerate(charToIndex.keys()):
    charToIndex[char] = i
print(charToIndex)

num = [charToIndex[char] for char in word]
73/25:
from collections import OrderedDict

word = words[0]
word
charToIndex = OrderedDict.fromkeys( word)
for i, char in enumerate(charToIndex.keys()):
    charToIndex[char] = i
print(charToIndex)

num = [charToIndex[char] for char in word]
num
73/26:
from collections import OrderedDict

word = words[0]
word
charToIndex = OrderedDict.fromkeys( word)
for i, char in enumerate(charToIndex.keys()):
    charToIndex[char] = i
print(charToIndex)

num = [charToIndex[char] for char in word]

{num:2}
73/27:
from collections import OrderedDict

word = words[0]
word
charToIndex = OrderedDict.fromkeys( word)
for i, char in enumerate(charToIndex.keys()):
    charToIndex[char] = i
print(charToIndex)

num = tuple(charToIndex[char] for char in word)

{num:2}
73/28:
def wordToNumericTuple(word):
    """
    Convert given word to a tuple of ints which will be identical for all friends.
    In the tuples each letter of the word is converted to an int, based on the location
    of the first instance of that letter in the word.
    Eg.
    if word = "LALALA"
    then 
    charToIndex = OrderedDict([('L', 0), ('A', 1)])
    and the resultant tuple = (0, 1, 0, 1, 0, 1)
    
    A tuple is returned so it can be used as a key in a dictionary, in order to count occurances of friends.
    """
    
    charToIndex = OrderedDict.fromkeys(word)
    for i, char in enumerate(charToIndex.keys()):
        charToIndex[char] = i
    print(charToIndex)

    num = tuple(charToIndex[char] for char in word)
73/29:
from collections import OrderedDict

def wordToNumericTuple(word):
    """
    Convert given word to a tuple of ints which will be identical for all friends.
    In the tuples each letter of the word is converted to an int, based on the location
    of the first instance of that letter in the word.
    Eg.
    if word = "LALALA"
    then 
    charToIndex = OrderedDict([('L', 0), ('A', 1)])
    and the resultant tuple = (0, 1, 0, 1, 0, 1)
    
    A tuple is returned so it can be used as a key in a dictionary, in order to count occurances of friends.
    """
    
    charToIndex = OrderedDict.fromkeys(word)
    for i, char in enumerate(charToIndex.keys()):
        charToIndex[char] = i
    print(charToIndex)

    num = tuple(charToIndex[char] for char in word)
73/30:
from collections import OrderedDict

def print(wordToNumericTuple(("LALALA"))word):
    """
    Convert given word to a tuple of ints which will be identical for all friends.
    In the tuples each letter of the word is converted to an int, based on the location
    of the first instance of that letter in the word.
    Eg.
    if word = "LALALA"
    then 
    charToIndex = OrderedDict([('L', 0), ('A', 1)])
    and the resultant tuple = (0, 1, 0, 1, 0, 1)
    
    A tuple is returned so it can be used as a key in a dictionary, in order to count occurances of friends.
    """
    
    charToIndex = OrderedDict.fromkeys(word)
    for i, char in enumerate(charToIndex.keys()):
        charToIndex[char] = i
    print(charToIndex)

    num = tuple(charToIndex[char] for char in word)
    
#e.g.:
print(wordToNumericTuple("LALALA"))
73/31:
from collections import OrderedDict

def print(wordToNumericTuple(("LALALA"))word):
    """
    Convert given word to a tuple of ints which will be identical for all friends.
    In the tuples each letter of the word is converted to an int, based on the location
    of the first instance of that letter in the word.
    Eg.
    if word = "LALALA"
    then 
    charToIndex = OrderedDict([('L', 0), ('A', 1)])
    and the resultant tuple = (0, 1, 0, 1, 0, 1)
    
    A tuple is returned so it can be used as a key in a dictionary, in order to count occurances of friends.
    """
    
    charToIndex = OrderedDict.fromkeys(word)
    for i, char in enumerate(charToIndex.keys()):
        charToIndex[char] = i
    print(charToIndex)

    num = tuple(charToIndex[char] for char in word)
    
#e.g.:
print(wordToNumericTuple("LALALA"))
73/32:
from collections import OrderedDict

def wordToNumericTuple(word):
    """
    Convert given word to a tuple of ints which will be identical for all friends.
    In the tuples each letter of the word is converted to an int, based on the location
    of the first instance of that letter in the word.
    Eg.
    if word = "LALALA"
    then 
    charToIndex = OrderedDict([('L', 0), ('A', 1)])
    and the resultant tuple = (0, 1, 0, 1, 0, 1)
    
    A tuple is returned so it can be used as a key in a dictionary, in order to count occurances of friends.
    """
    
    charToIndex = OrderedDict.fromkeys(word)
    for i, char in enumerate(charToIndex.keys()):
        charToIndex[char] = i
    print(charToIndex)

    num = tuple(charToIndex[char] for char in word)
    
#e.g.:
print(wordToNumericTuple("LALALA"))
73/33:
from collections import OrderedDict

def wordToNumericTuple(word):
    """
    Convert given word to a tuple of ints which will be identical for all friends.
    In the tuples each letter of the word is converted to an int, based on the location
    of the first instance of that letter in the word.
    Eg.
    if word = "LALALA"
    then 
    charToIndex = OrderedDict([('L', 0), ('A', 1)])
    and the resultant tuple = (0, 1, 0, 1, 0, 1)
    
    A tuple is returned so it can be used as a key in a dictionary, in order to count occurances of friends.
    """
    
    charToIndex = OrderedDict.fromkeys(word)
    for i, char in enumerate(charToIndex.keys()):
        charToIndex[char] = i

    num = tuple(charToIndex[char] for char in word)
    
#e.g.:
print(wordToNumericTuple("LALALA"))
73/34:
from collections import OrderedDict

def wordToNumericTuple(word):
    """
    Convert given word to a tuple of ints which will be identical for all friends.
    In the tuples each letter of the word is converted to an int, based on the location
    of the first instance of that letter in the word.
    Eg.
    if word = "LALALA"
    then 
    charToIndex = OrderedDict([('L', 0), ('A', 1)])
    and the resultant tuple = (0, 1, 0, 1, 0, 1)
    
    A tuple is returned so it can be used as a key in a dictionary, in order to count occurances of friends.
    """
    
    charToIndex = OrderedDict.fromkeys(word)
    for i, char in enumerate(charToIndex.keys()):
        charToIndex[char] = i

    return tuple(charToIndex[char] for char in word)
    
#e.g.:
print(wordToNumericTuple("LALALA"))
73/35:
from collections import OrderedDict

def wordToNumericTuple(word):
    """
    Convert given word to a tuple of ints which will be identical for all friends.
    In the tuples each letter of the word is converted to an int, based on the location
    of the first instance of that letter in the word.
    Eg.
    if word = "LALALA"
    then 
    charToIndex = OrderedDict([('L', 0), ('A', 1)])
    and the resultant tuple = (0, 1, 0, 1, 0, 1)
    
    A tuple is returned so it can be used as a key in a dictionary, in order to count occurances of friends.
    """
    
    charToIndex = OrderedDict.fromkeys(word)
    for i, char in enumerate(charToIndex.keys()):
        charToIndex[char] = i

    return tuple(charToIndex[char] for char in word)
    
#e.g.:
print("LALALA to tuple:")
print(wordToNumericTuple("LALALA"))
print("XOXOXO to tuple:")
print(wordToNumericTuple("XOXOXO"))
73/36:
from collections import OrderedDict

def wordToNumericTuple(word):
    """
    Convert given word to a tuple of ints which will be identical for all friends.
    In the tuples each letter of the word is converted to an int, based on the location
    of the first instance of that letter in the word.
    Eg.
    if word = "LALALA"
    then 
    charToIndex = OrderedDict([('L', 0), ('A', 1)])
    and the resultant tuple = (0, 1, 0, 1, 0, 1)
    
    A tuple is returned so it can be used as a key in a dictionary, in order to count occurances of friends.
    """
    
    charToIndex = OrderedDict.fromkeys(word)
    for i, char in enumerate(charToIndex.keys()):
        charToIndex[char] = i

    return tuple(charToIndex[char] for char in word)
    
#e.g.:
print("LALALA to tuple:")
print(wordToNumericTuple("LALALA"))
print("XOXOXO to tuple:")
print(wordToNumericTuple("XOXOXO"))
print("Both words result in the same tuple, because they are friends")
73/37:
#count all friends
from collections import Counter

friendCounts = Counter([wordToNumericTuple(word) for word in words])

friendCounts
73/38:
#count all friends
from collections import Counter

friendCounts = Counter([wordToNumericTuple(word) for word in words])

friendCounts
73/39:
#The above counts show a 2-word friend group, a 3-word friend group, and two words which have no friends.
#Inspecting the provided words, this seems correct.
73/40:
#wrap this all up in a function

def countNonLoners(words):
    """
    How many words in the given list are not loners?
    """
    friendCounts = Counter([wordToNumericTuple(word) for word in words])
    
    return sum(count for count in friendCounts.values if count > 1)

#eg:
countNonLoners(words)
73/41:
#wrap this all up in a function

def countNonLoners(words):
    """
    How many words in the given list are not loners?
    """
    friendCounts = Counter([wordToNumericTuple(word) for word in words])
    
    return sum(count for count in friendCounts.values() if count > 1)

#eg:
countNonLoners(words)
73/42:
#wrap this all up in a function

def countNonLoners(words):
    """
    How many words in the given list are not loners?
    """
    friendCounts = Counter([wordToNumericTuple(word) for word in words])
    
    return sum(count for count in friendCounts.values() if count > 1)

#eg:
print('Num non loners: {}'.format(countNonLoners(words))
73/43:
#wrap this all up in a function

def countNonLoners(words):
    """
    How many words in the given list are not loners?
    """
    friendCounts = Counter([wordToNumericTuple(word) for word in words])
    
    return sum(count for count in friendCounts.values() if count > 1)

#eg:
print('Num non loners: {}'.format(countNonLoners(words)))
73/44:
#wrap this all up in a function

def countNonLoners(words):
    """
    How many words in the given list are not loners?
    """
    friendCounts = Counter([wordToNumericTuple(word) for word in words])
    
    return sum(count for count in friendCounts.values() if count > 1)

#eg:
print('Number of non-loner words: {}'.format(countNonLoners(words)))
73/45:
#wrap this all up in a function

def countNonLoners(words):
    """
    How many words in the given list are not loners?
    """
    friendCounts = Counter([wordToNumericTuple(word) for word in words])
    
    return sum(count for count in friendCounts.values() if count > 1)

#eg:
print('Number of non-loner words: {}'.format(countNonLoners(words)))
73/46:
#The function gives the expected result on the example. 
#Now try on the provided data.

dataAddress = 'https://drive.google.com/uc?id=0By5aT61a8aD8WlVpWU9CSU9ubUU&export=download'
dataZipname = 'testData.zip'
import urllib
urllib.urlretrieve (dataAddress, dataZipname)
73/47:
#The function gives the expected result on the example. 
#Now try on the provided data.

dataAddress = 'https://drive.google.com/uc?id=0By5aT61a8aD8WlVpWU9CSU9ubUU&export=download'
dataZipname = 'testData.zip'
import urllib.request
urllib.request.urlretrievedataAddress, dataZipname)
73/48:
#The function gives the expected result on the example. 
#Now try on the provided data.

dataAddress = 'https://drive.google.com/uc?id=0By5aT61a8aD8WlVpWU9CSU9ubUU&export=download'
dataZipname = 'testData.zip'
import urllib.request
urllib.request.urlretrieve(dataAddress, dataZipname)
73/49:
#The function gives the expected result on the example. 
#Now try on the provided data.

dataAddress = 'https://drive.google.com/uc?id=0By5aT61a8aD8WlVpWU9CSU9ubUU&export=download'
dataZipname = 'testData.zip'
import urllib.request
urllib.request.urlretrieve(dataAddress, dataZipname)
73/50:
import zipfile
zip_ref = zipfile.ZipFile(dataZipname, 'r')
zip_ref.extractall()
zip_ref.close()
73/51:
import zipfile
dataFilename = 'words.txt'
zip_ref = zipfile.ZipFile(dataZipname, 'r')
zip_ref.extractall()
zip_ref.close()
73/52:
testWords = """
LALALA
XOXOXO
GCGCGC
HHHCCC
BBBMMM
EGONUH
HHRGOE
""".strip().split('\n')

testWords
73/53:
dataFilename = 'words.txt'
with open(dataFilename) as f:
    words = f.read().splitlines()
73/54:
dataFilename = 'words.txt'
with open(dataFilename) as f:
    words = f.read().splitlines()
len(words)
73/55:
dataFilename = 'words.txt'
with open(dataFilename) as f:
    words = f.read().splitlines()
print('Read {} words'.format(len(words)))
73/56:
#The function gives the expected result on the example. 
#Now try on the provided data.
import urllib.request

dataAddress = 'https://drive.google.com/uc?id=0By5aT61a8aD8WlVpWU9CSU9ubUU&export=download'
dataZipname = 'testData.zip'
dataFilename = 'words.txt'

#download
urllib.request.urlretrieve(dataAddress, dataZipname)

#unzip
zip_ref = zipfile.ZipFile(dataZipname, 'r')
zip_ref.extractall()
zip_ref.close()

#read
with open(dataFilename) as f:
    words = f.read().splitlines()
print('Read {} words'.format(len(words)))
73/57:
#The function gives the expected result on the example. 
#Now try on the provided data.
import urllib.request

dataAddress = 'https://drive.google.com/uc?id=0By5aT61a8aD8WlVpWU9CSU9ubUU&export=download'
dataZipname = 'testData.zip'
dataFilename = 'words.txt'

#download
urllib.request.urlretrieve(dataAddress, dataZipname)

#unzip
zip_ref = zipfile.ZipFile(dataZipname, 'r')
zip_ref.extractall()
zip_ref.close()

#read
with open(dataFilename) as f:
    words = f.read().splitlines()
print('Read {} words'.format(len(words)))
73/58: print('Number of non-loner words in downloaded file: {}'.format(countNonLoners(downloadedWords)))
73/59:
#The function gives the expected result on the example. 
#Now try on the provided data.
import urllib.request

dataAddress = 'https://drive.google.com/uc?id=0By5aT61a8aD8WlVpWU9CSU9ubUU&export=download'
dataZipname = 'testData.zip'
dataFilename = 'words.txt'

#download
urllib.request.urlretrieve(dataAddress, dataZipname)

#unzip
zip_ref = zipfile.ZipFile(dataZipname, 'r')
zip_ref.extractall()
zip_ref.close()

#read
with open(dataFilename) as f:
    downloadedWords = f.read().splitlines()
print('Read {} words'.format(len(downloadedWords)))
73/60: print('Number of non-loner words in downloaded file: {}'.format(countNonLoners(downloadedWords)))
73/61: print('Number of non-loner words in downloaded file: {}'.format(countNonLoners(downloadedWords)))
74/1:
testWords = """
LALALA
XOXOXO
GCGCGC
HHHCCC
BBBMMM
EGONUH
HHRGOE
""".strip().split('\n')

testWords
74/2:
from collections import OrderedDict

def wordToNumericTuple(word):
    """
    Convert given word to a tuple of ints which will be identical for all friends.
    In the tuples each letter of the word is converted to an int, based on the location
    of the first instance of that letter in the word.
    Eg.
    if word = "LALALA"
    then 
    charToIndex = OrderedDict([('L', 0), ('A', 1)])
    and the resultant tuple = (0, 1, 0, 1, 0, 1)
    
    A tuple is returned so it can be used as a key in a dictionary, in order to count occurances of friends.
    """
    
    charToIndex = OrderedDict.fromkeys(word)
    for i, char in enumerate(charToIndex.keys()):
        charToIndex[char] = i

    return tuple(charToIndex[char] for char in word)
    
#e.g.:
print("LALALA to tuple:")
print(wordToNumericTuple("LALALA"))
print("XOXOXO to tuple:")
print(wordToNumericTuple("XOXOXO"))
print("Both words result in the same tuple, because they are friends")
74/3:
#count all friends
from collections import Counter

friendCounts = Counter([wordToNumericTuple(word) for word in testWords])

friendCounts
74/4:
#The above counts show a 2-word friend group, a 3-word friend group, and two words which have no friends.
#Inspecting the provided words, this seems correct.
74/5:
#wrap this all up in a function

def countNonLoners(words):
    """
    How many words in the given list are not loners?
    """
    friendCounts = Counter([wordToNumericTuple(word) for word in words])
    
    return sum(count for count in friendCounts.values() if count > 1)

#eg:
print('Number of non-loner words: {}'.format(countNonLoners(testWords)))
74/6:
#The function gives the expected result on the example. 
#Now try on the provided data.
import urllib.request

dataAddress = 'https://drive.google.com/uc?id=0By5aT61a8aD8WlVpWU9CSU9ubUU&export=download'
dataZipname = 'testData.zip'
dataFilename = 'words.txt'

#download
urllib.request.urlretrieve(dataAddress, dataZipname)

#unzip
zip_ref = zipfile.ZipFile(dataZipname, 'r')
zip_ref.extractall()
zip_ref.close()

#read
with open(dataFilename) as f:
    downloadedWords = f.read().splitlines()
print('Read {} words'.format(len(downloadedWords)))
75/1:
testWords = """
LALALA
XOXOXO
GCGCGC
HHHCCC
BBBMMM
EGONUH
HHRGOE
""".strip().split('\n')

testWords
75/2:
from collections import OrderedDict

def wordToNumericTuple(word):
    """
    Convert given word to a tuple of ints which will be identical for all friends.
    In the tuples each letter of the word is converted to an int, based on the location
    of the first instance of that letter in the word.
    Eg.
    if word = "LALALA"
    then 
    charToIndex = OrderedDict([('L', 0), ('A', 1)])
    and the resultant tuple = (0, 1, 0, 1, 0, 1)
    
    A tuple is returned so it can be used as a key in a dictionary, in order to count occurances of friends.
    """
    
    charToIndex = OrderedDict.fromkeys(word)
    for i, char in enumerate(charToIndex.keys()):
        charToIndex[char] = i

    return tuple(charToIndex[char] for char in word)
    
#e.g.:
print("LALALA to tuple:")
print(wordToNumericTuple("LALALA"))
print("XOXOXO to tuple:")
print(wordToNumericTuple("XOXOXO"))
print("Both words result in the same tuple, because they are friends")
75/3:
#count all friends
from collections import Counter

friendCounts = Counter([wordToNumericTuple(word) for word in testWords])

friendCounts
75/4:
#The above counts show a 2-word friend group, a 3-word friend group, and two words which have no friends.
#Inspecting the provided words, this seems correct.
75/5:
#wrap this all up in a function

def countNonLoners(words):
    """
    How many words in the given list are not loners?
    """
    friendCounts = Counter([wordToNumericTuple(word) for word in words])
    
    return sum(count for count in friendCounts.values() if count > 1)

#eg:
print('Number of non-loner words: {}'.format(countNonLoners(testWords)))
75/6:
#The function gives the expected result on the example. 
#Now try on the provided data.
import urllib.request
import zipfile

dataAddress = 'https://drive.google.com/uc?id=0By5aT61a8aD8WlVpWU9CSU9ubUU&export=download'
dataZipname = 'testData.zip'
dataFilename = 'words.txt'

#download
urllib.request.urlretrieve(dataAddress, dataZipname)

#unzip
zip_ref = zipfile.ZipFile(dataZipname, 'r')
zip_ref.extractall()
zip_ref.close()

#read
with open(dataFilename) as f:
    downloadedWords = f.read().splitlines()
print('Read {} words'.format(len(downloadedWords)))
75/7: print('Number of non-loner words in downloaded file: {}'.format(countNonLoners(downloadedWords)))
75/8:
#The function gives the expected result on the example. 
#Now try on the provided data.
import urllib.request
import zipfile

dataAddress = 'https://drive.google.com/uc?id=0By5aT61a8aD8WlVpWU9CSU9ubUU&export=download'
dataZipname = 'testData.zip'
dataFilename = 'words.txt'

#download
urllib.request.urlretrieve(dataAddress, dataZipname)

#unzip
zip_ref = zipfile.ZipFile(dataZipname, 'r')
zip_ref.extractall()
zip_ref.close()

#read
with open(dataFilename) as f:
    downloadedWords = f.read().splitlines()
print('Read {} words'.format(len(downloadedWords)))
print('First 10 words:')
print(downloadedWords[0:10])
76/1:
testWords = """
LALALA
XOXOXO
GCGCGC
HHHCCC
BBBMMM
EGONUH
HHRGOE
""".strip().split('\n')

testWords
76/2:
from collections import OrderedDict

def wordToNumericTuple(word):
    """
    Convert given word to a tuple of ints which will be identical for all friends.
    In the tuples each letter of the word is converted to an int, based on the location
    of the first instance of that letter in the word.
    Eg.
    if word = "LALALA"
    then 
    charToIndex = OrderedDict([('L', 0), ('A', 1)])
    and the resultant tuple = (0, 1, 0, 1, 0, 1)
    
    A tuple is returned so it can be used as a key in a dictionary, in order to count occurances of friends.
    """
    
    charToIndex = OrderedDict.fromkeys(word)
    for i, char in enumerate(charToIndex.keys()):
        charToIndex[char] = i

    return tuple(charToIndex[char] for char in word)
    
#e.g.:
print("LALALA to tuple:")
print(wordToNumericTuple("LALALA"))
print("XOXOXO to tuple:")
print(wordToNumericTuple("XOXOXO"))
print("Both words result in the same tuple, because they are friends")
76/3:
#count all friends
from collections import Counter

friendCounts = Counter([wordToNumericTuple(word) for word in testWords])

friendCounts
76/4:
#The above counts show a 2-word friend group, a 3-word friend group, and two words which have no friends.
#Inspecting the provided words, this seems correct.
76/5:
#wrap this all up in a function

def countNonLoners(words):
    """
    How many words in the given list are not loners?
    """
    friendCounts = Counter([wordToNumericTuple(word) for word in words])
    
    return sum(count for count in friendCounts.values() if count > 1)

#eg:
print('Number of non-loner words: {}'.format(countNonLoners(words)))
77/1:
testWords = """
LALALA
XOXOXO
GCGCGC
HHHCCC
BBBMMM
EGONUH
HHRGOE
""".strip().split('\n')

testWords
77/2:
from collections import OrderedDict

def wordToNumericTuple(word):
    """
    Convert given word to a tuple of ints which will be identical for all friends.
    In the tuples each letter of the word is converted to an int, based on the location
    of the first instance of that letter in the word.
    Eg.
    if word = "LALALA"
    then 
    charToIndex = OrderedDict([('L', 0), ('A', 1)])
    and the resultant tuple = (0, 1, 0, 1, 0, 1)
    
    A tuple is returned so it can be used as a key in a dictionary, in order to count occurances of friends.
    """
    
    charToIndex = OrderedDict.fromkeys(word)
    for i, char in enumerate(charToIndex.keys()):
        charToIndex[char] = i

    return tuple(charToIndex[char] for char in word)
    
#e.g.:
print("LALALA to tuple:")
print(wordToNumericTuple("LALALA"))
print("XOXOXO to tuple:")
print(wordToNumericTuple("XOXOXO"))
print("Both words result in the same tuple, because they are friends")
77/3:
#count all friends
from collections import Counter

friendCounts = Counter([wordToNumericTuple(word) for word in testWords])

friendCounts
77/4:
#The above counts show a 2-word friend group, a 3-word friend group, and two words which have no friends.
#Inspecting the provided words, this seems correct.
77/5:
#wrap this all up in a function

def countNonLoners(words):
    """
    How many words in the given list are not loners?
    """
    friendCounts = Counter([wordToNumericTuple(word) for word in words])
    
    return sum(count for count in friendCounts.values() if count > 1)

#eg:
print('Number of non-loner words: {}'.format(countNonLoners(testWords)))
77/6:
#The function gives the expected result on the example. 
#Now try on the provided data.
import urllib.request
import zipfile

dataAddress = 'https://drive.google.com/uc?id=0By5aT61a8aD8WlVpWU9CSU9ubUU&export=download'
dataZipname = 'testData.zip'
dataFilename = 'words.txt'

#download
urllib.request.urlretrieve(dataAddress, dataZipname)

#unzip
zip_ref = zipfile.ZipFile(dataZipname, 'r')
zip_ref.extractall()
zip_ref.close()

#read
with open(dataFilename) as f:
    downloadedWords = f.read().splitlines()
print('Read {} words'.format(len(downloadedWords)))
print('First 10 words:')
for word in downloadedWords[0:10]:
    print(word)
77/7: print('Number of non-loner words in downloaded file: {}'.format(countNonLoners(downloadedWords)))
78/1: from arduino_control.srv import PublishAnalog
79/1: import rospy
80/1: import rospy
81/1: import rospy
82/1: import rospy
84/1: import rospy
86/1: import rospy
86/2: nh = rospy.init_node('test2')
86/3: rospy.Time.now()
86/4: rospy.Time.now().to_sec()
86/5: rospy.Time.now().to_sec()
87/1: import pandas as pd
88/1: import pandas
88/2: import pandas as pd
88/3: import pandas as pd
88/4:
import pandas as pd

pluckOnly = pd.read_csv('pluckSensorLogs/pluckOnly.csv')

pluckOnly
88/5:
import pandas as pd

pluckOnly = pd.read_csv('pluckSensorLogs/pluckOnly.csv')

pluckOnly
88/6:
import pandas as pd

pluckOnly = pd.read_csv('pluckSensorLogs/pluckOnly.csv', header=False)

pluckOnly
88/7:
import pandas as pd

pluckOnly = pd.read_csv('pluckSensorLogs/pluckOnly.csv', header=None)

pluckOnly
88/8:
import pandas as pd

pluckOnly = pd.read_csv('pluckSensorLogs/pluckOnly.csv', header=None, names=['timestamp', 'value'])

pluckOnly
88/9:
import pandas as pd

pluckOnly = pd.read_csv('pluckSensorLogs/pluckOnly.csv', header=None, names=['timestamp', 'value'])

pluckOnly
88/10:
import pandas as pd

pluckOnly = pd.read_csv('pluckSensorLogs/pluckOnly.csv', header=None, names=['timestamp', 'value'])

pluckOnly
88/11:
import pandas as pd

pluckOnly = pd.read_csv('pluckSensorLogs/pluckOnly.csv', header=None, names=['timestamp', 'value'])

pluckOnly
88/12: import plotly
88/13: import plotly
88/14:
import plotly

# Create a trace
trace = go.Scatter(
    x = pluckOnly.timestamp,
    y = pluckOnly.value
)

data = [trace]

py.iplot(data, filename='basic-line')
88/15:

import plotly.plotly as py
import plotly.graph_objs as go


# Create a trace
trace = go.Scatter(
    x = pluckOnly.timestamp,
    y = pluckOnly.value
)

data = [trace]

py.iplot(data, filename='basic-line')
88/16:

import plotly.plotly as py
import plotly.graph_objs as go


# Create a trace
trace = go.Scattergl(
    x = pluckOnly.timestamp,
    y = pluckOnly.value
)

data = [trace]

py.iplot(data, filename='basic-line')
88/17:

import plotly.plotly as py
import plotly.graph_objs as go

init_notebook_mode(connected=False)


# Create a trace
trace = go.Scattergl(
    x = pluckOnly.timestamp,
    y = pluckOnly.value
)

data = [trace]

py.iplot(data, filename='basic-line')
88/18:

import plotly.plotly as py
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot


init_notebook_mode(connected=True)


# Create a trace
trace = go.Scattergl(
    x = pluckOnly.timestamp,
    y = pluckOnly.value
)

data = [trace]

py.iplot(data, filename='basic-line')
88/19:

import plotly.plotly as py
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot


init_notebook_mode(connected=True)


# Create a trace
trace = go.Scattergl(
    x = pluckOnly.timestamp,
    y = pluckOnly.value
)

data = [trace]

iplot(data, filename='basic-line')
88/20:
import pandas as pd

loadCsv = lambda filename : pd.read_csv(filename, header=None, names=['timestamp', 'value']) 
pluckOnly = loadCsv('pluckSensorLogs/pluckOnly.csv')

pluckOnly
88/21:
#View raw pluck data

import plotly.plotly as py
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot


init_notebook_mode(connected=True)


# Create a trace
trace = go.Scattergl(
    x = pluckOnly.timestamp,
    y = pluckOnly.value
)

data = [trace]

iplot(data, filename='basic-line')
88/22:
#View raw pluck data

import plotly.plotly as py
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot


init_notebook_mode(connected=True)


# Create a trace
trace = go.Scattergl(
    x = pluckOnly.timestamp,
    y = pluckOnly.value
)

data = [trace]

iplot(data, filename='basic-line')
88/23:
#look at a sinlge pluck
#from the above plot, there is a pluck between t = 130.6M and 130.9M
startTime = 130.6 * 10e6
stopTime = 130.9 * 10e6
singlePluck = pluckOnly.loc[(pluckOnly['timestamp'] > startTime) & (pluckOnly['timestamp'] < stopTime)]
88/24:
#look at a sinlge pluck
#from the above plot, there is a pluck between t = 130.6M and 130.9M
startTime = 130.6 * 10e6
stopTime = 130.9 * 10e6
singlePluck = pluckOnly.loc[(pluckOnly['timestamp'] > startTime) & (pluckOnly['timestamp'] < stopTime)]
singlePluck
88/25:
#look at a sinlge pluck
#from the above plot, there is a pluck between t = 130.6M and 130.9M
startTime = 130.6 * 10e6
stopTime = 130.9 * 10e6
singlePluck = pluckOnly.loc[(pluckOnly['timestamp'] > startTime) and (pluckOnly['timestamp'] < stopTime)]
singlePluck
88/26:
#look at a sinlge pluck
#from the above plot, there is a pluck between t = 130.6M and 130.9M
startTime = 130.6 * 10e6
stopTime = 130.9 * 10e6
singlePluck = pluckOnly[pluckOnly['timestamp'].between(startTime, stopTime)]
singlePluck
88/27:
#look at a sinlge pluck
#from the above plot, there is a pluck between t = 130.6M and 130.9M
startTime = 130.6 * 1e6
stopTime = 130.9 * 1e6
singlePluck = pluckOnly[pluckOnly['timestamp'].between(startTime, stopTime)]
singlePluck
88/28:
#View raw pluck data

import plotly.plotly as py
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot


init_notebook_mode(connected=True)

def plotTrace(traceData):
    # Create a trace
    trace = go.Scattergl(
        x = traceData.timestamp,
        y = traceData.value
    )

    data = [trace]

    iplot(data, filename='basic-line')
    
plotTrace(pluckOnly)
88/29:
#look at a sinlge pluck
#from the above plot, there is a pluck between t = 130.6M and 130.9M
startTime = 130.6 * 1e6
stopTime = 130.9 * 1e6
singlePluck = pluckOnly[pluckOnly['timestamp'].between(startTime, stopTime)]

plotTrace(singlePluck)
88/30:
#look at a sinlge pluck
#from the above plot, there is a pluck between t = 130.65M and 130.75M
startTime = 130.65 * 1e6
stopTime = 130.75 * 1e6
singlePluck = pluckOnly[pluckOnly['timestamp'].between(startTime, stopTime)]

plotTrace(singlePluck)
88/31:
#look at a sinlge pluck
#from the above plot, there is a pluck between t = 130.65M and 130.75M
startTime = 130.66 * 1e6
stopTime = 130.7 * 1e6
singlePluck = pluckOnly[pluckOnly['timestamp'].between(startTime, stopTime)]

plotTrace(singlePluck)
88/32:
#Regarding sample rate - what is the sample rate at which this data was collected?
sampleRate = len(pluckOnly.index)
88/33:
#Regarding sample rate - what is the sample rate at which this data was collected?
sampleRate = len(pluckOnly.index)

sampleRate
88/34:
#Regarding sample rate - what is the sample rate at which this data was collected?
nSamples = len(pluckOnly.index) 
dTime = (pluckOnly.timestamp.max() - pluckOnly.timestamp.max()) / 1e6 #seconds

sampleRate
88/35:
#Regarding sample rate - what is the sample rate at which this data was collected?
nSamples = len(pluckOnly.index) 
dTime = (pluckOnly.timestamp.max() - pluckOnly.timestamp.max()) / 1e6 #seconds

dTime
88/36:
#Regarding sample rate - what is the sample rate at which this data was collected?
nSamples = len(pluckOnly.index) 
dTime = (pluckOnly.timestamp.max() - pluckOnly.timestamp.min()) / 1e6 #seconds

dTime
88/37:
#Regarding sample rate - what is the sample rate at which this data was collected?
nSamples = len(pluckOnly.index) 
dTime = (pluckOnly.timestamp.max() - pluckOnly.timestamp.min()) / 1e6 #seconds

sampleRate = nSamples / dTime
sampleRate
88/38:
import pandas as pd

def loadCsv(filename) :
    frame = pd.read_csv(filename, header=None, names=['timestamp', 'value']) 
    frame.timestamp = frame.timestamp * 1e-6 # micros to seconds
    return frame

pluckOnly = loadCsv('pluckSensorLogs/pluckOnly.csv')

pluckOnly
88/39:
#View raw pluck data

import plotly.plotly as py
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot


init_notebook_mode(connected=True)

def plotTrace(traceData):
    # Create a trace
    trace = go.Scattergl(
        x = traceData.timestamp,
        y = traceData.value
    )

    data = [trace]

    iplot(data, filename='basic-line')
    
plotTrace(pluckOnly)
88/40:
#Regarding sample rate - what is the sample rate at which this data was collected?
nSamples = len(pluckOnly.index) 
dTime = pluckOnly.timestamp.max() - pluckOnly.timestamp.min()

sampleRate = nSamples / dTime
sampleRate
#result - sample rate is about 8KHz
88/41:
#look at a sinlge pluck
#from the above plot, there is a pluck between t = 130.65 and 130.75
startTime = 130.66
stopTime = 130.7
singlePluck = pluckOnly[pluckOnly['timestamp'].between(startTime, stopTime)]

plotTrace(singlePluck)
88/42:
#look at a sinlge pluck
#from the above plot, there is a pluck between t = 130.65 and 130.75
startTime = 130.66
stopTime = 130.7
singlePluck = pluckOnly[pluckOnly['timestamp'].between(startTime, stopTime)]

plotTrace(singlePluck)
88/43:
The pluck triggers a voltage disturbance lasting about 10ms, so you'd need to sample at a least 100Hz to get a single
reading while the voltage is reacting to the pluck. However during this period the voltage is sometimes very close
to the steady-state value, so you'd need to take a few samples to ensure the disturbance is detected.

Maybe about 1KHz is a safe lower limit to the sampling frequency
88/44:
#Idea: detect pluck with a sliding-window variance metric
singlePluck.rolling(2, win_type='triang').variance()
88/45:
#Idea: detect pluck with a sliding-window variance metric
singlePluck.rolling(10).variance()
88/46:
#Idea: detect pluck with a sliding-window variance metric
#singlePluck.rolling(10).variance()
singlePluck.var
88/47:
#Idea: detect pluck with a sliding-window variance metric
#singlePluck.rolling(10).variance()
singlePluck.var()
88/48:
#Idea: detect pluck with a sliding-window variance metric
singlePluck.rolling(10).var()
88/49:
#Idea: detect pluck with a sliding-window variance metric
rollingVar = singlePluck.rolling(10).var()
plotTrace(rollingVar)
88/50:
#Idea: detect pluck with a sliding-window variance metric
rollingVar = singlePluck.rolling(10).var()
plotTrace(rollingVar)
rollingVar
88/51:
#Idea: detect pluck with a sliding-window variance metric
rollingVar = singlePluck.rolling(10, axis='value').var()
plotTrace(rollingVar)
rollingVar
88/52:
#Idea: detect pluck with a sliding-window variance metric
rollingVar = singlePluck.rolling(10).var()[,'value']
plotTrace(rollingVar)
rollingVar
88/53:
#Idea: detect pluck with a sliding-window variance metric
rollingVar = singlePluck.rolling(10).var()
plotTrace(rollingVar)
rollingVar
88/54:
#Idea: detect pluck with a sliding-window variance metric
rollingVar = singlePluck.rolling(10).var()
rollingVar.timestamp = singlePluck.timestamp
plotTrace(rollingVar)
rollingVar
88/55:
#Idea: detect pluck with a sliding-window variance metric
rollingVar = singlePluck.rolling(20).var()
rollingVar.timestamp = singlePluck.timestamp
plotTrace(rollingVar)
rollingVar
88/56:
#Idea: detect pluck with a sliding-window variance metric
rollingVar = singlePluck.rolling(50).var()
rollingVar.timestamp = singlePluck.timestamp
plotTrace(rollingVar)
rollingVar
88/57:
#Idea: detect pluck with a sliding-window variance metric
rollingVar = singlePluck.rolling(80).var()
rollingVar.timestamp = singlePluck.timestamp
plotTrace(rollingVar)
rollingVar
88/58:
#Idea: detect pluck with a sliding-window variance metric
def computeRollingVariance(data):
    rollingVar = data.rolling(80).var()
    rollingVar.timestamp = data.timestamp
    return rollingVar

rollingVar = computeRollingVariance(data)
plotTrace(rollingVar)
88/59:
#Idea: detect pluck with a sliding-window variance metric
def computeRollingVariance(data):
    rollingVar = data.rolling(80).var()
    rollingVar.timestamp = data.timestamp
    return rollingVar

rollingVar = computeRollingVariance(singlePluck)
plotTrace(rollingVar)
88/60:
#Idea: detect pluck with a sliding-window variance metric
def computeRollingVariance(data):
    rollingVar = data.rolling(80).var()
    rollingVar.timestamp = data.timestamp
    return rollingVar

rollingVar = computeRollingVariance(singlePluck)
plotTrace(rollingVar)
88/61:
#Idea: detect pluck with a sliding-window variance metric
def computeRollingVariance(data):
    rollingVar = data.rolling(80).var()
    rollingVar.timestamp = data.timestamp
    return rollingVar

rollingVarSingle = computeRollingVariance(singlePluck)
plotTrace(rollingVarSingle)

rollingVarAll = computeRollingVariance(pluckOnly)
plotTrace(rollingVarAll)
88/62:
import pandas as pd

def loadCsv(filename) :
    frame = pd.read_csv(filename, header=None, names=['timestamp', 'value']) 
    frame.timestamp = frame.timestamp * 1e-6 # micros to seconds
    return frame

pluckOnly = loadCsv('pluckSensorLogs/pluckOnly.csv')

drawOnly = loadCsv('pluckSensorLogs/drawOnly.csv')

pluckOnly
88/63:
#Idea: detect pluck with a sliding-window variance metric
def computeRollingVariance(data):
    rollingVar = data.rolling(80).var()
    rollingVar.timestamp = data.timestamp
    return rollingVar

rollingVarSingle = computeRollingVariance(singlePluck)
plotTrace(rollingVarSingle)

rollingVarAll = computeRollingVariance(pluckOnly)
plotTrace(rollingVarAll)

rollingVarDraw = computeRollingVariance(pluckOnly)
plotTrace(rollingVarDraw)
88/64:
#Idea: detect pluck with a sliding-window variance metric
def computeRollingVariance(data):
    rollingVar = data.rolling(80).var()
    rollingVar.timestamp = data.timestamp
    return rollingVar

rollingVarSingle = computeRollingVariance(singlePluck)
plotTrace(rollingVarSingle)

rollingVarAll = computeRollingVariance(pluckOnly)
plotTrace(rollingVarAll)

rollingVarDraw = computeRollingVariance(drawOnly)
plotTrace(rollingVarDraw)
88/65:
#View raw pluck data

import plotly.plotly as py
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot


init_notebook_mode(connected=True)

def plotTrace(traceData):
    # Create a trace
    trace = go.Scattergl(
        x = traceData.timestamp,
        y = traceData.value
    )

    data = [trace]

    iplot(data, filename='basic-line')
    
plotTrace(pluckOnly)
plotTrace(drawOnly)
88/66:
import pandas as pd

def loadCsv(filename) :
    frame = pd.read_csv(filename, header=None, names=['timestamp', 'value']) 
    frame.timestamp = frame.timestamp * 1e-6 # micros to seconds
    return frame

pluckOnly = loadCsv('pluckSensorLogs/pluckOnly.csv')

drawOnly = loadCsv('pluckSensorLogs/drawOnly.csv')

pluckOnly
88/67:
#View raw pluck data

import plotly.plotly as py
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot


init_notebook_mode(connected=True)

def plotTrace(traceData):
    # Create a trace
    trace = go.Scattergl(
        x = traceData.timestamp,
        y = traceData.value
    )

    data = [trace]

    iplot(data, filename='basic-line')
    
plotTrace(pluckOnly)
plotTrace(drawOnly)
88/68:
#Idea: detect pluck with a sliding-window variance metric
def computeRollingVariance(data):
    rollingVar = data.rolling(80).var()
    rollingVar.timestamp = data.timestamp
    return rollingVar

rollingVarSingle = computeRollingVariance(singlePluck)
plotTrace(rollingVarSingle)

rollingVarAll = computeRollingVariance(pluckOnly)
plotTrace(rollingVarAll)

rollingVarDraw = computeRollingVariance(drawOnly)
plotTrace(rollingVarDraw)
88/69:
# Rather than simulating different sample rates on the above data to determine the best option, 
# I just set it to 2kHz and took some data to see if that rate is suitabel (lazy option :s)
# Have a look at the traces

plucks2Khz = loadCsv('pluckSensorLogs/plucksOnly2kHz.csv')

plotTrace(plucks2Khz)
88/70:
# Rather than simulating different sample rates on the above data to determine the best option, 
# I just set it to 2kHz and took some data to see if that rate is suitabel (lazy option :s)
# Have a look at the traces

plucks2Khz = loadCsv('pluckSensorLogs/plucksOnly2kHz.csv')

plotTrace(plucks2Khz)
plucks2Khz
88/71:
# Rather than simulating different sample rates on the above data to determine the best option, 
# I just set it to 2kHz and took some data to see if that rate is suitabel (lazy option :s)
# Have a look at the traces

plucks2Khz = loadCsv('pluckSensorLogs/plucksOnly2kHz.csv')

#plotTrace(plucks2Khz)
plucks2Khz
88/72:
import pandas as pd

def loadCsv(filename) :
    frame = pd.read_csv(filename, header=None, names=['timestamp', 'value'], index_col = False) 
    frame.timestamp = frame.timestamp * 1e-6 # micros to seconds
    return frame

pluckOnly = loadCsv('pluckSensorLogs/pluckOnly.csv')

drawOnly = loadCsv('pluckSensorLogs/drawOnly.csv')

pluckOnly
88/73:
# Rather than simulating different sample rates on the above data to determine the best option, 
# I just set it to 2kHz and took some data to see if that rate is suitabel (lazy option :s)
# Have a look at the traces

plucks2Khz = loadCsv('pluckSensorLogs/plucksOnly2kHz.csv')

#plotTrace(plucks2Khz)
plucks2Khz
88/74:
# Rather than simulating different sample rates on the above data to determine the best option, 
# I just set it to 2kHz and took some data to see if that rate is suitabel (lazy option :s)
# Have a look at the traces

plucks2Khz = loadCsv('pluckSensorLogs/plucksOnly2kHz.csv')

plotTrace(plucks2Khz)
88/75:
#View raw pluck data

import plotly.plotly as py
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot


init_notebook_mode(connected=True)

def plotTrace(traceData):
    # Create a trace
    trace = go.Scattergl(
        x = traceData.timestamp,
        y = traceData.value
    )

    data = [trace]

    iplot(data, filename='basic-line')
    
plotTrace(pluckOnly)
plotTrace(drawOnly)
88/76:
#look at a sinlge pluck
#from the above plot, there is a pluck between t = 130.65 and 130.75
startTime = 130.66
stopTime = 130.7
singlePluck = pluckOnly[pluckOnly['timestamp'].between(startTime, stopTime)]

plotTrace(singlePluck)
88/77:
# Rather than simulating different sample rates on the above data to determine the best option, 
# I just set it to 2kHz and took some data to see if that rate is suitabel (lazy option :s)
# Have a look at the traces

plucks2Khz = loadCsv('pluckSensorLogs/plucksOnly2kHz.csv')

plotTrace(plucks2Khz)
88/78:
# Rather than simulating different sample rates on the above data to determine the best option, 
# I just set it to 2kHz and took some data to see if that rate is suitabel (lazy option :s)
# Have a look at the traces

plucks2Khz = loadCsv('pluckSensorLogs/plucksOnly2kHz.csv')

plotTrace(plucks2Khz)
plotTrace(rollingVar(plucks2Khz))
88/79:
# Rather than simulating different sample rates on the above data to determine the best option, 
# I just set it to 2kHz and took some data to see if that rate is suitabel (lazy option :s)
# Have a look at the traces

plucks2Khz = loadCsv('pluckSensorLogs/plucksOnly2kHz.csv')

plotTrace(plucks2Khz)
plotTrace(computeRollingVariance(plucks2Khz))
88/80:
# Rather than simulating different sample rates on the above data to determine the best option, 
# I just set it to 2kHz and took some data to see if that rate is suitabel (lazy option :s)
# Have a look at the traces

plucks2Khz = loadCsv('pluckSensorLogs/plucksOnly2kHz.csv')

plotTrace(plucks2Khz)
plotTrace(computeRollingVariance(plucks2Khz, windowSize = 30))
88/81:
#Idea: detect pluck with a sliding-window variance metric
def computeRollingVariance(data, windowSize = 80):
    rollingVar = data.rolling(windowSize).var()
    rollingVar.timestamp = data.timestamp
    return rollingVar

rollingVarSingle = computeRollingVariance(singlePluck)
plotTrace(rollingVarSingle)

rollingVarAll = computeRollingVariance(pluckOnly)
plotTrace(rollingVarAll)

rollingVarDraw = computeRollingVariance(drawOnly)
plotTrace(rollingVarDraw)
88/82:
# Rather than simulating different sample rates on the above data to determine the best option, 
# I just set it to 2kHz and took some data to see if that rate is suitabel (lazy option :s)
# Have a look at the traces

plucks2Khz = loadCsv('pluckSensorLogs/plucksOnly2kHz.csv')

plotTrace(plucks2Khz)
plotTrace(computeRollingVariance(plucks2Khz, windowSize = 30))
88/83:
#Idea: detect pluck with a sliding-window variance metric
def computeRollingVariance(data, windowSize = 80):
    rollingVar = data.rolling(windowSize).std()
    rollingVar.timestamp = data.timestamp
    return rollingVar

rollingVarSingle = computeRollingVariance(singlePluck)
plotTrace(rollingVarSingle)

rollingVarAll = computeRollingVariance(pluckOnly)
plotTrace(rollingVarAll)

rollingVarDraw = computeRollingVariance(drawOnly)
plotTrace(rollingVarDraw)
89/1:
import pandas as pd

def loadCsv(filename) :
    frame = pd.read_csv(filename, header=None, names=['timestamp', 'value'], index_col = False) 
    frame.timestamp = frame.timestamp * 1e-6 # micros to seconds
    return frame

pluckOnly = loadCsv('pluckSensorLogs/pluckOnly.csv')

drawOnly = loadCsv('pluckSensorLogs/drawOnly.csv')

pluckOnly
89/2:
#View raw pluck data

import plotly.plotly as py
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot


init_notebook_mode(connected=True)

def plotTrace(traceData):
    # Create a trace
    trace = go.Scattergl(
        x = traceData.timestamp,
        y = traceData.value
    )

    data = [trace]

    iplot(data, filename='basic-line')
    
plotTrace(pluckOnly)
plotTrace(drawOnly)
89/3:
#Regarding sample rate - what is the sample rate at which this data was collected?
nSamples = len(pluckOnly.index) 
dTime = pluckOnly.timestamp.max() - pluckOnly.timestamp.min()

sampleRate = nSamples / dTime
sampleRate
#result - sample rate is about 8KHz
89/4:
#look at a sinlge pluck
#from the above plot, there is a pluck between t = 130.65 and 130.75
startTime = 130.66
stopTime = 130.7
singlePluck = pluckOnly[pluckOnly['timestamp'].between(startTime, stopTime)]

plotTrace(singlePluck)
89/5:
#Idea: detect pluck with a sliding-window std deviation metric
def computeRollingStdDev(data, windowSize = 80):
    rollingVar = data.rolling(windowSize).std()
    rollingVar.timestamp = data.timestamp
    return rollingVar

rollingVarSingle = computeRollingStdDev(singlePluck)
plotTrace(rollingVarSingle)

rollingVarAll = computeRollingStdDev(pluckOnly)
plotTrace(rollingVarAll)

rollingVarDraw = computeRollingStdDev(drawOnly)
plotTrace(rollingVarDraw)
89/6:
# Rather than simulating different sample rates on the above data to determine the best option, 
# I just set it to 2kHz and took some data to see if that rate is suitabel (lazy option :s)
# Have a look at the traces

plucks2Khz = loadCsv('pluckSensorLogs/plucksOnly2kHz.csv')

plotTrace(plucks2Khz)
plotTrace(computeRollingStdDev(plucks2Khz, windowSize = 30))
90/1:
from sensor_msgs.msg import Image

import rospy

rospy.init_node('notebook')
90/2:
from sensor_msgs.msg import Image

import rospy

rospy.init_node('notebook')
90/3:
from sensor_msgs.msg import Image

import rospy

rospy.init_node('notebook')
105/1:
from sensor_msgs.msg import Image

import rospy

rospy.init_node('notebook')
105/2:
from sensor_msgs.msg import Image

import rospy

rospy.init_node('notebook')
105/3:
from sensor_msgs.msg import Image

import rospy

rospy.init_node('notebook')
105/4:
from sensor_msgs.msg import Image

import rospy

rospy.init_node('notebook')
107/1:
from sensor_msgs.msg import Image

import rospy

rospy.init_node('notebook')
107/2:
from sensor_msgs.msg import Image

import rospy

rospy.init_node('notebook')
107/3:
from sensor_msgs.msg import Image

import rospy

rospy.init_node('notebook')
107/4:
from sensor_msgs.msg import Image

import rospy

rospy.init_node('notebook')
107/5:
from sensor_msgs.msg import Image

import rospy

rospy.init_node('notebook')
107/6:
from sensor_msgs.msg import Image

import rospy

rospy.init_node('notebook')
107/7:
from sensor_msgs.msg import Image

import rospy

rospy.init_node('notebook')
107/8:
def cb_once(msg):
    #do processing here
    print('cb')
    image = msg
    sub_once.unregister()

global sub_once
global image
sub_once = rospy.Subscriber('edge_detection/image', Image, cb_once)
107/9:
def cb_once(msg):
    #do processing here
    print('cb')
    image = msg
    sub_once.unregister()

global sub_once
global image
sub_once = rospy.Subscriber('edge_detection/image', Image, cb_once)
107/10: msg
107/11: image
107/12:
def cb_once(msg):
    #do processing here
    print('cb')
    image = msg
    sub_once.unregister()

global sub_once
global image
sub_once = rospy.Subscriber('edge_detection/image', Image, cb_once)
107/13:
def cb_once(msg):
    #do processing here
    print('cb')
    global image = msg
    sub_once.unregister()

global sub_once
global image
sub_once = rospy.Subscriber('edge_detection/image', Image, cb_once)
107/14:
def cb_once(msg):
    #do processing here
    print('cb')
    global image
    image = msg
    sub_once.unregister()

global sub_once
global image
sub_once = rospy.Subscriber('edge_detection/image', Image, cb_once)
107/15: image
107/16:
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
import rospy
107/17:
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
import rospy
107/18:
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
import rospy
107/19:
image

from cv_bridge import CvBridge, CvBridgeError

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(data, "bgr8")
107/20:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(data, "bgr8")
107/21:
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
import rospy
107/22:
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
import rospy
107/23:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(data, "bgr8")
107/24:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(data, "bgr8")
107/25:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "bgr8")
107/26:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "bgr8")
107/27:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "bgr8")
cv2.imshow("Image window", cv_image)
107/28:
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
import rospy
import cv2
107/29:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "bgr8")
cv2.imshow("Image window", cv_image)
107/30:
def cb_once(msg):
    #do processing here
    print('cb')
    global image
    image = msg
    sub_once.unregister()

global sub_once
global image
sub_once = rospy.Subscriber('edge_detection/image', Image, cb_once)
107/31:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "bgr8")
cv2.imshow("Image window", cv_image)
108/1:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "bgr8")
cv2.imshow("Image window", cv_image)
109/1:
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
import rospy
import cv2
109/2: rospy.init_node('notebook')
109/3:
def cb_once(msg):
    #do processing here
    print('cb')
    global image
    image = msg
    sub_once.unregister()

global sub_once
global image
sub_once = rospy.Subscriber('edge_detection/image', Image, cb_once)
109/4:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "bgr8")
cv2.imshow("Image window", cv_image)
109/5:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "bgr8")
cv2.imshow("Image window", cv_image)
110/1:
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
import rospy
import cv2

from matplotlib import pyplot as plt
110/2:
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
import rospy
import cv2

from matplotlib import pyplot as plt
110/3:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "bgr8")

plt.imshow(gray)
110/4:
def cb_once(msg):
    #do processing here
    print('cb')
    global image
    image = msg
    sub_once.unregister()

global sub_once
global image
sub_once = rospy.Subscriber('edge_detection/image', Image, cb_once)
110/5:
def cb_once(msg):
    #do processing here
    print('cb')
    global image
    image = msg
    sub_once.unregister()

global sub_once
global image
sub_once = rospy.Subscriber('edge_detection/image', Image, cb_once)
110/6: rospy.init_node('notebook')
111/1:
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
import rospy
import cv2

from matplotlib import pyplot as plt
111/2: rospy.init_node('notebook')
111/3:
def cb_once(msg):
    #do processing here
    print('cb')
    global image
    image = msg
    sub_once.unregister()

global sub_once
global image
sub_once = rospy.Subscriber('edge_detection/image', Image, cb_once)
111/4:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "bgr8")

plt.imshow(gray)
111/5:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "bgr8")

plt.imshow(gray)
111/6:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "bgr8")

plt.imshow(cv_image)
111/7: cv_image[0,0,0]
111/8: cv_image > 0
111/9: numpy.argwhere(cv_image > 0)
111/10:
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
import rospy
import cv2
import numpy

from matplotlib import pyplot as plt
111/11: numpy.argwhere(cv_image > 0)
111/12:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "bgr8")

plt.imshow(cv_image)
111/13: help(bridge.imgmsg_to_cv2)
111/14: help(bridge.imgmsg_to_cv2)
111/15:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "mono8")

plt.imshow(cv_image)
111/16: cv_image
111/17: numpy.argwhere(cv_image > 100)
111/18: points = numpy.argwhere(cv_image > 100)
111/19:
points = numpy.argwhere(cv_image > 100)
len(points)
111/20:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "mono8")
cv_image = cv2.resize(cv_image, (0,0), fx=0.5, fy=0.5) 
plt.imshow(cv_image)
111/21: cv_image
111/22:
points = numpy.argwhere(cv_image > 100)
len(points)
111/23:
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
import rospy
import cv2
import numpy
import sensor_msgs.point_cloud2 as pc2
from matplotlib import pyplot as plt
111/24: pointCloud = pc2.create_cloud(points)
111/25:     pointCloud = pc2.create_cloud_xyz32(points)
111/26:
from sensor_msgs.msg import Image
from std_msgs.msg import Header
from cv_bridge import CvBridge, CvBridgeError
import rospy
import cv2
import numpy
import sensor_msgs.point_cloud2 as pc2
from matplotlib import pyplot as plt
111/27:     pointCloud = pc2.create_cloud_xyz32(Header, points)
111/28:     pointCloud = pc2.create_cloud(Header, points)
111/29:
from sensor_msgs.msg import Image
from std_msgs.msg import Header
from sensor_msgs.msg import PointCloud2, PointField

from cv_bridge import CvBridge, CvBridgeError
import rospy
import cv2
import numpy
import sensor_msgs.point_cloud2 as pc2
from matplotlib import pyplot as plt
111/30:
fields = []
    PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),
    PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1)
]
pointCloud = pc2.create_cloud(Header()ields, oints)
111/31:
fields = []
    PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),
    PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1)
]
pointCloud = pc2.create_cloud(Header()fields, oints)
111/32:
fields = []
    PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),
    PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1)
]
pointCloud = pc2.create_cloud(Header(), fields, points)
111/33:
fields = [
    PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),
    PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1)
]

pointCloud = pc2.create_cloud(Header(), fields, points)
111/34:
fields = [
    PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),
    PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1)
]

pointCloud = pc2.create_cloud(Header(), fields, points)
111/35:
fields = [
    PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),
    PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1)
]

pointCloud = pc2.create_cloud(Header(), fields, points)
pointCloud
111/36: publisher = rospy.publisher(PointCloud2, 'cloud')
111/37: publisher = rospy.Publisher(PointCloud2, 'cloud', queue_size=10)
111/38: publisher = rospy.Publisher('cloud', PointCloud2, queue_size=10)
111/39:
publisher = rospy.Publisher('cloud', PointCloud2, queue_size=10)
publisher.publish(pointCloud)
111/40: publisher.publish(pointCloud)
111/41: publisher.publish(pointCloud)
111/42: publisher.publish(pointCloud)
111/43:
fields = [
    PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),
    PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1)
]

pointCloud = pc2.create_cloud(Header(frame_id='camera'), fields, points)
pointCloud
111/44:
fields = [
    PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),
    PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1)
]

pointCloud = pc2.create_cloud(image.header, fields, points)
pointCloud
111/45:
fields = [
    PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),
    PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1)
]

pointCloud = pc2.create_cloud(image.header, fields, points)
pointCloud
111/46: publisher.publish(pointCloud)
111/47: publisher.publish(pointCloud)
111/48: publisher.publish(pointCloud)
111/49: pointCloud = PointCloud()
111/50: pointCloud = PointCloud2(header=image.header)
111/51:
pointCloud = PointCloud2(header=image.header)
pointCloud
111/52:
from sensor_msgs.msg import Image
from std_msgs.msg import Header
from sensor_msgs.msg import PointCloud2, PointField
from sensor_msgs.msg import PointCloud

from cv_bridge import CvBridge, CvBridgeError
import rospy
import cv2
import numpy
import sensor_msgs.point_cloud2 as pc2
from matplotlib import pyplot as plt
111/53:
pointCloud = PointCloud(header=image.header)
pointCloud
111/54:
from sensor_msgs.msg import Image
from std_msgs.msg import Header
from sensor_msgs.msg import PointCloud2, PointField
from sensor_msgs.msg import PointCloud
from geometry_msgs.msg import Point32
from cv_bridge import CvBridge, CvBridgeError
import rospy
import cv2
import numpy
import sensor_msgs.point_cloud2 as pc2
from matplotlib import pyplot as plt
111/55:
from sensor_msgs.msg import Image
from std_msgs.msg import Header
#from sensor_msgs.msg import PointCloud2, PointField
from sensor_msgs.msg import PointCloud
from geometry_msgs.msg import Point32
from cv_bridge import CvBridge, CvBridgeError
import rospy
import cv2
import numpy
import sensor_msgs.point_cloud2 as pc2
from matplotlib import pyplot as plt
111/56:
# fields = [
#     PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),
#     PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1)
# ]

# pointCloud = pc2.create_cloud(image.header, fields, points)
# pointCloud
111/57:
pointCloud = PointCloud(
    header=image.header,
    points = map(lambda x,y : Point32(x,y,0), points)

pointCloud
111/58:
pointCloud = PointCloud(
    header=image.header,
    points = map(lambda x,y : Point32(x,y,0), points)
)
pointCloud
111/59:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points])
)
pointCloud
111/60:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud
111/61: publisher = rospy.Publisher('cloud', PointCloud, queue_size=10)
111/62: publisher = rospy.Publisher('cloud', PointCloud, queue_size=10)
111/63: publisher.publish(pointCloud)
112/1:
from sensor_msgs.msg import Image
from std_msgs.msg import Header
#from sensor_msgs.msg import PointCloud2, PointField
from sensor_msgs.msg import PointCloud
from geometry_msgs.msg import Point32
from cv_bridge import CvBridge, CvBridgeError
import rospy
import cv2
import numpy
import sensor_msgs.point_cloud2 as pc2
from matplotlib import pyplot as plt
112/2: rospy.init_node('notebook')
112/3:
def cb_once(msg):
    #do processing here
    print('cb')
    global image
    image = msg
    sub_once.unregister()

global sub_once
global image
sub_once = rospy.Subscriber('edge_detection/image', Image, cb_once)
112/4:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "mono8")
cv_image = cv2.resize(cv_image, (0,0), fx=0.5, fy=0.5) 
plt.imshow(cv_image)
112/5:
image

bridge = CvBridge()
cv_image = bridge.imgmsg_to_cv2(image, "mono8")
cv_image = cv2.resize(cv_image, (0,0), fx=0.5, fy=0.5) 
plt.imshow(cv_image)
112/6:
points = numpy.argwhere(cv_image > 100)
len(points)
112/7:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud
112/8:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud
112/9: publisher = rospy.Publisher('cloud', PointCloud, queue_size=10)
112/10: publisher.publish(pointCloud)
112/11: publisher.publish(pointCloud)
112/12: publisher.publish(pointCloud)
112/13: points
112/14:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud.points
112/15:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud.points[0]
112/16:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud.points[0].x
112/17:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud.points[0].y
112/18:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud.points[0].y
height, width, _ = img.shape
112/19:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud.points[0].y
height, width, _ = cv_image.shape
112/20:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud.points[0].y
height, width, channels = cv_image.shape
112/21:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud.points[0].y
height, width = cv_image.shape
112/22:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud.points[0].y
height, width = cv_image.shape
height
112/23:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud.points[0].y
height, width = cv_image.shape
width
112/24:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud.points[0].y
height, width = cv_image.shape

#translate so image center is at 0,0, and scale to something closer to reality
for point in pointCloud.points:
    point.x = -1

pointCloud
112/25:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud.points[0].y
height, width = cv_image.shape

#translate so image center is at 0,0, and scale to something closer to reality
scale = 1./100;
for point in pointCloud.points:
    point.x = (point.x - height / 2.) * scale
    point.y = (point.y - width / 2.) * scale

pointCloud
112/26:
from sensor_msgs.msg import Image
from sensor_msgs.msg import PointCloud2, PointField
from sensor_msgs.msg import PointCloud
from geometry_msgs.msg import Point32
from cv_bridge import CvBridge
import rospy
import cv2
import pc2
import numpy
import sensor_msgs.point_cloud2 as pc2
from matplotlib import pyplot as plt
112/27:
from sensor_msgs.msg import Image
from sensor_msgs.msg import PointCloud2, PointField
from sensor_msgs.msg import PointCloud
from geometry_msgs.msg import Point32
from cv_bridge import CvBridge
import rospy
import cv2
from sensor_msgs import point_cloud2 as pc2
import numpy
import sensor_msgs.point_cloud2 as pc2
from matplotlib import pyplot as plt
112/28: pc2.create_cloud_xyz32(pointCloud.header, pointCloud.points)
112/29: pc2.create_cloud_xyz32(pointCloud.header, [[p.x,p.y,p.z] for p in pointCloud.points])
112/30:
pointCloud = PointCloud(
    header=image.header,
    points = [Point32(x,y,0) for x,y in points]
)
pointCloud.points[0].y
height, width = cv_image.shape

#translate so image center is at 0,0, and scale to something closer to reality
scale = 1./100;
for point in pointCloud.points:
    point.x = (point.x - height / 2.) * scale
    point.y = (point.y - width / 2.) * scale

#convert to PointCloud2 (for cartographer)
pointCloud2 = pc2.create_cloud_xyz32(pointCloud.header, [[p.x,p.y,p.z] for p in pointCloud.points])
112/31:
cv_image = cvBridge.imgmsg_to_cv2(image, "mono8")

imageScaleFactor = 0.1
imageToRealworldScale = 0.5/200 #200 px per half-meter

cv_image = cv2.resize(cv_image, (0,0), fx=imageScaleFactor, fy=imageScaleFactor) 
points = numpy.argwhere(cv_image > 255/2)

pointCloud = PointCloud(
    header= image.header,
    points = [Point32(x,y,0) for x,y in points]
)

#translate so image center is at 0,0, and scale to something closer to reality
height, width = cv_image.shape
scale = 1./imageScaleFactor * imageToRealworldScale;
for point in pointCloud.points:
    point.x = (point.x - height / 2.) * scale 
    point.y = (point.y - width / 2.) * scale

#convert to PointCloud2 (for cartographer)
pointCloud2 = pc2.create_cloud_xyz32(pointCloud.header, [[p.x,p.y,p.z] for p in pointCloud.points])
112/32:
cvBridge = CvBridge() 

cv_image = cvBridge.imgmsg_to_cv2(image, "mono8")

imageScaleFactor = 0.1
imageToRealworldScale = 0.5/200 #200 px per half-meter

cv_image = cv2.resize(cv_image, (0,0), fx=imageScaleFactor, fy=imageScaleFactor) 
points = numpy.argwhere(cv_image > 255/2)

pointCloud = PointCloud(
    header= image.header,
    points = [Point32(x,y,0) for x,y in points]
)

#translate so image center is at 0,0, and scale to something closer to reality
height, width = cv_image.shape
scale = 1./imageScaleFactor * imageToRealworldScale;
for point in pointCloud.points:
    point.x = (point.x - height / 2.) * scale 
    point.y = (point.y - width / 2.) * scale

#convert to PointCloud2 (for cartographer)
pointCloud2 = pc2.create_cloud_xyz32(pointCloud.header, [[p.x,p.y,p.z] for p in pointCloud.points])
112/33:
cvBridge = CvBridge() 

cv_image = cvBridge.imgmsg_to_cv2(image, "mono8")

imageScaleFactor = 0.1
imageToRealworldScale = 0.5/200 #200 px per half-meter

cv_image = cv2.resize(cv_image, (0,0), fx=imageScaleFactor, fy=imageScaleFactor) 

plt.imshow(cv_image)

points = numpy.argwhere(cv_image > 255/2)

pointCloud = PointCloud(
    header= image.header,
    points = [Point32(x,y,0) for x,y in points]
)

#translate so image center is at 0,0, and scale to something closer to reality
height, width = cv_image.shape
scale = 1./imageScaleFactor * imageToRealworldScale;
for point in pointCloud.points:
    point.x = (point.x - height / 2.) * scale 
    point.y = (point.y - width / 2.) * scale

#convert to PointCloud2 (for cartographer)
pointCloud2 = pc2.create_cloud_xyz32(pointCloud.header, [[p.x,p.y,p.z] for p in pointCloud.points])
112/34:
cvBridge = CvBridge() 

cv_image = cvBridge.imgmsg_to_cv2(image, "mono8")

imageScaleFactor = 0.1
imageToRealworldScale = 0.5/200 #200 px per half-meter

dilated = cv2.dilate(cv_image, np.ones((11, 11)))

plt.imshow(dilated)

cv_image = cv2.resize(cv_image, (0,0), fx=imageScaleFactor, fy=imageScaleFactor) 


plt.imshow(cv_image)

points = numpy.argwhere(cv_image > 255/2)

pointCloud = PointCloud(
    header= image.header,
    points = [Point32(x,y,0) for x,y in points]
)

#translate so image center is at 0,0, and scale to something closer to reality
height, width = cv_image.shape
scale = 1./imageScaleFactor * imageToRealworldScale;
for point in pointCloud.points:
    point.x = (point.x - height / 2.) * scale 
    point.y = (point.y - width / 2.) * scale

#convert to PointCloud2 (for cartographer)
pointCloud2 = pc2.create_cloud_xyz32(pointCloud.header, [[p.x,p.y,p.z] for p in pointCloud.points])
112/35:
from sensor_msgs.msg import Image
from sensor_msgs.msg import PointCloud2, PointField
from sensor_msgs.msg import PointCloud
from geometry_msgs.msg import Point32
from cv_bridge import CvBridge
import rospy
import cv2
from sensor_msgs import point_cloud2 as pc2
import numpy as np
import sensor_msgs.point_cloud2 as pc2
from matplotlib import pyplot as plt
112/36:
cvBridge = CvBridge() 

cv_image = cvBridge.imgmsg_to_cv2(image, "mono8")

imageScaleFactor = 0.1
imageToRealworldScale = 0.5/200 #200 px per half-meter

dilated = cv2.dilate(cv_image, np.ones((11, 11)))

plt.imshow(dilated)

cv_image = cv2.resize(cv_image, (0,0), fx=imageScaleFactor, fy=imageScaleFactor) 


plt.imshow(cv_image)

points = np.argwhere(cv_image > 255/2)

pointCloud = PointCloud(
    header= image.header,
    points = [Point32(x,y,0) for x,y in points]
)

#translate so image center is at 0,0, and scale to something closer to reality
height, width = cv_image.shape
scale = 1./imageScaleFactor * imageToRealworldScale;
for point in pointCloud.points:
    point.x = (point.x - height / 2.) * scale 
    point.y = (point.y - width / 2.) * scale

#convert to PointCloud2 (for cartographer)
pointCloud2 = pc2.create_cloud_xyz32(pointCloud.header, [[p.x,p.y,p.z] for p in pointCloud.points])
112/37:
cvBridge = CvBridge() 

cv_image = cvBridge.imgmsg_to_cv2(image, "mono8")

imageScaleFactor = 0.1
imageToRealworldScale = 0.5/200 #200 px per half-meter

dilated = cv2.dilate(cv_image, np.ones((11, 11)))

plt.imshow(dilated)

cv_image = cv2.resize(cv_image, (0,0), fx=imageScaleFactor, fy=imageScaleFactor) 

plt.figure()
plt.imshow(cv_image)

points = np.argwhere(cv_image > 255/2)

pointCloud = PointCloud(
    header= image.header,
    points = [Point32(x,y,0) for x,y in points]
)

#translate so image center is at 0,0, and scale to something closer to reality
height, width = cv_image.shape
scale = 1./imageScaleFactor * imageToRealworldScale;
for point in pointCloud.points:
    point.x = (point.x - height / 2.) * scale 
    point.y = (point.y - width / 2.) * scale

#convert to PointCloud2 (for cartographer)
pointCloud2 = pc2.create_cloud_xyz32(pointCloud.header, [[p.x,p.y,p.z] for p in pointCloud.points])
112/38:
cvBridge = CvBridge() 

cv_image = cvBridge.imgmsg_to_cv2(image, "mono8")

imageScaleFactor = 0.1
imageToRealworldScale = 0.5/200 #200 px per half-meter

dilated = cv2.dilate(cv_image, np.ones((21, 21)))

plt.imshow(dilated)

cv_image = cv2.resize(cv_image, (0,0), fx=imageScaleFactor, fy=imageScaleFactor) 

plt.figure()
plt.imshow(cv_image)

points = np.argwhere(cv_image > 255/2)

pointCloud = PointCloud(
    header= image.header,
    points = [Point32(x,y,0) for x,y in points]
)

#translate so image center is at 0,0, and scale to something closer to reality
height, width = cv_image.shape
scale = 1./imageScaleFactor * imageToRealworldScale;
for point in pointCloud.points:
    point.x = (point.x - height / 2.) * scale 
    point.y = (point.y - width / 2.) * scale

#convert to PointCloud2 (for cartographer)
pointCloud2 = pc2.create_cloud_xyz32(pointCloud.header, [[p.x,p.y,p.z] for p in pointCloud.points])
112/39:
cvBridge = CvBridge() 

cv_image = cvBridge.imgmsg_to_cv2(image, "mono8")

imageScaleFactor = 0.1
imageToRealworldScale = 0.5/200 #200 px per half-meter

cv_image = cv2.dilate(cv_image, np.ones((21, 21)))

plt.imshow(cv_image)

cv_image = cv2.resize(cv_image, (0,0), fx=imageScaleFactor, fy=imageScaleFactor) 

plt.figure()
plt.imshow(cv_image)

points = np.argwhere(cv_image > 255/2)

pointCloud = PointCloud(
    header= image.header,
    points = [Point32(x,y,0) for x,y in points]
)

#translate so image center is at 0,0, and scale to something closer to reality
height, width = cv_image.shape
scale = 1./imageScaleFactor * imageToRealworldScale;
for point in pointCloud.points:
    point.x = (point.x - height / 2.) * scale 
    point.y = (point.y - width / 2.) * scale

#convert to PointCloud2 (for cartographer)
pointCloud2 = pc2.create_cloud_xyz32(pointCloud.header, [[p.x,p.y,p.z] for p in pointCloud.points])
112/40:
cvBridge = CvBridge() 

cv_image = cvBridge.imgmsg_to_cv2(image, "mono8")

imageScaleFactor = 0.1
imageToRealworldScale = 0.5/200 #200 px per half-meter

plt.imshow(cv_image)

cv_image = cv2.dilate(cv_image, np.ones((11, 11)))

plt.figure()
plt.imshow(cv_image)

cv_image = cv2.resize(cv_image, (0,0), fx=imageScaleFactor, fy=imageScaleFactor) 

plt.figure()
plt.imshow(cv_image)

points = np.argwhere(cv_image > 255/2)

pointCloud = PointCloud(
    header= image.header,
    points = [Point32(x,y,0) for x,y in points]
)

#translate so image center is at 0,0, and scale to something closer to reality
height, width = cv_image.shape
scale = 1./imageScaleFactor * imageToRealworldScale;
for point in pointCloud.points:
    point.x = (point.x - height / 2.) * scale 
    point.y = (point.y - width / 2.) * scale

#convert to PointCloud2 (for cartographer)
pointCloud2 = pc2.create_cloud_xyz32(pointCloud.header, [[p.x,p.y,p.z] for p in pointCloud.points])
112/41:
cvBridge = CvBridge() 

cv_image = cvBridge.imgmsg_to_cv2(image, "mono8")

imageScaleFactor = 0.1
imageToRealworldScale = 0.5/200 #200 px per half-meter

plt.imshow(cv_image)

cv_image = cv2.dilate(cv_image, np.ones((5, 5)))

plt.figure()
plt.imshow(cv_image)

cv_image = cv2.resize(cv_image, (0,0), fx=imageScaleFactor, fy=imageScaleFactor) 

plt.figure()
plt.imshow(cv_image)

points = np.argwhere(cv_image > 255/2)

pointCloud = PointCloud(
    header= image.header,
    points = [Point32(x,y,0) for x,y in points]
)

#translate so image center is at 0,0, and scale to something closer to reality
height, width = cv_image.shape
scale = 1./imageScaleFactor * imageToRealworldScale;
for point in pointCloud.points:
    point.x = (point.x - height / 2.) * scale 
    point.y = (point.y - width / 2.) * scale

#convert to PointCloud2 (for cartographer)
pointCloud2 = pc2.create_cloud_xyz32(pointCloud.header, [[p.x,p.y,p.z] for p in pointCloud.points])
112/42:
cvBridge = CvBridge() 

cv_image = cvBridge.imgmsg_to_cv2(image, "mono8")

imageScaleFactor = 0.1
imageToRealworldScale = 0.5/200 #200 px per half-meter

plt.imshow(cv_image)

cv_image = cv2.dilate(cv_image, np.ones((11,  11)))

plt.figure()
plt.imshow(cv_image)

cv_image = cv2.resize(cv_image, (0,0), fx=imageScaleFactor, fy=imageScaleFactor) 

plt.figure()
plt.imshow(cv_image)

points = np.argwhere(cv_image > 255/2)

pointCloud = PointCloud(
    header= image.header,
    points = [Point32(x,y,0) for x,y in points]
)

#translate so image center is at 0,0, and scale to something closer to reality
height, width = cv_image.shape
scale = 1./imageScaleFactor * imageToRealworldScale;
for point in pointCloud.points:
    point.x = (point.x - height / 2.) * scale 
    point.y = (point.y - width / 2.) * scale

#convert to PointCloud2 (for cartographer)
pointCloud2 = pc2.create_cloud_xyz32(pointCloud.header, [[p.x,p.y,p.z] for p in pointCloud.points])
113/1: from geometry_msgs.msg import Transform
113/2: from geometry_msgs.msg import TransformStamped
114/1: from geometry_msgs.msg import TransformStamped
114/2: from geometry_msgs.msg import TransformStamped
114/3: tfMsg = TransformStamped()
114/4: tfMsg
114/5: import tf
114/6: br = tf.TransformBroadcaster()
114/7: bf.sendTransform()
114/8: br.sendTransform()
114/9: br.sendTransform()
114/10: ?br.sendTransformMessage
114/11: ?br.sendTransform
114/12: tfMsg
114/13: tfMsg.header.frame_id
114/14: tfMsg.child_frame_id
114/15: tfMsg.header.stamp = rospy.Time.now()
114/16: from nav_msgs.msg import Odometry
114/17: o = Odometry()
114/18: o
114/19: tfListener.lookupTransform('/odom', '/base_link', rospy.Time(0))
114/20: tfListener = tf.TransformListener()
114/21: tfListener.lookupTransform('/odom', '/base_link', rospy.Time(0))
114/22: import rospy
114/23: tfListener.lookupTransform('/odom', '/base_link', rospy.Time(0))
114/24: tfListener.lookupTransform('/odom', '/base_link', rospy.Time(0))
114/25: tfListener.lookupTransform('/base_link', '/odom', rospy.Time(0))
114/26: rospy.get_published_topics()
114/27: tfListener.lookupTransform('/base_link', '/odom', rospy.Time(0))
114/28: tfListener.lookupTransform('/device', '/odom', rospy.Time(0))
114/29: tfListener.lookupTransform('device', 'odom', rospy.Time(0))
114/30: tfListener.lookupTransform('tango', 'odom', rospy.Time(0))
114/31: tfListener.lookupTransform('/tango', '/odom', rospy.Time(0))
114/32: rospy.init_node('ipython')
114/33: tfListener = tf.TransformListener()
114/34: tfListener.lookupTransform('/tango', '/odom', rospy.Time(0))
114/35: tfListener.lookupTransform('tango', '/odom', rospy.Time(0))
114/36: tfListener.lookupTransform('tango', 'odom', rospy.Time(0))
114/37: ?tfListener.lookupTransform
115/1: import rospy
115/2: tfListener = tf.TransformListener()
115/3: import tf
115/4: tfListener = tf.TransformListener()
115/5: tfListener.lookupTransform('tango', 'odom', rospy.Time(0))
115/6: tfListener.lookupTransform('tango', 'odom', rospy.Time(0))
115/7: rospy.init_node('ipython')
115/8: tfListener.lookupTransform('tango', 'odom', rospy.Time(0))
116/1: import tf
116/2: import rospy
116/3: rospy.init_node('ipython')
116/4: tfListener = tf.TransformListener()
116/5: tfListener.lookupTransform('tango', 'odom', rospy.Time(0))
116/6: ls
116/7: echo
116/8: dsdfsdfs
116/9: tfListener = tf.TransformListener()
116/10: tfListener = tf.TransformListener()
116/11: dsdfsdfs
116/12: tfListener = tf.TransformListener()
116/13: tfListener = tf.TransformListener()
116/14: tfListener = tf.TransformListener()
116/15: tfListener = tf.TransformListener()
116/16: del tf_listener
117/1: rospy.init_node('ipython')
117/2: import rospy
117/3: import tf
117/4: import tf2
117/5: import tf2_ros
117/6:
    tfBuffer = tf2_ros.Buffer()
    listener = tf2_ros.TransformListener(tfBuffer)
117/7: tfListener = tf2_ros.TransformListener(tfBuffer)
117/8: tfListener.lookupTransform('tango', 'odom', rospy.Time(0))
117/9: tfListener.lookup_transform('tango', 'odom', rospy.Time(0))
117/10: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
117/11: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
117/12: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
117/13: tfBuffer.lookup_transform('/tango', '/odom', rospy.Time(0))
117/14: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
117/15: tfBuffer.lookup_transform('tango', 'odom', rospy.Time())
117/16: rospy.init_node('ipython')
117/17: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/1: import tf2
118/2: import tf2_ros
118/3: import rospy
118/4: tfListener = tf.TransformListener()
118/5:
    tfBuffer = tf2_ros.Buffer()
    listener = tf2_ros.TransformListener(tfBuffer)
118/6: tfBuffer.clear()
118/7: tfListener = tf2_ros.TransformListener(tfBuffer)
118/8: rospy.init_node('ipython')
118/9: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/10: tfBuffer.clear()
118/11: tfBuffer.clear()
118/12: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/13: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/14: tfBuffer.clear()
118/15: tfBuffer.clear()
118/16: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/17: tfBuffer.clear()
118/18: rospy.Time.now()
118/19: rospy.Time.now()
118/20: tfBuffer.clear()
118/21: currentTime = rospy.Time.now()
118/22: lastTime = currentTime
118/23: currentTime = rospy.Time.now()
118/24: tfBuffer.clear()
118/25: currentTime = rospy.Time.now()
118/26: lastTime - currentTime
118/27: (lastTime - currentTime).to_sec()
118/28: tfBuffer.clear()
118/29: tfBuffer.clear()
118/30: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/31: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/32: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/33: tfBuffer.clear()
118/34: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/35: tfBuffer.clear()
118/36: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/37: tfBuffer.lookup_transform('tango', 'odom', rospy.Time.now())
118/38: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/39: tfBuffer.lookup_transform('tango', 'odom', rospy.Time.now())
118/40: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/41: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/42: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/43: tfBuffer.clear()
118/44: currentPos = tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/45: currentPos.header.stamp
118/46: currentPos = tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/47: currentPos = tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/48: tfBuffer.clear()
118/49: currentPos = tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
118/50: currentPos.transform
118/51: tfBuffer.clear()
118/52: currentPos.transform.translation.x
118/53: tfBuffer.clear()
118/54: currentPos.transform.translation.x
118/55: tfBuffer.clear()
118/56: currentPos.transform.translation.x
118/57: currentPos.transform.translation.x
118/58: currentPos.transform.translation.x
118/59: tfBuffer.clear()
118/60: import tf2_ros
118/61: tfBuffer.clear()
118/62: import tf2_py
118/63: tfBuffer.clear()
118/64: import tf2_py
118/65: import tf2_kdl
118/66: import tf2_geometry_msgs
118/67: tf2_geometry_msgs.from_msg_msg
118/68: import tf2_kdl
118/69: tfBuffer.clear()
118/70: import tf2_geometry_msgs
118/71: tf2_geometry_msgs.from_msg_msg(msg=currentPos)
118/72: tfBuffer.clear()
118/73: currentPos
118/74: type(currentPos)
118/75: tfBuffer.clear()
118/76: tfBuffer.clear()
118/77: type(currentPos)
118/78: tfBuffer.clear()
118/79: type(currentPos)
118/80: tfBuffer.clear()
118/81: tfBuffer.clear()
118/82: tfBuffer.clear()
118/83: type(currentPos)
119/1: from geometry_msgs.msg import TransformStamped
119/2: currentPos = TransformStamped()
119/3: currentPos
119/4: import tf2_ros
119/5: tf2_ros.TransformStamped(currentPos)
119/6: from tf.transformations import euler_from_quaternion
119/7: euler_from_quaternion
119/8: ?euler_from_quaternion
119/9: from tf.msg import tfMessage
119/10: currentPos.transform
119/11: currentPos.transform.rotation
119/12: from tf.transformations import euler_from_quaternion
119/13: lambda quaternion_array(o) : [o.x, o.y, o.z, o.w]
119/14: lambda quaternion_array o : [o.x, o.y, o.z, o.w]
119/15: quaternion_array = lambda o : [o.x, o.y, o.z, o.w]
119/16: quaternion_array(currentPos.transform.rotation)
119/17: quaternion_array = lambda q : [q.x, q.y, q.z, q.w]
119/18: quaternion_array(currentPos.transform.rotation)
119/19: quaternion_array(currentPos.transform.rotation)
119/20: from tf.transformations import euler_from_quaternion
119/21: euler_from_quaternion(quaternion_array(currentPos.transform.rotation))
119/22: ?euler_from_quaternion
119/23: test = lambda : [4,5,6]
119/24: test()
119/25: a,b,c = test()
119/26: a
119/27: b
119/28: c
119/29: type(currentPos)
119/30: from tf.transformations import quaternion_from_euler
119/31: aw
119/32: yaw
119/33: euler_from_quaternion(quaternion_array(currentPos.transform.rotation))
119/34: roll, pitch, yaw = euler_from_quaternion(quaternion_array(currentPos.transform.rotation))
119/35: yaw
119/36: quaternion_from_euler
119/37: ?quaternion_from_euler
119/38: quaternion_from_euler(0,0,2)
119/39: from nav_msgs.msg import Odometry
119/40: odomMsg = Odometry()
119/41: odomMsg.header
119/42: currentPos.header
119/43: odomMsg.pose
119/44: odomMsg.pose.pose
119/45: currentPos.transform
119/46: type(odomMsg.pose.pose)
119/47: odomMsg.pose.pose
119/48: type(odomMsg.pose.pose)
119/49: type(currentPos.transform)
119/50: currentPos.transform
119/51: odomMsg.pose.pose
119/52: type(odomMsg.pose.pose)
119/53: type(currentPos.transform)
119/54: from geometry_msgs.msg import Pose
119/55: p = Pose
119/56: p = Pose()
119/57: p.orientation
119/58: p.orientation.x
119/59: t = currentPos.transform
119/60: t.rotation.x
119/61: p.position
119/62: t.translation
119/63: odomMsg.pose
119/64: odomMsg.pose.pose
119/65: odomMsg
119/66: odomMsg.child_frame_id = currentPos.child_frame_id
119/67: odomMsg
119/68: odomMsg.twist.twist.linear.x
119/69: odomMsg.twist.twist.angular.z
119/70: currentPos = tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
119/71: t.rotation.x
120/1: from tf2_ros import ConnectivityException
120/2:
try:
    raise ConnectivityException()
catch tf2_ros.ConnectivityException:
120/3:
try:
    raise ConnectivityException()
except tf2_ros.ConnectivityException:
120/4:
try:
    raise ConnectivityException()
except tf2_ros.ConnectivityException:
120/5:
try:
    raise ConnectivityException()
except tf2_ros.ConnectivityException:
    print('caught')
120/6: import tf2_ros
120/7:
try:
    raise ConnectivityException()
except tf2_ros.ConnectivityException:
    print('caught')
119/72: t
119/73: currentPos
119/74: currentPos.transform
119/75: type(currentPos.transform)
119/76: type(currentPos.transform)
119/77: type(currentPos)
119/78: currentPos = tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
119/79: tfBuffer.lookup_transform('tango', 'odom', rospy.Time(0))
119/80:
tfBuffer = tf2_ros.Buffer()
listener = tf2_ros.TransformListener(tfBuffer)
119/81: tfBuffer.transform
119/82: ?tfBuffer.transform
119/83: currentPos
119/84: ?currentPos
119/85: from tf import transformations
119/86: ?tfBuffer.transform
119/87: ?tfBuffer.transform_full
119/88: import tf2_geometry_msgs
119/89: currentPos
119/90: type(currentPos)
119/91: tf2_geometry_msgs.PoseStamped
121/1: v = -0.05
121/2: sign(v)
121/3: from math import sign
121/4: 1 if true else 0
121/5: 1 if True else 0
121/6:
def sign(x):
    if x > 0:
        return -1
    elif x < 0:
        return -1
    else:
        return 0
121/7:
def sign(x):
    if x > 0:
        return 1
    elif x < 0:
        return -1
    else:
        return 0
121/8: sign(0)
121/9: sign(-2)
121/10: sign(3)
121/11: from geometry_msgs.msg import Twist
121/12: abs(-3)
121/13: ls
121/14: twistMsg = Twist()
121/15: twistMsg.linear.x
121/16:
getattr(twistMsg, 'linear'
)
121/17: getattr(twistMsg, 'linear')
121/18: getattr(twistMsg, 'linear.x')
121/19: getattr(twistMsg, 'linear/x')
121/20: %paste
121/21: %paste
121/22: %paste
121/23: getattr(twistMsg, 'linear.x')
121/24: rgetattr(twistMsg, 'linear.x')
121/25: import functools
121/26: rgetattr(twistMsg, 'linear.x')
121/27: rsetattr(twistMsg, 'linear.x', 2)
121/28: rgetattr(twistMsg, 'linear.x')
121/29: twistMsg
121/30: limits = {'linear.x': 0.2, 'angular.z' : 0.3}
121/31: limits.keys()
121/32: limits.items()
123/1: from office_bot.cfg import CmdVelLimitsConfig
123/2: CmdVelLimitsConfig
123/3: CmdVelLimitsConfig.config_description
123/4: CmdVelLimitsConfig.defaults
123/5: rospy
123/6: import rospy
124/1: import angles
124/2: angles.normalize_angle(3*pi)
124/3: from math import pi
124/4: angles.normalize_angle(3*pi)
124/5: angles.normalize_angle(-3*pi)
124/6: angles.normalize_angle(-3*pi-0.1)
124/7: ?angles.normalize_angle
124/8: angles.normalize_angle(3*pi)
124/9: angles.normalize_angle(3/2*pi)
124/10: angles.normalize_angle(3/2*pi)
124/11: angles.normalize_angle(5/2*pi)
124/12: angles.normalize_angle(5./2*pi)
124/13: angles.normalize_angle(3./2*pi)
125/1: from geometry_msgs.msg import Twist
125/2: twist = Twist()
125/3: twist
126/1: from tf import transformations
126/2: from tf import transformations as t
126/3: t.inverse_matrix()
126/4: from tf import Transformer
126/5: from tf import TransformerROS
126/6: TransformerROS.transformPose
126/7: ?TransformerROS.transformPose
127/1: import tf2
128/1: import tf2_ros
128/2: tf2_ros.transform_broadcaster
129/1: from geometry_msgs.msg import TransformStamped
129/2: t = TransformStamped()
129/3: t.transform.rotation.w = 1
129/4: import transformations
129/5: from tf import transformations
129/6: transformations.quaternion_from_euler(0,0,0)
129/7: ?transformations.quaternion_from_euler
130/1: import pandas as pd
130/2: import pandas as pd
131/1: import pandas as pd
131/2: import pandas as pd
131/3:
import pandas as pd
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
131/4:
import pandas as pd
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights
131/5:
import pandas as pd
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights
weights.weight.plot()
131/6:
import pandas as pd
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights
weights.weight.plot()
131/7:
import pandas as pd
import matplotlib
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights
weights.weight.plot()
132/1:
import pandas as pd
import matplotlib
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights
weights.weight.plot()
132/2:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights
weights.weight.plot()
pylab.show
132/3:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights
weights.weight.plot()
pylab.show()
132/4:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights
weights.weight.plot()
pylab.show()
132/5: weights
132/6: weights.date.min()
132/7: weights.date.max()
132/8: weights.date.idxmaxmax()
132/9: weights.date.idxmax()
132/10: weights
132/11: weights.date.apply(datetime.datetime.fromtimestamp)
132/12:
import datetime
weights.date.apply(datetime.datetime.fromtimestamp)
132/13:
import datetime
toDate = lambda millisSinceEpoch : datetime.datetime.fromtimestamp(millisSinceEpoch/1000)
weights.date.apply(toDate)
132/14:
import datetime
toDate = lambda millisSinceEpoch : datetime.datetime.fromtimestamp(millisSinceEpoch/1000)
weights.datetime = weights.date.apply(toDate)
132/15:
import datetime
toDate = lambda millisSinceEpoch : datetime.datetime.fromtimestamp(millisSinceEpoch/1000)
weights['datetime'] = weights.date.apply(toDate)
132/16:
import datetime
toDate = lambda millisSinceEpoch : datetime.datetime.fromtimestamp(millisSinceEpoch/1000)
weights['datetime'] = weights.date.apply(toDate)
132/17:
import datetime
toDate = lambda millisSinceEpoch : datetime.datetime.fromtimestamp(millisSinceEpoch/1000)
weights['datetime'] = weights.date.apply(toDate)
weights['weekday'] = weights.datetime.apply(datetime.datetime.weekday)
132/18: weights.weekday
132/19: weights.weekday
132/20:
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
import plotly.graph_objs as go
init_notebook_mode(connected=True)


# Create a trace
trace = go.Scatter(
    x = weights.weekday,
    y = weights.weight,
    mode = 'markers'
)

data = [trace]

# Plot and embed in ipython notebook!
py.iplot(data, filename='basic-scatter')
132/21:
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
import plotly.graph_objs as go
init_notebook_mode(connected=True)


# Create a trace
trace = go.Scatter(
    x = weights.weekday,
    y = weights.weight,
    mode = 'markers'
)

data = [trace]

# Plot and embed in ipython notebook!
iplot(data, filename='basic-scatter')
132/22: weights.weight.rolling_mean()
132/23: pd.rolling_mean
132/24: weights.weight.rolling(7)
132/25: weights.weight.rolling(7).mean()
132/26: weights.weight.rolling(7).mean().plot()
132/27: weights['rollingMean'] = weights.weight.rolling(7).mean()
132/28:
weights['rollingMean'] = weights.weight.rolling(7).mean()
weights['diffFromMean'] = weights.weight - weights.rollingMean
132/29:
weights['rollingMean'] = weights.weight.rolling(7).mean()
weights['diffFromMean'] = weights.weight - weights.rollingMean
weights.diffFromMean.plot()
132/30:
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
import plotly.graph_objs as go
init_notebook_mode(connected=True)


# Create a trace
trace = go.Scatter(
    x = weights.weekday,
    y = weights.diffFromMean,
    mode = 'markers'
)

data = [trace]

# Plot and embed in ipython notebook!
iplot(data, filename='basic-scatter')
132/31:
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
import plotly.graph_objs as go
init_notebook_mode(connected=True)


# Create a trace
trace = go.Scatter(
    x = weights.weekday,
    y = weights.diffFromMean,
    mode = 'markers'
)

data = [trace]

# Plot and embed in ipython notebook!
iplot(data, filename='basic-scatter')
132/32: weights.groupby('weekday')
132/33: weights.groupby('weekday').mean()
132/34:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights = weights.iloc[::-1]
132/35:
weights.weight.plot()
pylab.show()
132/36:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights.iloc[::-1]
132/37:
weights.weight.plot()
pylab.show()
132/38:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights[::-1]
132/39:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights = weights[::-1]
132/40:
weights.weight.plot()
pylab.show()
132/41:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights.reindex(index=weights.index[::-1])
132/42:
weights.weight.plot()
pylab.show()
132/43:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights = weights.reindex(index=weights.index[::-1])
132/44:
weights.weight.plot()
pylab.show()
132/45:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights = weights.reindex(index=weights.index[::-1])
132/46:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
weights = weights.reindex(index=weights.index[::-1])
132/47:
weights.weight.plot()
pylab.show()
132/48:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
# weights = weights.reindex(index=weights.index[::-1])
132/49:
weights.weight.plot()
pylab.show()
132/50:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
# weights = weights.reindex(index=weights.index[::-1])
weights.sort_values(by='date')
132/51:
weights.weight.plot()
pylab.show()
132/52:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
# weights = weights.reindex(index=weights.index[::-1])
weights = weights.sort_values(by='date')
132/53:
weights.weight.plot()
pylab.show()
133/1:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
# weights = weights.reindex(index=weights.index[::-1])
weights = weights.sort_values(by='date')
133/2:
weights.weight.plot()
pylab.show()
133/3:
weights['rollingMean'] = weights.weight.rolling(7).mean()
weights['diffFromMean'] = weights.weight - weights.rollingMean
weights.diffFromMean.plot()
133/4:
import datetime
toDate = lambda millisSinceEpoch : datetime.datetime.fromtimestamp(millisSinceEpoch/1000)
weights['datetime'] = weights.date.apply(toDate)
weights['weekday'] = weights.datetime.apply(datetime.datetime.weekday)
133/5: weights.weekday
133/6:
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
import plotly.graph_objs as go
init_notebook_mode(connected=True)


# Create a trace
trace = go.Scatter(
    x = weights.weekday,
    y = weights.diffFromMean,
    mode = 'markers'
)

data = [trace]

# Plot and embed in ipython notebook!
iplot(data, filename='basic-scatter')
133/7: weights.groupby('weekday').mean()
133/8: averagesByDay = weights.groupby('weekday').mean()
133/9: averagesByDay = weights.groupby('weekday').mean()
133/10:
trace = go.Scatter(
    x = averagesByDay.weekday,
    y = averagesByDay.diffFromMean,
    mode = 'line'
)

data = [trace]

# Plot and embed in ipython notebook!
iplot(data, filename='basic-scatter')
133/11:
averagesByDay = weights.groupby('weekday').mean()
averagesByDay
133/12:
averagesByDay = weights.groupby('weekday').mean()
averagesByDay.T
133/13:
averagesByDay = weights.groupby('weekday').mean()
averagesByDay.index
133/14:
trace = go.Scatter(
    x = averagesByDay.index,
    y = averagesByDay.diffFromMean,
    mode = 'line'
)

data = [trace]

# Plot and embed in ipython notebook!
iplot(data, filename='basic-scatter')
133/15:
trace = go.Scatter(
    x = averagesByDay.index,
    y = averagesByDay.diffFromMean,
    mode = 'lines'
)

data = [trace]

# Plot and embed in ipython notebook!
iplot(data, filename='basic-scatter')
133/16:
traceMean = go.Scatter(
    x = averagesByDay.index,
    y = averagesByDay.diffFromMean,
    mode = 'lines'
)

traceScatter = go.Scatter(
    x = weights.weekday,
    y = weights.diffFromMean,
    mode = 'markers'
)

data = [traceMean, traceScatter]

# Plot and embed in ipython notebook!
iplot(data, filename='basic-scatter')
134/1:
import pandas as pd
import pylab
weights = pd.read_csv('/home/tim/Downloads/weight.csv')
# weights = weights.reindex(index=weights.index[::-1])
weights = weights.sort_values(by='date')
weights.weight = weights.weight/1000
134/2:
weights.weight.plot()
pylab.show()
134/3:
weights['rollingMean'] = weights.weight.rolling(7).mean()
weights['diffFromMean'] = weights.weight - weights.rollingMean
weights.diffFromMean.plot()
134/4:
import datetime
toDate = lambda millisSinceEpoch : datetime.datetime.fromtimestamp(millisSinceEpoch/1000)
weights['datetime'] = weights.date.apply(toDate)
weights['weekday'] = weights.datetime.apply(datetime.datetime.weekday)
134/5: weights.weekday
134/6:
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
import plotly.graph_objs as go
init_notebook_mode(connected=True)


# Create a trace
trace = go.Scatter(
    x = weights.weekday,
    y = weights.diffFromMean,
    mode = 'markers'
)

data = [trace]

# Plot and embed in ipython notebook!
iplot(data, filename='basic-scatter')
134/7:
averagesByDay = weights.groupby('weekday').mean()
averagesByDay.index
134/8:
traceMean = go.Scatter(
    x = averagesByDay.index,
    y = averagesByDay.diffFromMean,
    mode = 'lines'
)

traceScatter = go.Scatter(
    x = weights.weekday,
    y = weights.diffFromMean,
    mode = 'markers'
)

data = [traceMean, traceScatter]

# Plot and embed in ipython notebook!
iplot(data, filename='basic-scatter')
129/8: t
129/9: t = TransformStamped()
129/10: t.transform.rotation.w = 1
129/11: t.transform.translation.x = 2
129/12: t1 = t
129/13: t2 = t
129/14: t2.transform.translation.y =2
129/15: t1
129/16: t1 = t.copy()
129/17: t1 = TransformStamped(t)
129/18: t
129/19: t.serialize
129/20: t.serialize()
129/21: import tf2_msgs
129/22: import tf2_geometry_msgs
129/23: tf2_geometry_msgs.copy(t)
129/24: tf2_geometry_msgs.do_transform_pose
129/25: ?tf2_geometry_msgs.do_transform_pose
129/26: ?tf2_geometry_msgs.do_transform_pose(t1,t2)
129/27: tf2_geometry_msgs.do_transform_pose(t1,t2)
126/8: t1 * t2
129/28: t1 * t2
129/29: t1.transform * t2.transform
129/30: t
129/31: tf2_geometry_msgs.from_msg_msg(t)
129/32: from tf import transformations
129/33: from tf import TransformerROS
129/34: TransformerROS.asMatrix(t1)
129/35: TransformerROS.asMatrix(t1.transform)
129/36: transformer = TransformerROS
129/37: transformer.asMatrix(t1)
129/38: transformer = TransformerROS()
129/39: transformer.asMatrix(t1)
129/40: ?transformer.asMatrix
129/41: ?transformer.fromTranslationRotation
129/42: TransformerROS.fromTranslationRotation(t1.transform.translation, t1.transform.rotation)
129/43: transformer.fromTranslationRotation(t1.transform.translation, t1.transform.rotation)
129/44: tf2_geometry_msgs.from_msg_msg(t)
129/45: type(tf2_geometry_msgs.from_msg_msg(t))
129/46: import tf2_kdl
129/47: tf2_kdl.transform_to_kdl(t1)
129/48: tf2_geometry_msgs.from_msg_msg(t1)
129/49: type(tf2_geometry_msgs.from_msg_msg(t1))
129/50: type(t1)
129/51: import tf2
129/52: import tf2_msgs
129/53: import tf2_py
129/54: import tf2_ros
129/55: tf2_ros.convert
129/56: ?tf2_ros.convert
129/57: ?tf2_ros.convert(t1)
129/58: tf2_ros.convert(t1)
129/59: tf2_ros.convert(t1, 'transform')
129/60: tf2_ros.TFMessage
129/61: tf2_ros.convert(t1, tf2_msgs.msg._TFMessage.TFMessage)
129/62: tf2_ros.convert(t1, 'tf2_msgs.msg._TFMessage.TFMessage')
129/63: import tf2_kdl
129/64: tf2_kdl.transform_to_kdl(t)
129/65: t1kdl = tf2_kdl.transform_to_kdl(t)1
129/66: t1kdl = tf2_kdl.transform_to_kdl(t1)
129/67: type(t1kdl)
129/68: t1kdl.Inverse
129/69: t1kdl.Inverse()
129/70: t2kdl = tf2_kdl.transform_to_kdl(t2)
129/71: t2kdl * t1kdl
129/72: t1kdl.p
129/73: t1
129/74: (t2kdl * t1kdl).p
129/75: t2
129/76: t1
129/77: t1kdl
129/78: t1kdl.p
129/79: t2kdl.p
129/80: t2kdl
129/81: t2kdl * t2kdl
129/82: (t2kdl * t2kdl).p
129/83: c = (t2kdl * t2kdl)
129/84: c.p
129/85: t1kdl.p
129/86: t1.transform.translation.x = 4
129/87: t1.transform.translation.y = 1
129/88: t1kdl = tf2_kdl.transform_to_kdl(t1)
129/89: t1kdl * t2kdl
129/90: t1kdl
129/91: t2kdl
129/92: t1kdl * t2kdl
129/93: t1kdl * t2kdl.Inverse()
129/94: tf2_kdl.to_msg_vector(t1kdl * t2kdl.Inverse())
129/95: t1kdl.M
129/96: t1kdl.p
129/97: tf2_kdl.PointStamped(t1kdl)
129/98: tf2_geometry_msgs.transform_to_kdl(t1)
129/99: tf2_geometry_msgs.do_transform_point
129/100: ?tf2_geometry_msgs.do_transform_point
129/101: ?tf2_geometry_msgs.do_transform_pose
129/102: tf2_geometry_msgs.do_transform_pose
129/103: tf2_geometry_msgs.do_transform_pose(t1.transform, t2)
129/104: tf2_geometry_msgs.to_msg_msg(t1)
129/105: type(tf2_geometry_msgs.to_msg_msg(t1))
129/106: type(tf2_geometry_msgs.fom_msg_msg(t1))
129/107: type(tf2_geometry_msgs.fom_msg_msg(t1))
129/108: type(tf2_geometry_msgs.from_msg_msg(t1))
129/109: t1kdl
129/110: toMg
129/111: toMsg
129/112: toMsg(t1kdl)
129/113: type(t1kdl)
129/114: tf2_kdl.to_msg_vector(t1kdl)
129/115: import tf_conversions
129/116: tf_conversions.Chain
129/117: ?tf_conversions.Chain
129/118: tf_conversions.toMsg(t1kdl)
129/119: from tf import transformations
129/120: tf_conversions.fromMsg(t1)
129/121: tf_conversions.fromTf(t1)
129/122: tf_conversions.fromTf(t1kdl)
129/123: tf_conversions.fromTf(t1)
129/124: t1.transform
129/125: tf_conversions.fromTf(t1.transform)
129/126: tf_conversions.toMatrix(t1)
129/127: from tf_conversions import toMsg
129/128: from tf2_kdl import transform_to_kdl
129/129: transform_to_kdl(t1)
129/130: transform_to_kdl(t1) * transform_to_kdl(t2)
129/131: toMsg(transform_to_kdl(t1) * transform_to_kdl(t2))
129/132: tf_buf = tf2_ros.Buffer()
129/133: import rospy
129/134: rospy.init_node('tf_testing')
129/135: import os
129/136: os.environ('ROS_MASTER_URI')
129/137: os.environ['ROS_MASTER_URI']
129/138: os.environ['ROS_MASTER_URI'] = 'http://localhost:11311'
129/139: rospy.init_node('tf_testing')
129/140: tf_buf = tf2_ros.Buffer()
129/141: tf_buf.transform
129/142: ?tf_buf.transform
129/143: odomToTangoTf = TransformStamped()
129/144: odomToTangoTf.transform.translation.x = 5
129/145: odomToTangoTf.transform.translation.z = 1
129/146: baseToTangoTf = TransformStamped()
129/147: baseToTangoTf.transform.translation.z = 1
129/148: odomToTangoKdl = tf2_kdl.transform_to_kdl(odomToTangoTf)
129/149: tangoToOdomKdl = odomToTangoKdl.Inverse()
129/150: tangoToOdomTf = tf_conversions.toMsg(tangoToOdomKdl)
129/151: tangoToOdomTf
129/152: odomToTangoKdl
129/153: odomToTangoTf.transform.rotation.w = 1
129/154: baseToTangoTf.transform.rotation.w = 1
129/155: odomToTangoKdl = tf2_kdl.transform_to_kdl(odomToTangoTf)
129/156: odomToTangoKdl
129/157: tangoToOdomKdl = odomToTangoKdl.Inverse()
129/158: tangoToOdomTf = tf_conversions.toMsg(tangoToOdomKdl)
129/159: tangoToOdomTf
129/160: tf_buf.transform(tangoToOdomTf, 'base_link')
129/161: tangoToOdomTf
129/162: tangoToOdomTf = TransformStamped()
129/163: tangoToOdomTf.transform = tf_conversions.toMsg(tangoToOdomKdl)
129/164: tf_buf.transform(tangoToOdomTf, 'base_link')
129/165: ?toMsg
129/166: toMsg(t1kdl)
129/167: tangoToOdomPose = PoseStamped()
129/168: from geometry_msgs.msg import PoseStamped
129/169: tangoToOdomPose = PoseStamped()
129/170: tangoToOdomPose.pose = tf_conversions.toMsg(tangoToOdomKdl)
129/171: tf_buf.transform(tangoToOdomPose, 'base_link')
129/172: tfListener = tf2_ros.TransformListener(tf_buf)
129/173: tf_buf.transform(tangoToOdomPose, 'base_link')
129/174: tf_buf.all_frames_as_string
129/175: tf_buf.all_frames_as_string()
129/176: import rostopic
129/177: rostopic.rosgraph.names
129/178: rospy.get_published_topics()
129/179: tf_buf.transform(tangoToOdomPose, 'base_link')
   1: import tf2_ros
   2: tf_buf.transform(tangoToOdomPose, 'base_link')
   3: tf_buf = tf2_ros.Buffer()
   4: tfListener = tf2_ros.TransformListener(tf_buf)
   5: tf_buf.transform(tangoToOdomPose, 'base_link')
   6: tangoToOdomPose.pose = tf_conversions.toMsg(tangoToOdomKdl)
   7: import tf_conversions
   8: tangoToOdomPose.pose = tf_conversions.toMsg(tangoToOdomKdl)
   9: tangoToOdomKdl = odomToTangoKdl.Inverse()
  10: odomToTangoKdl = tf2_kdl.transform_to_kdl(odomToTangoTf)
  11: import tf2_kdl
  12: odomToTangoKdl = tf2_kdl.transform_to_kdl(odomToTangoTf)
  13: odomToTangoKdl = tf2_kdl.transform_to_kdl(odomToTangoTf)
  14: odomToTangoTf = tf_buf.lookup_transform('start_of_service', 'device')
  15: import rospy
  16: odomToTangoTf = tf_buf.lookup_transform('start_of_service', 'device', rospy.Time.now())
  17: rospy.init_node('tf_testing')
  18: odomToTangoTf = tf_buf.lookup_transform('start_of_service', 'device', rospy.Time.now())
  19: odomToTangoTf
  20: odomToTangoKdl = tf2_kdl.transform_to_kdl(odomToTangoTf)
  21: tangoToOdomKdl = odomToTangoKdl.Inverse()
  22: tangoToOdomPose.pose = tf_conversions.toMsg(tangoToOdomKdl)
  23: tangoToOdomPose = PoseStamped()
  24: from geometry_msgs.msg import PoseStamped
  25: tangoToOdomPose = PoseStamped()
  26: tangoToOdomPose.pose = tf_conversions.toMsg(tangoToOdomKdl)
  27: tf_buf.transform(tangoToOdomPose, 'base_link')
  28: tangoToOdomPose
  29: type(tangoToOdomPose)
  30: tf_buf.transform(tangoToOdomPose, 'base_link')
  31: import tf2_kdl
  32: tf_buf.transform(tangoToOdomPose, 'base_link')
  33: import tf2_geometry_msgs
  34: tf_buf.transform(tangoToOdomPose, 'base_link')
  35: tangoToOdomPose.frame_id = 'tango'
  36: tangoToOdomPose.header.frame_id = tango
  37: tangoToOdomPose.header.frame_id = 'tango'
  38: tf_buf.transform(tangoToOdomPose, 'base_link')
  39: tangoToOdomPose
  40: tangoToOdomPose.pose = tf_conversions.toMsg(tangoToOdomKdl)
  41: tangoToOdomKdl
  42: tangoToOdomKdl = odomToTangoKdl.Inverse()
  43: odomToTangoKdl = tf2_kdl.transform_to_kdl(odomToTangoTf)
  44: odomToTangoTf
  45: odomToTangoTf = tf_buf.lookup_transform('start_of_service', 'device', rospy.Time.now())
  46: %history -g -f /tmp/ipythonHist.txt
